{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865180a7",
   "metadata": {},
   "source": [
    "# Adapting W2V for unsipervised glyph embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import nle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del gym.Wrapper.__getattr__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9906d62",
   "metadata": {},
   "source": [
    "A wrpper that keeps track of the action history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "class RecentHistory(gym.Wrapper):\n",
    "    \"\"\"The base interaction architecture is essentially a middleman, who passes\n",
    "    the action to the underlying env and intercepts the resulting transition\n",
    "    data. It also is allowed, but not obliged to interact with the env, while\n",
    "    intercepting the observations.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, *, n_recent=0):\n",
    "        super().__init__(env)\n",
    "        self.recent = deque([], n_recent)\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.recent.append(action)\n",
    "        return self.env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330fa985",
   "metadata": {},
   "source": [
    "We hide the NLE under several layers of wrappers. From the core to the shell:\n",
    "1. `ReplayToFile` saves the seeds and the takes actions into a file for later inspection and replay.\n",
    "2. `NLEAtoN` maps ascii actions to opaque actions accpeted by the NLE.\n",
    "3. `NLEPatches` patches tty-screens, botched by the cr-lf misconfiguration of the NLE's tty term emulator and NetHacks displays (lf only).\n",
    "4. `NLEFeatures` adds extra features generated on-the-fly from the current NLE's observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.play.wrapper import ReplayToFile, Replay\n",
    "from nle_toolbox.utils.env.wrappers import NLEPatches, NLEAtoN, NLEFeatures\n",
    "\n",
    "def gui_factory(seed=None):\n",
    "    env = NLEPatches(\n",
    "        ReplayToFile(\n",
    "            gym.make('NetHackChallenge-v0'),\n",
    "            save_on='done',\n",
    "            sticky=True,\n",
    "            folder='./replays',\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    env.seed(seed)\n",
    "\n",
    "    return NLEAtoN(env)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644a2ab",
   "metadata": {},
   "source": [
    "We start with implementing a simple command evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71997f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gui_run(\n",
    "    env,\n",
    "    *commands\n",
    "):\n",
    "    pipe0 = deque([])\n",
    "    obs, done = env.reset(), False\n",
    "    for cmd in commands:\n",
    "        pipe0.extend(cmd)\n",
    "        while pipe0 and not done:\n",
    "            obs, rew, done, info = env.step(pipe0.popleft())\n",
    "\n",
    "        yield obs\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a3da8",
   "metadata": {},
   "source": [
    "A renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7124c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "\n",
    "from time import sleep\n",
    "from nle_toolbox.utils.env.render import render as tty_render\n",
    "\n",
    "def ipynb_render(obs, clear=True, fps=None):\n",
    "    if fps is None:\n",
    "        return True\n",
    "\n",
    "    from IPython.display import clear_output\n",
    "    if clear:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(tty_render(**obs))\n",
    "    if fps > 0:\n",
    "        sleep(fps)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5746554",
   "metadata": {},
   "source": [
    "Below is a wrapper, which handles menus (unless an interaction is required) and\n",
    "fetches all consecutive messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.chassis import Chassis, ActionMasker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151e0bc0",
   "metadata": {},
   "source": [
    "Let's test it in bulk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb23f2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# seed = None\n",
    "# seed = 12513325507677477210, 18325590921330101247  # multi\n",
    "# seed = 1251332550767747710, 18325590921330101247  # single\n",
    "# seed = 125133255076774710, 18325590921330101247  # single\n",
    "# seed = 13765371332493407478, 12246923801353953927\n",
    "# seed = 12301533412141513004, 11519511065143048485\n",
    "# seed = 1632082041122464284, 11609152793318129379\n",
    "seed = 12604736832047991440, 12469632217503715839  # an aspirant\n",
    "# seed = 5009195464289726085, 12625175316870653325\n",
    "\n",
    "with Chassis(RecentHistory(gui_factory(seed), n_recent=None), split=False) as env:\n",
    "    for obs in gui_run(\n",
    "        env,\n",
    "        ';j:',         # a paragraph about a cat\n",
    "#         'acy',         # break a wand \"of slow\" and blow up\n",
    "        '\\033Zbyyy,',  # cast a sleep ray at a newt and pick up its corpse\n",
    "    ):\n",
    "        ipynb_render(obs, clear=False)  # dump(env.env, obs[0])\n",
    "        pp.pprint(\n",
    "            (\n",
    "                env.messages,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f5491bf",
   "metadata": {},
   "source": [
    "import pdb;pdb.pm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc0b8e",
   "metadata": {},
   "source": [
    "The factory for collecting random exploration rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aed90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nle_toolbox.utils import seeding\n",
    "\n",
    "def factory(seed=None, folder=None):\n",
    "    # get the base env and apply tty patches\n",
    "    env = NLEPatches(gym.make('NetHackChallenge-v0'))\n",
    "    ctoa = {chr(a): j for j, a in enumerate(env.unwrapped._actions)}\n",
    "\n",
    "    # setup seed runs capabilities\n",
    "    if folder is None:\n",
    "        env = Replay(env, sticky=True)\n",
    "\n",
    "    else:\n",
    "        env = ReplayToFile(env, sticky=True,\n",
    "                           folder=folder, save_on='done')\n",
    "    env.seed(seed)\n",
    "\n",
    "    # if not isinstance(seed, tuple):\n",
    "    #     seed = seeding.generate(seed)\n",
    "    # seeding.pyroot(env).set_initial_seeds(*seed, False)\n",
    "\n",
    "    # use chassis\n",
    "    env = RecentHistory(env, n_recent=32)\n",
    "    return ActionMasker(Chassis(env, space=ctoa[' '], split=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c03a68",
   "metadata": {},
   "source": [
    "A non-illegal random action exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def random_explore(seed=None, n_steps=1000, *, auto=False, fps=None, copy=False):\n",
    "    \"\"\"A non-illegal random action explorer.\n",
    "    \"\"\"\n",
    "    ss_pol, ss_env = np.random.SeedSequence(seed).spawn(2)\n",
    "\n",
    "    rng, j = np.random.default_rng(ss_pol), 0\n",
    "    with factory(seed=ss_env) as env:\n",
    "        (obs, mask), fin = env.reset(), False\n",
    "        while (\n",
    "            ipynb_render(obs, clear=True, fps=fps)\n",
    "            and not (fin or j >= n_steps)\n",
    "        ):\n",
    "            # though nle reuses buffers, we do not deep copy them\n",
    "            #  delegating this to the downstream user instead\n",
    "            yield deepcopy(obs) if copy else obs\n",
    "\n",
    "            # sample from non-forbidden actions\n",
    "            # XXX whelp... tilde uint8 flips the sign bit and is not the logical not\n",
    "            act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "            (obs, mask), rew, fin, info = env.step(act)\n",
    "            j += 1\n",
    "\n",
    "            if fin and auto:\n",
    "                ipynb_render(obs, clear=True, fps=fps)\n",
    "                (obs, mask), fin = env.reset(), False    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e9e46",
   "metadata": {},
   "source": [
    "Set up the glyph-to-vec embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb447c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn.utils.weight_norm import weight_norm\n",
    "\n",
    "from nle.nethack import MAX_GLYPH, DUNGEON_SHAPE\n",
    "\n",
    "from nle_toolbox.utils.env.defs import glyphlut\n",
    "from nle_toolbox.utils.env.defs import MAX_ENTITY, glyph_group\n",
    "\n",
    "from nle_toolbox.bot.model.glyph import GlyphEmbedding\n",
    "\n",
    "\n",
    "embedding = GlyphEmbedding(embedding_dim=128)\n",
    "g2v = nn.Sequential(OrderedDict([\n",
    "    ('inp', embedding),\n",
    "    ('out', weight_norm(\n",
    "        # XXX are we sure we need this weight reparam here?\n",
    "        #  \\frac{g_j}{\\|w_j\\|} w_j, j=0..d for m -->> d linear layer\n",
    "        nn.Linear(128, MAX_ENTITY + 1, bias=False)\n",
    "    )),\n",
    "]))\n",
    "\n",
    "optim = torch.optim.Adam(\n",
    "    g2v.parameters(),\n",
    "    lr=1e-3,\n",
    ")\n",
    "\n",
    "n_border = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2da249",
   "metadata": {},
   "source": [
    "### w2v\n",
    "\n",
    "Let's repurpose the word-to-vec skip-gram model to train good initial glyph embeddings.\n",
    "\n",
    "$$\n",
    "p(w\\mid c)\n",
    "    \\propto \\exp\\{\\theta_w^\\top \\phi_c\\}\n",
    "    \\,,$$\n",
    "$\\phi_v, \\theta_v \\in \\mathbb{R}^d$.\n",
    "\n",
    "Consider the context graph $G = (V, E)$. Skip-gram W2V embedding models the probability of\n",
    "a context $G_c$ of a given token $c$ with\n",
    "$$\n",
    "p(G_c)\n",
    "    = \\pi(c) p(G_c \\mid c)\n",
    "    = \\pi(c) \\prod_{w \\in G_c} p(w \\mid c)\n",
    "    \\,, $$\n",
    "where $\n",
    "    G_v := \\{w \\in G\\colon vw in E\\}\n",
    "$ is the collection of the $E$-neighbours of $v$ and $w \\in G$ stands for iterating\n",
    "over tokens in $V$ with $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8807f",
   "metadata": {},
   "source": [
    "Assuming independent contexts (**why?**), skip-gram W2V maximizes the following log-likelihood:\n",
    "$$\n",
    "\\mathcal{L}\n",
    "    = \\frac1{\\lvert G \\rvert} \\sum_{c \\in G} \\log p(G_c)\n",
    "    = \\frac1{\\lvert G \\rvert} \\sum_{c \\in G} \\biggl(\n",
    "        \\log \\pi(c) + \\sum_{w \\in G_c} \\log p(w\\mid c)\n",
    "    \\biggr)\n",
    "    \\,. $$\n",
    "\n",
    "Let's notice that $G$ is an undirected graph, which implies that\n",
    "$$\n",
    "\\sum_{c\\in G} \\sum_{w \\in G_c}\n",
    "        = \\sum_{uw \\in E}\n",
    "        = \\sum_{w \\in G} \\sum_{c \\in G_w}\n",
    "    \\,. $$\n",
    "Hence,\n",
    "$$\n",
    "\\mathcal{L}\n",
    "    = \\frac1{\\lvert G \\rvert} \\sum_{w \\in G} \\biggl(\n",
    "        \\log \\pi(w) + \\sum_{c \\in G_w} \\log p(w\\mid c)\n",
    "    \\biggr)\n",
    "    \\,. $$"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c7da1bca",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f3876",
   "metadata": {},
   "source": [
    "Ignoring the prior glyph probabilities (**why?**) and randomizing over the contexts,\n",
    "the final loss to be minimized is\n",
    "$$\n",
    "\\mathcal{L}\n",
    "    = \\mathbb{E}_G \\mathbb{E}_{w\\sim G}\n",
    "        \\sum_{c \\in G_w} \\log p(w\\mid c)\n",
    "    \\,, $$\n",
    "which means that it is possible to sample contexts $G_w$ instead of full 2d meshes $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28100536",
   "metadata": {},
   "source": [
    "The following online batch prefetcher logic was copied from elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e7343",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "\n",
    "from nle_toolbox.utils.fold import pyt_fold2d\n",
    "\n",
    "it = random_explore(\n",
    "    seed=None,\n",
    "    n_steps=float('inf'),\n",
    "    auto=True,\n",
    "    copy=False,\n",
    "    fps=0.01,\n",
    ")\n",
    "losses = []\n",
    "\n",
    "# the stream prefetch buffer size, the batch size, and\n",
    "#  the overall number of batches\n",
    "n_buffer_size, n_batch_size, n_batches = 256, 1, 500*8\n",
    "prefetch, buffer = [], []\n",
    "# XXX we can actually fetch the neighbouring context into the buffer\n",
    "\n",
    "# bordering array (MAX_GLYPH <<-->> MAX_ENTITY)\n",
    "rows, cols = DUNGEON_SHAPE\n",
    "bordered = np.full(\n",
    "    (n_border + rows + n_border, n_border + cols + n_border),\n",
    "    MAX_GLYPH, dtype=np.int16)\n",
    "stage = bordered[n_border:-n_border, n_border:-n_border]\n",
    "\n",
    "# prng for prefetch -->> batch eviction\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# the total number of step in the env (+1 for collation step)\n",
    "n_total = n_buffer_size + (n_batch_size + 1) * n_batches\n",
    "with tqdm.tqdm(range(n_total), ncols=80, disable=True) as bar:\n",
    "    for j in bar:\n",
    "        # (collect) fetch the next obs\n",
    "        obs = next(it)\n",
    "\n",
    "        # (collect) we reuse the buffer\n",
    "        np.copyto(stage, obs['glyphs'])\n",
    "        item = bordered.copy()\n",
    "\n",
    "        # (collect) add a sample to the prefetch buffer\n",
    "        if len(prefetch) < n_buffer_size:\n",
    "            prefetch.append(item)\n",
    "            continue\n",
    "\n",
    "        # (collect) if prefetch is full, randomly evict into the batch buffer\n",
    "        elif len(buffer) < n_batch_size:\n",
    "            ix = rng.integers(len(prefetch))\n",
    "            buffer.append(prefetch[ix])\n",
    "            prefetch[ix] = item\n",
    "            continue\n",
    "\n",
    "        # XXX reached every `n_batch_size`-th iteration after the prefetch\n",
    "        #  buffer has been saturated\n",
    "        pass\n",
    "\n",
    "        # (collect) collate a batch and flush\n",
    "        batch = default_collate(buffer)\n",
    "        buffer.clear()\n",
    "\n",
    "        # (g2v) fwd through the embedding model\n",
    "        # XXX \\log p(w \\mid c) conditional prob of w given c\n",
    "        raw = g2v(batch).permute(0, 3, 1, 2).clone()\n",
    "        logprob = F.log_softmax(raw, dim=1)\n",
    "\n",
    "        # (g2v) ignore the artificial borders\n",
    "        _, entity = embedding.lookup(batch[..., n_border:-n_border, n_border:-n_border])\n",
    "        context = pyt_fold2d(raw, k=n_border, n_leading=-2)\n",
    "        c_raw = raw[..., n_border:-n_border, n_border:-n_border]\n",
    "\n",
    "        # (g2v) compute the skip-gram embedding loss\n",
    "        # XXX full[:, x, y, i, j] = \\log p((x, y) \\mid (i, j))\n",
    "        #     cent[:, x, y] = \\log p((x, y) \\mid (x, y))\n",
    "        # XXX .cross_entropy does its own `log_softmax`\n",
    "        target = entity.reshape(*entity.shape, 1, 1).expand(-1, -1, -1, *context.shape[-2:])\n",
    "        full = F.cross_entropy(context, target, reduction='none')\n",
    "        cent = F.cross_entropy(c_raw, entity, reduction='none')\n",
    "\n",
    "        loss = full.sum((-1, -2)).mean() - cent.mean()\n",
    "\n",
    "        # (train) zero-grad backward and step blah blah yada yada\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        losses.append(float(loss))\n",
    "\n",
    "        bar.set_postfix_str(f'{float(loss):.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9364a29",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
