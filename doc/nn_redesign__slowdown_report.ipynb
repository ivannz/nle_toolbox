{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a978e8",
   "metadata": {},
   "source": [
    "# Let's try an non-hierarchical RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import nle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del gym.Wrapper.__getattr__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e1ac6e",
   "metadata": {},
   "source": [
    "Import other useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baefd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plyr\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91212f6",
   "metadata": {},
   "source": [
    "We hide the NLE under several layers of wrappers. From the core to the shell:\n",
    "1. `ReplayToFile` handles seeding and logs the taken actions and seed into a file for later inspection and replay.\n",
    "\n",
    "2. `NLEPatches` patches tty-screens, botched by the cr-lf misconfiguration of the NLE's tty term emulator and NetHacks displays (lf only).\n",
    "\n",
    "3. `Chassis` handles skippable gui events that do not require a decision, such as collecting menu pages unless an interaction is required, fetching consecutive topline or log messages.\n",
    "\n",
    "4. `ActionMasker` computes the mask of action that are **forbidden** in the current game state (_gui_ or _play_)\n",
    "\n",
    "5. `RecentHistory` keeps a brief log of actions taken in the environment (partially duplicates the functionality of the `Replay` wrapper).\n",
    "\n",
    "6. `NLEAtoN` maps ascii actions to opaque actions accpeted by the NLE.\n",
    "\n",
    "7. (**unused**) `NLEFeatures` adds extra features generated on-the-fly from the current NLE's observation.\n",
    "  * see `NLEFeaturesVicinity` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.wrappers.replay import ReplayToFile, Replay\n",
    "\n",
    "from nle_toolbox.wrappers.features import NLEPatches, NLEAtoN\n",
    "from nle_toolbox.bot.chassis import Chassis, ActionMasker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5975e4e3",
   "metadata": {},
   "source": [
    "A temporary wrapper that bails out on any menu or prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.chassis import InteractiveWrapper\n",
    "from nle_toolbox.bot.chassis import get_wrapper\n",
    "\n",
    "class AutoEscape(InteractiveWrapper):\n",
    "    def __init__(self, env, escape='\\033'):\n",
    "        super().__init__(env)\n",
    "        self.chassis = get_wrapper(env, Chassis)\n",
    "        self.escape = escape\n",
    "\n",
    "    def update(self, obs, rew=0., done=False, info=None):\n",
    "        # default to immediately escaping from any menu or prompt\n",
    "        while self.chassis.in_menu or self.chassis.prompt:\n",
    "            obs, rew, done, info = self.env.step(self.escape)\n",
    "\n",
    "        # update must always return the most recent relevant transition data\n",
    "        return obs, rew, done, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9906d62",
   "metadata": {},
   "source": [
    "A wrpper that keeps track of the action history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class RecentHistory(gym.Wrapper):\n",
    "    \"\"\"The base interaction architecture is essentially a middleman, who passes\n",
    "    the action to the underlying env and intercepts the resulting transition\n",
    "    data. It also is allowed, but not obliged to interact with the env, while\n",
    "    intercepting the observations.\n",
    "    \"\"\"\n",
    "    def __new__(cls, env, *, n_recent=0, map=None):\n",
    "        if n_recent < 1:\n",
    "            return env\n",
    "        return object.__new__(cls)\n",
    "\n",
    "    def __init__(self, env, *, n_recent=0, map=None):\n",
    "        super().__init__(env)\n",
    "        self.recent = deque([], n_recent)\n",
    "        self.map = map if callable(map) else lambda x: x\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.recent.append(self.map(action))\n",
    "        return self.env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386b5c9",
   "metadata": {},
   "source": [
    "A wrapper that keeps the specified observation keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3890c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.wrappers.features import ObservationWrapper\n",
    "\n",
    "class ObservationKeyFilter(ObservationWrapper):\n",
    "    def __init__(self, env, *keys):\n",
    "        super().__init__(env)\n",
    "        self.keys = frozenset(keys)\n",
    "\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            self.observation(self.observation_space)\n",
    "        )\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return {k: v for k, v in observation.items() if k in self.keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01294c",
   "metadata": {},
   "source": [
    "A wrapper, which pre-extracts the field-of-view around the agent\n",
    "* `NLEFeatures` is a little bit outdated, but hopefully, if the wrapper below helps,\n",
    "then it will be updated and merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf165df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.wrappers.features import ObservationWrapper\n",
    "\n",
    "from nle_toolbox.utils.fold import npy_fold2d\n",
    "from nle.nethack import (\n",
    "    MAX_GLYPH,\n",
    "    NLE_BL_X,\n",
    "    NLE_BL_Y,\n",
    "    DUNGEON_SHAPE,\n",
    ")\n",
    "\n",
    "class NLEFeaturesVicinity(ObservationWrapper):\n",
    "    def __init__(self, env, *, k=3):\n",
    "        super().__init__(env)\n",
    "\n",
    "        decl = self.observation_space['glyphs']\n",
    "\n",
    "        # create bordered glyph array\n",
    "        rows, cols = DUNGEON_SHAPE\n",
    "        glyphs = self.glyphs = np.full((\n",
    "            k + rows + k, k + cols + k,\n",
    "        ), MAX_GLYPH, dtype=decl.dtype)\n",
    "\n",
    "        # create view for fast access\n",
    "        self.vw_glyphs = glyphs[k:-k, k:-k]\n",
    "        self.vw_vicinity = npy_fold2d(\n",
    "            glyphs, k=k, n_leading=0, writeable=True,\n",
    "            # XXX pytorch does not like read-only views\n",
    "        )\n",
    "\n",
    "        # declare the observation space\n",
    "        self.observation_space['vicinity'] = gym.spaces.Box(\n",
    "            MAX_GLYPH,\n",
    "            0,\n",
    "            dtype=self.vw_vicinity.dtype,\n",
    "            shape=self.vw_vicinity.shape[2:],\n",
    "        )\n",
    "\n",
    "    def observation(self, observation):\n",
    "        np.copyto(self.vw_glyphs, observation['glyphs'], 'same_kind')\n",
    "\n",
    "        bls = observation['blstats']\n",
    "        vic = self.vw_vicinity[bls[NLE_BL_Y], bls[NLE_BL_X]]\n",
    "\n",
    "        # make sure to produce a coipy of the array\n",
    "        observation.update(dict(vicinity=vic.copy()))\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d23967",
   "metadata": {},
   "source": [
    "The strength stats in ADnD, upon which the mechanics of NetHack is based,\n",
    "comes in two ints: strength and percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle.nethack import (\n",
    "    NLE_BL_STR25,\n",
    "    NLE_BL_STR125,\n",
    ")\n",
    "\n",
    "class NLEFeaturesStrengthPatch(ObservationWrapper):\n",
    "    def observation(self, observation):\n",
    "        bls = observation['blstats'].copy()\n",
    "\n",
    "        # strength percentage is more detailed than `str` stat\n",
    "        # XXX compare src/winrl.cc#L538 with src/attrib.c#L1072-1085\n",
    "        #     e.g. src/dokick.c#L38 sums the transformed str with dex and con\n",
    "        str, prc = bls[NLE_BL_STR125], 0.\n",
    "        if str >= 122:\n",
    "            str = min(str - 100, 25)\n",
    "\n",
    "        elif str >= 19:\n",
    "            str, prc = divmod(19 + str / 50, 1)  # divmod-by-one :)\n",
    "        bls[NLE_BL_STR25] = int(str)\n",
    "        bls[NLE_BL_STR125] = int(prc * 100)  # original step .02, so ok\n",
    "\n",
    "        # replace the original blstats array\n",
    "        observation.update(dict(blstats=bls))\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7194a",
   "metadata": {},
   "source": [
    "The factory for collecting random exploration rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fe6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nle_toolbox.utils import seeding\n",
    "import minihack\n",
    "# env = gym.make(\"MiniHack-River-v0\")\n",
    "\n",
    "def factory(seed=None, folder=None, sticky=False):\n",
    "#     env = gym.make('NetHackChallenge-v0')\n",
    "    env = gym.make(\n",
    "        'MiniHack-Room-Ultimate-15x15-v0',\n",
    "        observation_keys=(\n",
    "            'glyphs',\n",
    "            'chars',\n",
    "            'colors',\n",
    "            'specials',\n",
    "            'blstats',\n",
    "            'message',\n",
    "            'inv_glyphs',\n",
    "            'inv_strs',\n",
    "            'inv_letters',\n",
    "            'inv_oclasses',\n",
    "            'tty_chars',\n",
    "            'tty_colors',\n",
    "            'tty_cursor',\n",
    "            'misc',\n",
    "            'screen_descriptions',\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    from nle.nethack import ACTIONS\n",
    "    ctoa = {chr(a): j for j, a in enumerate(env.unwrapped._actions)}\n",
    "    atoc = tuple(map(chr, env.unwrapped._actions))\n",
    "\n",
    "    # provide seeding capabilities and full action tracking\n",
    "    if folder is None:\n",
    "        env = Replay(env, sticky=sticky)\n",
    "\n",
    "    else:\n",
    "        env = ReplayToFile(env, sticky=sticky, folder=folder, save_on='done')\n",
    "    env.seed(seed)\n",
    "\n",
    "    # patch bugged tty output\n",
    "    env = NLEPatches(env)\n",
    "\n",
    "    # log recent actions\n",
    "    env = RecentHistory(\n",
    "        env,\n",
    "        n_recent=128,\n",
    "        map=lambda a: atoc[a],\n",
    "    )\n",
    "\n",
    "    # skippable gui abstraction layer. Excluded if the action space does not\n",
    "    #  hace the SPACE action.\n",
    "    env = Chassis(env, space=ctoa.get(' '), split=False)\n",
    "\n",
    "    # # auto-skip any menu or prompt\n",
    "    # env = AutoEscape(env, escape=ctoa['\\033'])\n",
    "\n",
    "    # a feature extractor to potentially reduce\n",
    "    #  the runtime complexity of the agent.\n",
    "    env = NLEFeaturesVicinity(env, k=3)\n",
    "\n",
    "    # properly handle str and str125 stats\n",
    "    env = NLEFeaturesStrengthPatch(env)\n",
    "\n",
    "    # filter unused observation keys\n",
    "    # XXX this wrapper should be applied before any container\n",
    "    #  type modifications of the NLE's observation space.\n",
    "    env = ObservationKeyFilter(\n",
    "        env,\n",
    "        # the map, bottom line stats and inventory\n",
    "        'glyphs',\n",
    "        # 'chars',\n",
    "        # 'colors',\n",
    "        # 'specials',\n",
    "        'blstats',\n",
    "        'inv_glyphs',\n",
    "        # 'inv_strs',\n",
    "        # 'inv_letters',\n",
    "        # 'inv_oclasses',\n",
    "\n",
    "        # used for in-notebook rendering\n",
    "        'tty_chars',\n",
    "        'tty_colors',\n",
    "        'tty_cursor',\n",
    "\n",
    "        # used by the GUI abstraction layer (Chassis)\n",
    "        # 'message',\n",
    "        # 'misc',\n",
    "\n",
    "        # extra features produced by the upstream wrappers\n",
    "        'vicinity',\n",
    "        # 'is_objpile',\n",
    "    )\n",
    "\n",
    "    # compute and action mask based on the current NLE mode: gui or play\n",
    "    env = ActionMasker(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a3da8",
   "metadata": {},
   "source": [
    "A renderer for this **factory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7124c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "from time import sleep\n",
    "\n",
    "from nle_toolbox.utils.env.render import render as tty_render\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def ipynb_render(obs, clear=True, fps=None):\n",
    "    if fps is not None:\n",
    "        if clear:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        obs, mask = obs\n",
    "        print(tty_render(**obs))\n",
    "        if fps > 0:\n",
    "            sleep(fps)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644a2ab",
   "metadata": {},
   "source": [
    "We start with implementing a simple command evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71997f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def gui_run(env, *commands):\n",
    "    pipe0 = deque([])\n",
    "    obs, fin = env.reset(), False\n",
    "    for cmd in commands:\n",
    "        if fin:\n",
    "            break\n",
    "\n",
    "        pipe0.extend(cmd)\n",
    "        while pipe0 and not fin:\n",
    "            obs, rew, fin, nfo = env.step(pipe0.popleft())\n",
    "\n",
    "        yield obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e46693",
   "metadata": {},
   "source": [
    "Interesting historical seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaaa8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = None\n",
    "# seed = 13765371332493407478, 12246923801353953927\n",
    "# seed = 12301533412141513004, 11519511065143048485\n",
    "# seed = 1632082041122464284, 11609152793318129379\n",
    "# seed = 5009195464289726085, 12625175316870653325\n",
    "# seed = 8962210393456991721, 8431607288866012881\n",
    "# seed = 14729177660914946268, 9187177962698747861\n",
    "# seed = 16892554419799916328, 6562518563582851317\n",
    "\n",
    "# seed = 12513325507677477210, 18325590921330101247  # Ranger, arrows, dualwields\n",
    "# seed = 1251332550767747710, 18325590921330101247  # Monk, martial arts, single\n",
    "# seed = 125133255076774710, 18325590921330101247  # single\n",
    "# seed = 12604736832047991440, 12469632217503715839  # Wizard, three spells, exploding wand\n",
    "# seed = 14278027783296323177, 11038440290352864458  # valkyrie, dual-wield\n",
    "# seed = 5009195464289726085, 12625175316870653325  # priestess, can loot lots of spells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570ba4d",
   "metadata": {},
   "source": [
    "The code below is used to debug certain events and gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d9c10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with NLEAtoN(factory(seed, sticky=True)) as env:\n",
    "    from nle_toolbox.bot.chassis import get_wrapper\n",
    "    cha = get_wrapper(env, Chassis)\n",
    "\n",
    "    for obs in gui_run(\n",
    "        env,\n",
    "#         ';j:',         # a paragraph about a cat\n",
    "#         'acy',         # break a wand \"of slow\" and blow up\n",
    "        ''\n",
    "    ):\n",
    "        pp.pprint(\n",
    "            (\n",
    "                cha.messages, cha.prompt,  # obs['tty_chars'][0].view('S80')[0].strip(),\n",
    "                cha.in_getlin, cha.in_menu, cha.in_yn_function, cha.xwaitingforspace,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ipynb_render(obs, clear=False, fps=0.01)  # dump(env.env, obs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573960f0",
   "metadata": {},
   "source": [
    "Random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2373af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(obs, n=float('inf'), *, seed=None):\n",
    "    obs, mask = obs\n",
    "    rng, j = np.random.default_rng(seed), 0\n",
    "    while not mask.all() and j < n:\n",
    "        # if we're in LINGER state, pick a random non-forbidden action\n",
    "        # XXX whelp... tilde on int8 is `two's complement`, not the `logical not`\n",
    "        act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "\n",
    "        obs, mask = (yield act)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67fc9e",
   "metadata": {},
   "source": [
    "Do a limited step run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df767340",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with factory(seed=seed, sticky=True) as env:\n",
    "        cha = get_wrapper(env, Chassis)\n",
    "        msk = get_wrapper(env, ActionMasker)\n",
    "\n",
    "        # init the agent and get its first reaction\n",
    "        gen = random(obs)\n",
    "        act = gen.send(None)\n",
    "\n",
    "        # reset the env and get the initial obs\n",
    "        obs, fin = env.reset(), False\n",
    "        while ipynb_render(obs, clear=True, fps=0.01) and not fin:\n",
    "            obs, rew, fin, info = env.step(act)\n",
    "            act = gen.send(obs)\n",
    "\n",
    "# Although the crawler is an infinite loop\n",
    "#  we still trivially protect against `StopIteration`\n",
    "except StopIteration:\n",
    "    pass\n",
    "\n",
    "finally:\n",
    "    gen.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb157caf",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5264f",
   "metadata": {},
   "source": [
    "### Let's train an A2C agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c6fbc",
   "metadata": {},
   "source": [
    "An object to extract full episodes from their trajectory fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c77184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def stitch(*chunks, dim=0):\n",
    "    return plyr.apply(torch.cat, *chunks, _star=False, dim=dim)\n",
    "\n",
    "def split(cache, reset, fragment):\n",
    "    # for each independent env\n",
    "    for j in range(reset.shape[1]):\n",
    "        # find all reset brackets [t0, t1)\n",
    "        t1 = None\n",
    "        for t, flag in enumerate(reset[:, j]):\n",
    "            if not flag:\n",
    "                continue\n",
    "\n",
    "            # get the [t0, t1+1) slice (we include the `t1` reset,\n",
    "            #  since it contains the reward and the lethal action).\n",
    "            t1, t0 = t, t1\n",
    "            tail = plyr.apply(lambda x: x[t0:t1+1, j], fragment)\n",
    "\n",
    "            # stitch the fragments together and flush the cache\n",
    "            yield stitch(*cache[j], tail)\n",
    "            cache[j].clear()\n",
    "\n",
    "        # commit the resudual piece [t1, +oo) to the cache\n",
    "        cache[j].append(plyr.apply(lambda x: x[t1:, j], fragment))\n",
    "\n",
    "class EpisodeExtractor:\n",
    "    def __init__(self):\n",
    "        # `current` contains the contiguous fragments of the current episode\n",
    "        self.cache = defaultdict(list)\n",
    "\n",
    "    def extract(self, reset, fragment):\n",
    "        # the list of ready episode strands\n",
    "        return list(split(self.cache, reset, fragment))\n",
    "\n",
    "    def finish(self):\n",
    "        out = [stitch(*thread) for thread in self.cache.values()]\n",
    "        self.cache.clear()  # this also decrefs the lists in the cache\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28465837",
   "metadata": {},
   "source": [
    "One step in the joint differentiable rollout collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.engine import step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88b7014",
   "metadata": {},
   "source": [
    "Prepare the runtume context for the advantage-actor-critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.engine import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4069b68",
   "metadata": {},
   "source": [
    "A procedure to collect a differentiable rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(env, agent, npyt, hx, *, n_steps, visualize=None):\n",
    "    \"\"\"Collect a fragment of the trajectory.\"\"\"\n",
    "    # (sys) get a view into numpy's observation arrays\n",
    "    vw_vis = None\n",
    "    if visualize is not None:\n",
    "        vw_vis = plyr.apply(plyr.getitem, npyt.npy.obs, index=visualize)\n",
    "\n",
    "    for j in range(n_steps):\n",
    "        if vw_vis is not None:\n",
    "            ipynb_render(vw_vis, clear=True, fps=0.01)\n",
    "\n",
    "        # (sys) get $(x_t, a_{t-1}, r_t, d_t), v_t, \\pi_t$\n",
    "        ignore, hx = out = step(env, agent, npyt, hx)\n",
    "        yield out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75236c1",
   "metadata": {},
   "source": [
    "Compute the policy gradient surrogate, the entropy and other loss components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea31c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.engine import pyt_polgrad\n",
    "\n",
    "from nle_toolbox.utils.rl.engine import pyt_entropy\n",
    "\n",
    "from nle_toolbox.utils.rl.engine import pyt_critic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2ea52",
   "metadata": {},
   "source": [
    "We shall use GAE for polivy gradient advantages and returns for the critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.returns import pyt_ret_gae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1397a",
   "metadata": {},
   "source": [
    "A function to compute the targets (GAE, returns) for policy grads and critic loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c04614",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def pg_targets(rew, val, /, gam, lam, *, fin):\n",
    "    r\"\"\"Compute the targets (GAE, returns) for policy grads and critic loss.\n",
    "\n",
    "    Details\n",
    "    -------\n",
    "    The arguments `rew`, `fin`, and `val` are $r_t$, $d_t$ and $v(s_t)$,\n",
    "    respectively! The td-error terms in GAE depend on $r_{t+1}$, $d_{t+1}$\n",
    "    and on both $v(s_{t+1})$ and $v(s_t)$, hence on `rew[1:]`, `fin[1:]`,\n",
    "    `val[1:]` and `val[:-1]`. `val[-1]` is the value-to-go estimate for\n",
    "    the last state in the related trajectory fragment.\n",
    "    \"\"\"\n",
    "    gae, ret = {}, {}\n",
    "    for k in rew:\n",
    "        ret[k], gae[k] = pyt_ret_gae(\n",
    "            rew[k][1:], fin[1:], val[k],\n",
    "            gam=gam[k], lam=lam[k],\n",
    "        )\n",
    "\n",
    "    return gae, ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5383f",
   "metadata": {},
   "source": [
    "The following network feeds the **obs**ervation $x_t$, **act**ion $a_{t-1}$, and **rew**ard $r_t$ through\n",
    "the provided `features` network, then passes the representatinos into an LSTM core, and finally\n",
    "through value and policy heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15241a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import monotonic_ns\n",
    "\n",
    "from nle_toolbox.utils.nn import multinomial, masked_rnn\n",
    "from nle_toolbox.utils.nn import LinearSplitter, ModuleDict\n",
    "\n",
    "def masked_multinomial(raw, mask, dim=-1):\n",
    "    raw = raw.detach().masked_fill(mask, -float('inf'))\n",
    "    return multinomial(raw.softmax(dim=dim), 1, dim).squeeze(dim)\n",
    "\n",
    "\n",
    "class NLENeuralAgent(nn.Module):\n",
    "    def __init__(self, env, features, *, pol, val, core=None):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "\n",
    "        self.register_parameter('h0', None)\n",
    "\n",
    "        self.core = nn.Identity()\n",
    "        if isinstance(core, dict):\n",
    "            self.core = nn.LSTM(**core)\n",
    "        self.pol = LinearSplitter(**pol)\n",
    "        self.val = LinearSplitter(**val)\n",
    "\n",
    "        self.timings_ns = []  # record simple time-based profiling\n",
    "\n",
    "    def forward(self, obs, act=None, rew=None, hx=None, *, fin=None):\n",
    "        timing_ns = []\n",
    "\n",
    "        obs, mask = obs\n",
    "        timing_ns.append(monotonic_ns())  # base\n",
    "\n",
    "        x = self.features(locals())\n",
    "        timing_ns.append(monotonic_ns())  # features\n",
    "\n",
    "        out, hx = masked_rnn(self.core, x, hx, reset=fin, h0=self.h0)\n",
    "        timing_ns.append(monotonic_ns())  # masked-rnn\n",
    "\n",
    "        # sampling before logsoftmax, because unnormalized logits should be masked\n",
    "        pol = self.pol(out)\n",
    "        act = plyr.apply(masked_multinomial, pol, mask)\n",
    "\n",
    "        try:\n",
    "            return act, (\n",
    "                plyr.suply(torch.squeeze, self.val(out), dim=-1),\n",
    "                plyr.apply(F.log_softmax, pol, dim=-1),\n",
    "            ), hx\n",
    "\n",
    "        finally:\n",
    "            timing_ns.append(monotonic_ns())  # policy and value\n",
    "\n",
    "            T, B = x.shape[:2]\n",
    "            self.timings_ns.append((T, B, tuple(timing_ns)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2709ece",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b592f56",
   "metadata": {},
   "source": [
    "### Redesigning the building blocks of the NLE featrue extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e7595",
   "metadata": {},
   "source": [
    "We simplify the shared glyph embedding layer to rely on glyph entities only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.model.glyph import GlyphEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c74ea",
   "metadata": {},
   "source": [
    "We re-use the original glyph feature extractor layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.model.glyph import GlyphFeatures\n",
    "from einops import rearrange\n",
    "\n",
    "class RestrictedGlyphFeatures(GlyphFeatures):\n",
    "    def __init__(self, glyphs):\n",
    "        super().__init__(glyphs, window=None)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # extract vicinities around the row-col coordinates, specified in bls\n",
    "        gl_vicinity = rearrange(self.glyphs(obs['vicinity']),\n",
    "                                'T B H W C -> T B C H W')\n",
    "        # embed inventory glyphs\n",
    "        # XXX need to replace NO_GLYPH with MAX_GLYPH, unless they coincide.\n",
    "        gl_inventory = rearrange(self.glyphs(obs['inv_glyphs']),\n",
    "                                 'T B N ... -> T B ... N')\n",
    "\n",
    "        return dict(\n",
    "            vicinity=gl_vicinity,\n",
    "            inventory=gl_inventory.contiguous(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4092a",
   "metadata": {},
   "source": [
    "Now let's redo the bottom line stats: vitals first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class BLSHungerEmbedding(nn.Embedding):\n",
    "    from nle_toolbox.utils.env.defs import hunger\n",
    "    from nle.nethack import NLE_BL_HUNGER\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int = 8,\n",
    "        max_norm: Optional[float] = None,\n",
    "        norm_type: float = 2.0,\n",
    "        scale_grad_by_freq: bool = False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            self.hunger.MAX + 1,\n",
    "            embedding_dim,\n",
    "            padding_idx=self.hunger.MAX,\n",
    "            max_norm=max_norm,\n",
    "            norm_type=norm_type,\n",
    "            scale_grad_by_freq=scale_grad_by_freq,\n",
    "            sparse=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        return super().forward(blstats[..., self.NLE_BL_HUNGER])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42127666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.nn import OneHotBits\n",
    "\n",
    "class BLSConditionEmbedding(nn.Module):\n",
    "    from nle_toolbox.utils.env.defs import condition\n",
    "    from nle.nethack import NLE_BL_CONDITION\n",
    "\n",
    "    def __init__(self, embedding_dim: int = 8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.onehot = OneHotBits(self.condition.N_BITS)\n",
    "        self.linear = nn.Linear(self.condition.N_BITS, embedding_dim)\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        return self.linear(self.onehot(blstats[..., self.NLE_BL_CONDITION]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da939d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.nn import EquispacedEmbedding\n",
    "\n",
    "class BLSVitalsEmbedding(EquispacedEmbedding):\n",
    "    from nle.nethack import (\n",
    "        NLE_BL_HP,\n",
    "        NLE_BL_HPMAX,\n",
    "        NLE_BL_ENE,\n",
    "        NLE_BL_ENEMAX,\n",
    "    )\n",
    "\n",
    "    def __init__(self, num_bins: int):\n",
    "        super().__init__(0, 1, num_bins - 1, scale='lin')\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        hp = blstats[..., self.NLE_BL_HP] / blstats[..., self.NLE_BL_HPMAX]\n",
    "        mp = blstats[..., self.NLE_BL_ENE] / blstats[..., self.NLE_BL_ENEMAX]\n",
    "        return torch.cat([\n",
    "            super().forward(torch.nan_to_num_(hp)),\n",
    "            super().forward(torch.nan_to_num_(mp)),\n",
    "        ], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d628d4",
   "metadata": {},
   "source": [
    "Now we redo the stats and build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597127e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSStatsEmbedding(nn.ModuleDict):\n",
    "    from nle.nethack import (\n",
    "        NLE_BL_STR25,\n",
    "        NLE_BL_STR125,\n",
    "        NLE_BL_DEX,\n",
    "        NLE_BL_CON,\n",
    "        NLE_BL_INT,\n",
    "        NLE_BL_WIS,\n",
    "        NLE_BL_CHA,\n",
    "    )\n",
    "\n",
    "    # 6 base stats (luck is hidden) range 0..25\n",
    "    index = {\n",
    "        'str': NLE_BL_STR25,\n",
    "        # 'strprc': NLE_BL_STR125,  # handled manually\n",
    "        'dex': NLE_BL_DEX,\n",
    "        'con': NLE_BL_CON,\n",
    "        'int': NLE_BL_INT,\n",
    "        'wis': NLE_BL_WIS,\n",
    "        'cha': NLE_BL_CHA,\n",
    "    }\n",
    "\n",
    "    def __init__(self, embedding_dim: int = 16):\n",
    "        stats = {k: nn.Embedding(25 + 1, embedding_dim) for k in self.index}\n",
    "\n",
    "        # embedding (adjusted) percentage strength for warrior classes\n",
    "        stats['strprc'] = EquispacedEmbedding(0, 1, embedding_dim-1, scale='lin')\n",
    "        super().__init__(stats)\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        # deal with\n",
    "        #  'strength_percentage',\n",
    "        #  'str', 'dex', 'con', 'int', 'wis', 'cha',\n",
    "        out = []\n",
    "        for k, j in self.index.items():\n",
    "            out.append(self[k](blstats[..., j]))\n",
    "\n",
    "        out.append(self['strprc'](blstats[..., self.NLE_BL_STR125].div(99)))\n",
    "        return torch.cat(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSArmorClassEmbedding(nn.Embedding):\n",
    "    from nle.nethack import NLE_BL_AC\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int,\n",
    "        max_norm: Optional[float] = None,\n",
    "        norm_type: float = 2.0,\n",
    "        scale_grad_by_freq: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            24,  # the AC is mapped to 24 bins by the lookup table below\n",
    "            embedding_dim,\n",
    "            padding_idx=None,  # no padding index,\n",
    "            max_norm=max_norm,\n",
    "            norm_type=norm_type,\n",
    "            scale_grad_by_freq=scale_grad_by_freq,\n",
    "            sparse=False,\n",
    "        )\n",
    "\n",
    "        # a bin lookup table for armor_class, a categorical variable.\n",
    "        self.register_buffer(\n",
    "            'lookup', torch.tensor(\n",
    "                # 0..10 mapped to 11..1, 11..127 to 0\n",
    "                [*reversed(range(1, 12))] + [0] * 117\n",
    "\n",
    "                # 128..244 mapped to 23, 245..256 to 22..12\n",
    "                + [23] * 117 + [*range(22, 11, -1)]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, blstats: torch.Tensor) -> torch.Tensor:\n",
    "        # 'armor_class' in NetHack is descending just like in adnd. In the\n",
    "        # [code](src/do_wear.c#L2107-2153) it appears that AC is confined\n",
    "        # to the range of a `signed char`, however to adnd 2e mechanics it\n",
    "        # is sufficient to consider the range [-10, 10] for the player's AC,\n",
    "        # since we make d20 rolls anyway.\n",
    "        # https://merricb.com/2014/06/08/a-look-at-armour-class-in-original-dd-and-first-edition-add/\n",
    "        # XXX Also, NetHack, just why?! include/hack.h#L499-500\n",
    "        return super().forward(self.lookup[blstats[..., self.NLE_BL_AC]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b02c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSEncumberanceEmbedding(nn.Embedding):\n",
    "    from nle_toolbox.utils.env.defs import encumberance\n",
    "    from nle.nethack import NLE_BL_CAP\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int = 8,\n",
    "        max_norm: Optional[float] = None,\n",
    "        norm_type: float = 2.0,\n",
    "        scale_grad_by_freq: bool = False,\n",
    "    ):\n",
    "        #  'carrying_capacity'\n",
    "        super().__init__(\n",
    "            self.encumberance.MAX + 1,\n",
    "            embedding_dim,\n",
    "            padding_idx=self.encumberance.MAX,\n",
    "            max_norm=max_norm,\n",
    "            norm_type=norm_type,\n",
    "            scale_grad_by_freq=scale_grad_by_freq,\n",
    "            sparse=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        return super().forward(blstats[..., self.NLE_BL_CAP])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b856aef",
   "metadata": {},
   "source": [
    "The following layer puts all the preceding layers together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91894d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# botl stats that were not accounted for.\n",
    "from nle.nethack import (\n",
    "    NLE_BL_X,\n",
    "    NLE_BL_Y,\n",
    "    NLE_BL_SCORE,\n",
    "    NLE_BL_DEPTH,\n",
    "    NLE_BL_GOLD,\n",
    "    NLE_BL_HD,\n",
    "    NLE_BL_XP,\n",
    "    NLE_BL_EXP,\n",
    "    NLE_BL_TIME,\n",
    "    NLE_BL_DNUM,\n",
    "    NLE_BL_DLEVEL,\n",
    ")\n",
    "\n",
    "class BLSEmbedding(nn.ModuleDict):\n",
    "    def __init__(self, **recipe):\n",
    "        super().__init__(dict(\n",
    "            hunger=BLSHungerEmbedding(**recipe['hunger']),\n",
    "            condition=BLSConditionEmbedding(**recipe['condition']),\n",
    "            vitals=BLSVitalsEmbedding(**recipe['vitals']),\n",
    "            stats=BLSStatsEmbedding(**recipe['stats']),\n",
    "            armorclass=BLSArmorClassEmbedding(**recipe['armorclass']),\n",
    "            encumberance=BLSEncumberanceEmbedding(**recipe['encumberance']),\n",
    "        ))\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        return torch.cat([m(blstats) for m in self.values()], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004b57e",
   "metadata": {},
   "source": [
    "Now we put the glyph- and botl- related features in one module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from nle_toolbox.utils.nn import ModuleDict\n",
    "\n",
    "from nle_toolbox.bot.model.vit import ViTEncoder\n",
    "\n",
    "class GlyphViTEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        radius: int,\n",
    "        embedding_dim: int,\n",
    "        num_attention_heads: int,\n",
    "        intermediate_size: int,\n",
    "        head_size:int = None,\n",
    "        dropout: float = 0.0,\n",
    "        *,\n",
    "        n_layers: int = 1,\n",
    "        b_mean: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.extractor = RestrictedGlyphFeatures(\n",
    "            GlyphEmbedding(embedding_dim),\n",
    "            # window=radius,\n",
    "        )\n",
    "\n",
    "        self.vit = ViTEncoder(\n",
    "            radius + 1 + radius,\n",
    "            embedding_dim,\n",
    "            num_attention_heads,\n",
    "            intermediate_size,\n",
    "            head_size=head_size,\n",
    "            dropout=dropout,\n",
    "            n_layers=n_layers,\n",
    "            b_mean=b_mean,\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        patch = self.extractor(obs)['vicinity']\n",
    "\n",
    "        size = dict(zip(\"TBCHW\", patch.shape[:2]))\n",
    "        out, attn = self.vit(rearrange(patch, 'T B ... -> (T B) ...'))\n",
    "        return rearrange(out, '(T B) ... -> T B ...', **size), \\\n",
    "            rearrange(attn, '(T B) ... -> T B ...', **size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e10d9",
   "metadata": {},
   "source": [
    "Layers for slowdown diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9893b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.diagnostics import DiagnosticReLU, collect_relu_death\n",
    "\n",
    "from nle_toolbox.utils.diagnostics import DiagnosticSequential, collect_seq_timings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8970432d",
   "metadata": {},
   "source": [
    "Compute the number of denormals in the parametrs of the given module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.diagnostics import named_denormal_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d16f1",
   "metadata": {},
   "source": [
    "A testbed Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a69484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinear(nn.Linear):\n",
    "    def forward(self, input):\n",
    "        # out = input.matmul(self.weight.T)\n",
    "        # return out if self.bias is None else out.add(self.bias)\n",
    "        return super().forward(input)\n",
    "\n",
    "# a quick unit test\n",
    "lin1 = nn.Linear(32, 45)\n",
    "lin2 = CustomLinear(32, 45)\n",
    "lin2.load_state_dict(lin1.state_dict())\n",
    "\n",
    "x = torch.randn(21, 8, 4, 5, 32)\n",
    "assert torch.allclose(lin2(x), lin1(x),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e202c08",
   "metadata": {},
   "source": [
    "Get the min, median and max of the neurons in the linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec648e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_linear_health(module):\n",
    "    for nom, mod in module.named_modules():\n",
    "        if isinstance(mod, nn.Linear):\n",
    "            # compute the norms\n",
    "            norms = mod.weight.detach().norm(p=2, dim=1)\n",
    "            yield nom, (\n",
    "                float(norms.min()),\n",
    "                float(norms.median()),\n",
    "                float(norms.max()),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91217287",
   "metadata": {},
   "source": [
    "An encoder of glyphs, simpler than ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26525ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "class GlyphSimpleEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        radius: int,\n",
    "        embedding_dim: int,\n",
    "        intermediate_size: int,\n",
    "        dropout: float = 0.0,\n",
    "        **ignore,\n",
    "    ):\n",
    "        n_rows = n_cols = radius + 1 + radius\n",
    "\n",
    "        super().__init__()\n",
    "        self.extractor = RestrictedGlyphFeatures(\n",
    "            GlyphEmbedding(embedding_dim),\n",
    "            # window=radius,\n",
    "        )\n",
    "\n",
    "        self.encoder1 = DiagnosticSequential(\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            Rearrange('B N C -> B (N C)'),\n",
    "        )\n",
    "\n",
    "        self.encoder2 = DiagnosticSequential(\n",
    "            CustomLinear(\n",
    "                (n_rows * n_cols) * embedding_dim,\n",
    "                intermediate_size,\n",
    "                bias=True,\n",
    "            ),\n",
    "            DiagnosticReLU(),\n",
    "            CustomLinear(intermediate_size, intermediate_size, bias=True),\n",
    "            DiagnosticReLU(),\n",
    "        )\n",
    "\n",
    "        self.timings_ns = []  # record simple time-based profiling\n",
    "\n",
    "    def forward(self, obs):\n",
    "        timing_ns = []\n",
    "        timing_ns.append(monotonic_ns())  # base\n",
    "\n",
    "        patch = self.extractor(obs)['vicinity']\n",
    "        timing_ns.append(monotonic_ns())  # extract\n",
    "\n",
    "        size = dict(zip(\"TBCHW\", patch.shape[:2]))\n",
    "        x = rearrange(patch, 'T B C H W -> (T B) (H W) C')\n",
    "        timing_ns.append(monotonic_ns())  # rearrange-1\n",
    "\n",
    "        x = self.encoder1(x)\n",
    "        timing_ns.append(monotonic_ns())  # encode-1\n",
    "\n",
    "        out = self.encoder2(x)\n",
    "        timing_ns.append(monotonic_ns())  # encode-2\n",
    "\n",
    "        out = rearrange(out, '(T B) ... -> T B ...', **size)\n",
    "        timing_ns.append(monotonic_ns())  # rearrange-1\n",
    "\n",
    "        self.timings_ns.append(tuple(timing_ns))\n",
    "\n",
    "        return out, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae782e12",
   "metadata": {},
   "source": [
    "A mutating encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlyphEncoder(nn.Module):\n",
    "    def __new__(cls, kind, **passthrough):\n",
    "        if kind == 'vit':\n",
    "            return GlyphViTEncoder(**passthrough)\n",
    "\n",
    "        if kind == 'simple':\n",
    "            return GlyphSimpleEncoder(**passthrough)\n",
    "\n",
    "        raise RuntimeError(f'Unknown encoder `{kind}`.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12353904",
   "metadata": {},
   "source": [
    "The combined feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLEFeatures(nn.Module):\n",
    "    def __init__(self, glyphs, blstats, **ignore):\n",
    "        super().__init__()\n",
    "\n",
    "        self.glyphs = GlyphEncoder(**glyphs)\n",
    "        self.blstats = BLSEmbedding(**blstats)\n",
    "\n",
    "        self.timings_ns = []  # record simple time-based profiling\n",
    "\n",
    "    def forward(self, obs):\n",
    "        timing_ns = []\n",
    "        timing_ns.append(monotonic_ns())  # base\n",
    "\n",
    "        gl = self.glyphs(obs)[0]\n",
    "        timing_ns.append(monotonic_ns())  # glyph embedding\n",
    "\n",
    "        bls = self.blstats(obs['blstats'])\n",
    "        timing_ns.append(monotonic_ns())  # comprehensve blstats\n",
    "\n",
    "        try:\n",
    "            return torch.cat((gl, bls,), dim=-1)\n",
    "\n",
    "        finally:\n",
    "            timing_ns.append(monotonic_ns())  # cat\n",
    "            self.timings_ns.append(tuple(timing_ns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b98cdb",
   "metadata": {},
   "source": [
    "Create the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32\n",
    "intermediate_size = 512\n",
    "\n",
    "recipe = {\n",
    "    'features': {\n",
    "        'glyphs': {\n",
    "            'kind': 'simple',\n",
    "            # radius is currently hardcoded to be `k=3` in `factory()`\n",
    "            'radius': 3,  # (2 + 1 + 2) * (2 + 1 + 2) * embedding_dim\n",
    "            'embedding_dim': embedding_dim,\n",
    "            'num_attention_heads': 4,\n",
    "            'intermediate_size': intermediate_size,\n",
    "            'head_size': None,\n",
    "            'dropout': 0.0,\n",
    "            'n_layers': 3,\n",
    "            'b_mean': False,\n",
    "        },\n",
    "        'blstats': {\n",
    "            'hunger': {\n",
    "                'embedding_dim': 5,\n",
    "            },\n",
    "            'condition': {\n",
    "                'embedding_dim': 5,\n",
    "            },\n",
    "            'vitals': {\n",
    "                'num_bins': 5,  # * 2\n",
    "            },\n",
    "            'stats': {\n",
    "                'embedding_dim': 5,  # * (6 + 1)\n",
    "            },\n",
    "            'armorclass': {\n",
    "                'embedding_dim': 5,\n",
    "            },\n",
    "            'encumberance': {\n",
    "                'embedding_dim': 5,\n",
    "            },\n",
    "        },  # (4 + 7 + 2) * 5\n",
    "    },\n",
    "    'core': {\n",
    "        'input_size': (4 + 7 + 2) * 5 + intermediate_size,\n",
    "        'hidden_size': 128,\n",
    "        'num_layers': 1,\n",
    "    },\n",
    "    'pol': {\n",
    "        'in_features': 128,\n",
    "        'out_features': 8,  # len(ActionMasker._raw_nethack_actions)\n",
    "    },\n",
    "    'val': {\n",
    "        'in_features': 128,\n",
    "        'out_features': {\n",
    "            'ext': 1,\n",
    "            'int': 1,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8f3c1",
   "metadata": {},
   "source": [
    "The fragmented a2c parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffdb847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project='nle-toolbox',\n",
    "    job_type='nethack',\n",
    "    tags=[\n",
    "        'VicinityWrapper'\n",
    "    ],\n",
    "    # mode='disabled',\n",
    "    config=dict(\n",
    "        # int weight in the gae mix for the polgrads\n",
    "        f_alpha=0.5,\n",
    "\n",
    "        # extrinsic/intrinsic reward PV discount\n",
    "        f_gamma={'ext': 0.999, 'int': 0.99},\n",
    "\n",
    "        # the GAE discount\n",
    "        f_lambda={'ext': 0.96, 'int': 0.96},\n",
    "\n",
    "        # critic (both ext and int) and entropy weights in the loss\n",
    "        C_pg=1.,\n",
    "        C_critic={'ext': 0.5, 'int': 0.5},\n",
    "        C_entropy=0.01,\n",
    "\n",
    "        # the truncated-bptt length rollout\n",
    "        n_fragment_length=20,\n",
    "\n",
    "        # the number of envs run simultaneously\n",
    "        n_batch=8,\n",
    "\n",
    "        # the total number of steps allotted to training (summed across all envs)\n",
    "        n_total=2_592_000 // 5,\n",
    "\n",
    "        # also track the recipe\n",
    "        recipe=recipe,\n",
    "    ),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d43ff",
   "metadata": {},
   "source": [
    "Create the vectorized env and the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0623ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.engine import SerialVecEnv\n",
    "\n",
    "env = SerialVecEnv(factory, n_envs=wandb.config.n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd63e21",
   "metadata": {},
   "source": [
    "Build an agent from the recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nle_toolbox.bot.model.network import NetworkFeatures\n",
    "from collections import OrderedDict\n",
    "\n",
    "agent = NLENeuralAgent(env, **{\n",
    "    **recipe,\n",
    "    'features': ModuleDict({\n",
    "        # XXX ignores kwargs not declared at `__init__`\n",
    "        'obs': NLEFeatures(**recipe['features']),\n",
    "    }, dim=-1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init\n",
    "from nle_toolbox.utils.nn import rnn_reset_bias\n",
    "\n",
    "agent.apply(rnn_reset_bias);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc8da7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f8dd2",
   "metadata": {},
   "source": [
    "Intrinsic motivation via Random Network distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc808030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNDModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        radius: int,\n",
    "        embedding_dim: int,\n",
    "        sizes: list[int],\n",
    "    ):\n",
    "        n_rows = n_cols = radius + 1 + radius\n",
    "\n",
    "        super().__init__()\n",
    "        self.extractor = RestrictedGlyphFeatures(\n",
    "            GlyphEmbedding(embedding_dim),\n",
    "            # window=radius,\n",
    "        )\n",
    "\n",
    "        layers = [\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            Rearrange('B N C -> B (N C)'),\n",
    "            CustomLinear(\n",
    "                (n_rows * n_cols) * embedding_dim,\n",
    "                sizes[0],\n",
    "                bias=True,\n",
    "            ),\n",
    "        ]\n",
    "        for n, m in zip(sizes, sizes[1:]):\n",
    "            layers.append(DiagnosticReLU())\n",
    "            layers.append(CustomLinear(n, m, bias=True))\n",
    "\n",
    "        self.encoder = DiagnosticSequential(*layers)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        patch = self.extractor(obs)['vicinity']\n",
    "        size = dict(zip(\"TBCHW\", patch.shape[:2]))\n",
    "        x = rearrange(patch, 'T B C H W -> (T B) (H W) C')\n",
    "        return rearrange(self.encoder(x), '(T B) ... -> T B ...', **size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1eb51",
   "metadata": {},
   "source": [
    "A clunky tool to split the parameters into baises and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85984142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "def split_parameters(mod, *, recurse=False):\n",
    "    # prioritise descent into disctionary modules\n",
    "    if recurse and isinstance(mod, nn.ModuleDict):  # XXX no recursion protection!\n",
    "        return {nom: split_parameters(sub, recurse=recurse) for nom, sub in mod.items()}\n",
    "\n",
    "    weights, biases = [], []\n",
    "    for nom, par in mod.named_parameters():\n",
    "        (\n",
    "            biases if 'bias' in nom else weights\n",
    "        ).append(par)\n",
    "\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbe708",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = split_parameters(agent)\n",
    "\n",
    "# AdamW doesnt do what you expect it to do, Ivan! (although it\n",
    "#  correctly decouples the objective's grad and the ell-2 weight reg).\n",
    "#  See https://arxiv.org/abs/1711.05101.pdf\n",
    "optim = torch.optim.Adam([\n",
    "    dict(params=weights),\n",
    "    dict(params=biases, weight_decay=0.),\n",
    "], lr=1e-3, eps=1e-5, weight_decay=0.001)\n",
    "\n",
    "# on the other hand, Adam with high `weight_decay` may push many\n",
    "#  parameters' values into denormalized fp mode, which is ultra\n",
    "#  slow on CPU (but not as bad on GPU).\n",
    "# torch.set_flush_denormal(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a27a7",
   "metadata": {},
   "source": [
    "An optimizer for the RND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fa267",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_recipe = {\n",
    "    'radius': 3,  # hardcoded! see `factory()`\n",
    "    'embedding_dim': 32,\n",
    "    'sizes': [256, 64],\n",
    "}\n",
    "\n",
    "rnd = ModuleDict(dict(\n",
    "    target=RNDModule(**rnd_recipe).requires_grad_(False),\n",
    "    online=RNDModule(**rnd_recipe),\n",
    "))\n",
    "\n",
    "# force the same embeddings\n",
    "# with torch.no_grad():\n",
    "#     rnd.online.extractor.glyphs.load_state_dict(\n",
    "#         rnd.target.extractor.glyphs.state_dict()\n",
    "#     )\n",
    "# rnd.online.extractor.glyphs.requires_grad_(False)\n",
    "\n",
    "# rnd.online.load_state_dict(rnd.target.state_dict())\n",
    "\n",
    "weights, biases = split_parameters(rnd.online)\n",
    "rnd.optim = torch.optim.Adam([\n",
    "    dict(params=weights),\n",
    "    dict(params=biases, weight_decay=0.),\n",
    "], lr=1e-3, eps=1e-5, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5529759",
   "metadata": {},
   "source": [
    "Cache the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b764657",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = wandb.config.n_total\n",
    "n_fragment_length = wandb.config.n_fragment_length\n",
    "n_batch = wandb.config.n_batch\n",
    "\n",
    "f_lambda = wandb.config.f_lambda\n",
    "f_gamma = wandb.config.f_gamma\n",
    "f_alpha = wandb.config.f_alpha\n",
    "\n",
    "C_pg = wandb.config.C_pg\n",
    "C_entropy = wandb.config.C_entropy\n",
    "C_critic = wandb.config.C_critic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e0e50",
   "metadata": {},
   "source": [
    "Progress bar update and termination condition checker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587f6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def progress(bar, n):\n",
    "    bar.update(n - bar.n)\n",
    "    return n < bar.total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0561c0dd",
   "metadata": {},
   "source": [
    "a service function to get diagnostic stats from an episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8707e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nle_toolbox.utils.env.defs import MAX_ENTITY\n",
    "\n",
    "\n",
    "def ep_stats(ep):\n",
    "    # episode duration and total score\n",
    "    n_length = len(ep.fin) - int(ep.fin[-1])\n",
    "    f_score = float(ep.rew[1:].sum())\n",
    "\n",
    "    # count the number of unique glyphs seen during the episode\n",
    "    off = -1 if ep.fin[-1] else None  # end-of-episode/reset corrrection\n",
    "    vic = ep.obs[0]['vicinity'][:off]\n",
    "    cnt = torch.bincount(vic.flatten(), minlength=MAX_ENTITY + 1)\n",
    "    n_unique = int(cnt.gt(0).sum())\n",
    "\n",
    "    # compute the entropy of the discrete distribution. This is\n",
    "    #  a good proxy for the diversity, since it measures the amoun\n",
    "    #  of information content the encountered glyphs signal.\n",
    "    proba = cnt.div(cnt.sum())\n",
    "    f_ent = F.kl_div(proba.new_zeros(()), proba, reduction='sum').neg()\n",
    "\n",
    "    return n_length, f_score, n_unique, float(f_ent) / math.log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890182e3",
   "metadata": {},
   "source": [
    "A function to produce unique temporary names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def mkname(folder, *tags, exist_ok=True):\n",
    "    \"\"\"Make a tempalte filename in a specified folder with an optional prefix.\n",
    "    \"\"\"\n",
    "\n",
    "    target = os.path.abspath(folder)\n",
    "    os.makedirs(target, exist_ok=exist_ok)\n",
    "\n",
    "    suffix = '__'.join(map(str, tags))\n",
    "    suffix = ('__' if suffix else '') + suffix\n",
    "    return os.path.join(target, f'{{}}{suffix}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255c949",
   "metadata": {},
   "source": [
    "Load a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67948592",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = mkname('./slowdown')\n",
    "\n",
    "checkpoint = '''IGNORE'''\n",
    "if False:  # True/False?\n",
    "    checkpoint = '''/Users/ivannazarov/Github/repos_with_rl/nle_toolbox/doc/slowdown/ckpt__518400.pt'''\n",
    "    ckpt = torch.load(checkpoint)\n",
    "\n",
    "    print(agent.load_state_dict(ckpt['agent']))\n",
    "    # print(rnd.load_state_dict(ckpt['rnd']))\n",
    "    # print(optim.load_state_dict(ckpt['agent.optim']))\n",
    "    # print(rnd.optim.load_state_dict(ckpt['rnd.optim']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfceb44",
   "metadata": {},
   "source": [
    "learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1f7db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "from time import monotonic_ns\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "timings_ns, agent_norm_records, agent_denorms_records = [], [], []\n",
    "\n",
    "n_steps, epx = 0, EpisodeExtractor()\n",
    "npyt, hx = prepare(env, rew=0., fin=True), None\n",
    "with tqdm.tqdm(\n",
    "    initial=n_steps, total=n_total, ncols=80, disable=False,\n",
    ") as bar:\n",
    "    while progress(bar, n_steps):\n",
    "        timing_ns = []\n",
    "        timing_ns.append(monotonic_ns())  # base\n",
    "\n",
    "        # (sys) collect a fragment of the episode time `t` afterstates, t=0..N-1\n",
    "        fragment, hxx = zip(*collect(\n",
    "            env, agent, npyt, hx, n_steps=n_fragment_length, visualize=None,\n",
    "        ))\n",
    "        timing_ns.append(monotonic_ns())  # collect\n",
    "\n",
    "        # (sys) bootstrap the one-step value-to-go approximation\n",
    "        # XXX do not update `npyt` and `hx`! Also be careful not to\n",
    "        # add this last record to the trajectory!\n",
    "        input = plyr.apply(torch.clone, npyt.pyt)\n",
    "        act_, (val_, pol_), _ = agent(**input._asdict(), hx=hxx[-1])\n",
    "        fragment += ((input, val_, pol_),)\n",
    "\n",
    "        # (sys) repack data ((x_t, a_{t-1}, r^E_t, d_t), v_t, \\pi_t)\n",
    "        input, val, pol = plyr.apply(torch.cat, *fragment, _star=False)\n",
    "        # XXX note, `.act[t]` is $a_{t-1}$, but the other `*[t]` are $*_t$,\n",
    "        #  e.g. `.rew[t]` is $r_t$, and `pol[t]` is `$\\pi_t$.\n",
    "\n",
    "        # (sys) retain running state `hx`, but detach its grads (truncated bptt)\n",
    "        # XXX although val[-1] is used as a non-diffable bootstrap for value-to-go\n",
    "        #  estimate, and pol[-1] does not participates in either policy-grad nor\n",
    "        #  the entropy computation, it is imperative that we DO NOT `.detach` prior\n",
    "        #  to computing these values. Although torch does not backprop through unused\n",
    "        #  tensors, for some reason, it destabilizes a reference implementation.\n",
    "        hx, hx_old = plyr.apply(torch.Tensor.detach, hxx[-1]), hx\n",
    "\n",
    "        # (sys) extract episode strands\n",
    "        # XXX the current `input` overlaps the next one! due to the one-step-ahead bootstrap\n",
    "        episodes = epx.extract(\n",
    "            input.fin[:-1], plyr.apply(lambda t: t[:-1], input)\n",
    "        )\n",
    "\n",
    "        # del fragment, hxx\n",
    "        timing_ns.append(monotonic_ns())  # bootstrap and extract strands\n",
    "\n",
    "        # (rnd) compute the diff-able intrinsic reward\n",
    "        #     r^I_t = \\frac12 \\| f(x_t) - \\bar{f}(x_t) \\|, t=0..N\n",
    "        # XXX we use huber loss and clamp the intinsic rewards to [0, 1]\n",
    "        with torch.no_grad():\n",
    "            rnd_target = rnd.target(input.obs[0])\n",
    "        rnd_mse = F.smooth_l1_loss(\n",
    "            rnd.online(input.obs[0]), rnd_target, reduction='none',\n",
    "        ).sum(-1)\n",
    "        timing_ns.append(monotonic_ns())  # rnd rewards\n",
    "\n",
    "        rew_int = rnd_mse.detach().clamp(max=1)  # torch.zeros_like(input.rew)\n",
    "\n",
    "        # (gae) compute the extrinsic GAE and returns\n",
    "        # XXX `rew`, `fin`, `val` are $r_t$, $d_t$ and $v(s_t)$!\n",
    "        rew = {'ext': input.rew, 'int': rew_int}\n",
    "        gae, ret = pg_targets(rew, val, f_gamma, f_lambda, fin=input.fin)\n",
    "        # XXX had we used `plyr.apply()` we would need to invert the structure\n",
    "\n",
    "        # (sys) policy grad surrogate (uses common gae!)\n",
    "        # XXX r_{t+1}, v_t, v{t+1} -->> A_t \\log \\pi_t(a_t)\n",
    "        adv = gae['ext'].add(gae['int'], alpha=f_alpha).detach()\n",
    "        pg_gae = plyr.apply(pyt_polgrad, pol, input.act, adv=adv)\n",
    "\n",
    "        # (sys) entropy of the policy\n",
    "        # XXX kl-div computes \\sum_n e^{\\log p_n} \\log p_n, so we flip the sign\n",
    "        entropy = plyr.apply(pyt_entropy, pol)\n",
    "\n",
    "        # (sys) extrinsic critic loss\n",
    "        critic = plyr.apply(pyt_critic, val, ret)\n",
    "\n",
    "        # (sys) compute the loss\n",
    "        loss = \\\n",
    "            - pg_gae * C_pg \\\n",
    "            - entropy * C_entropy \\\n",
    "            + critic['ext'] * (C_critic['ext'] / 2) \\\n",
    "            + critic['int'] * (C_critic['int'] / 2)\n",
    "\n",
    "        loss_rnd = rnd_mse.sum() / 2\n",
    "\n",
    "        timing_ns.append(monotonic_ns())  # computing losses\n",
    "\n",
    "        # (sys) backprop through the agent\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = clip_grad_norm_(agent.parameters(), 5.)\n",
    "        optim.step()\n",
    "\n",
    "        # (sys) backprop through the online network of RND\n",
    "        rnd.optim.zero_grad()\n",
    "        loss_rnd.backward()\n",
    "        rnd.optim.step()\n",
    "\n",
    "        timing_ns.append(monotonic_ns())  # backprop and optim\n",
    "\n",
    "        # (sys) incerment the step count\n",
    "        n_steps += n_fragment_length * n_batch\n",
    "\n",
    "        # (log) the training progress\n",
    "        meminfo = psutil.Process().memory_info()\n",
    "        with torch.no_grad():\n",
    "            if episodes:\n",
    "                dur_, ret_, unq_, div_ = \\\n",
    "                    map(np.median, zip(*map(ep_stats, episodes)))\n",
    "                wandb.log({\n",
    "                    'metrics/return': float(ret_),\n",
    "                    'metrics/duration': float(dur_),\n",
    "                    'metrics/n_unique': float(unq_),\n",
    "                    'metrics/diversity': float(div_),\n",
    "                }, commit=False)\n",
    "\n",
    "            wandb.log({\n",
    "                'n_steps': n_steps,\n",
    "                'loss/loss': float(loss),\n",
    "                'loss/ext': float(critic['ext']),\n",
    "                'loss/int': float(critic['int']),\n",
    "                'loss/entropy': float(entropy) / (n_fragment_length * n_batch),\n",
    "                'loss/pg': float(pg_gae),\n",
    "                'loss/rnd': float(loss_rnd),\n",
    "                'sys/rss': meminfo.rss,\n",
    "                'sys/pfaults': meminfo.pfaults,\n",
    "            })\n",
    "            bar.set_postfix_str(f\"{float(loss):.2e} {float(grad):.1e}\")\n",
    "\n",
    "        timing_ns.append(monotonic_ns())  # logging\n",
    "\n",
    "        timings_ns.append(tuple(timing_ns))  # store timings\n",
    "\n",
    "        agent_norm_records.append(dict(collect_linear_health(agent)))\n",
    "        agent_denorms_records.append(dict(named_denormal_stats(agent)))\n",
    "\n",
    "    # (sys) extract episode stands\n",
    "    unfninished = epx.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790bde2",
   "metadata": {},
   "source": [
    "Save the end-of-training checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if checkpoint is None:\n",
    "    checkpoint = template.format(f\"ckpt__{n_steps}\")\n",
    "    torch.save({\n",
    "        'agent': agent.state_dict(),\n",
    "        'agent.optim': optim.state_dict(),\n",
    "        'rnd': rnd.state_dict(),\n",
    "        'rnd.optim': rnd.optim.state_dict(),\n",
    "        # include the last input and the hx used to generate it\n",
    "        'state': (input, hx_old),\n",
    "    }, checkpoint)\n",
    "print(f\"checkpoint = '''{checkpoint}'''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e8094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc; gc.collect(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b44bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.finish(quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc43fd5",
   "metadata": {},
   "source": [
    "### analyzing the timing profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc92cf9",
   "metadata": {},
   "source": [
    "We plot the timings in a unified style using the following procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timing(timings_ns, labels=None):\n",
    "    tot_ms = (timings_ns[:, 1:] - timings_ns[:, :1]) / 1e6\n",
    "    del_ms = (timings_ns[:, 1:] - timings_ns[:, :-1]) / 1e6\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(9, 3), dpi=200)\n",
    "    fig.patch.set_alpha(1.0)\n",
    "\n",
    "    ax[0].plot(tot_ms, label=labels)\n",
    "    ax[0].set_title('cumulative')\n",
    "    ax[0].set_ylabel(r'$\\mu$sec.')\n",
    "    if labels is not None:\n",
    "        ax[0].legend(fontsize='xx-small')\n",
    "\n",
    "    ax[1].plot(del_ms, label=labels)\n",
    "    ax[1].set_title('section')\n",
    "    ax[1].set_yscale('log')\n",
    "    ax[1].set_ylabel(r'$\\mu$sec.')\n",
    "    if labels is not None:\n",
    "        ax[1].legend(fontsize='xx-small')\n",
    "\n",
    "    ax[2].plot(del_ms / tot_ms[:, -1:], label=labels)\n",
    "    ax[2].set_title('share')\n",
    "    ax[2].set_ylabel('%')\n",
    "    if labels is not None:\n",
    "        ax[2].legend(fontsize='xx-small')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b93dbf",
   "metadata": {},
   "source": [
    "Observe that the profile of `del_ms` (time spent in a section) for 'collect'\n",
    "is _almost_ identical to the profile of 'process' (up to a constant shift\n",
    "of `log10(n_fragment_length)` in log-scale). At the same time these sections\n",
    "run essentially identical kernels (except the first runs it `n_fragment_length`\n",
    "times). The cores differ in whether a partial or a full step is performed.\n",
    "A partial step makes a clone of `npyt.pyt` and single-steps through the\n",
    "agent, while a full step additionally steps through the env and updates\n",
    "the `npyt.pyt.act` and `npyt.npy`. Therefore, by comparing the time spent\n",
    "in `agent.forward` with the timing of 'process' and 'collect' (scaled down\n",
    "by `n_fragment_length`) we indirectly learn the following:\n",
    "  1. ('process') the net time spent on cloning `npyt.pyt` (alloc+copy)\n",
    "  2. ('collect') the combined time of `env.step` and `npyt` update\n",
    "\n",
    "Per section timings of `agent.forward` indicate (as expected) that the time\n",
    "spent on `masked_rnn` and policy-value head are roughly constant. Surprisingly,\n",
    "however, the time profile of `features` replicates the overall pattern: it\n",
    "starts at rouhgly consant level and then exhibits elevenfold slowdown at the\n",
    "1.6k iteration mark ($\\div$ by `n_fragment_length`).\n",
    "* could it be the same slowdown bug mentioned in torchbeast and NLE baseline?\n",
    "  * but it was reported as fixed in the related `F.embedding` issue at\n",
    "  torch's [github](https://github.com/pytorch/pytorch/issues/24912)\n",
    "  * this [issue](https://github.com/pytorch/pytorch/issues/20655) appears to\n",
    "  be exactly our case: severely imbalanced token distribution causes backward\n",
    "  slowdown (this also could explain why `backward` section slowd down).\n",
    "* i wonder what those regular spikes in `features` section of `agent.forward` are...\n",
    "  * could they also be realted to that issue?\n",
    "\n",
    "The code below was copied from [`nle/nle/agent/agent.py`](https://github.com/facebookresearch/nle/blob/0c5d66f8902929ba3963d38780a23ff79b72e7e8/nle/agent/agent.py#L829-L833)\n",
    "```python\n",
    "    def _select(self, embed, x):\n",
    "        # Work around slow backward pass of nn.Embedding, see\n",
    "        # https://github.com/pytorch/pytorch/issues/24912\n",
    "        out = embed.weight.index_select(0, x.reshape(-1))\n",
    "        return out.reshape(x.shape + (-1,))\n",
    "```\n",
    "\n",
    "Also note that the loss computation starts to grow linearly around the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f77d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'collect', 'process', 'RND', 'loss', 'backprop', 'log',\n",
    "\n",
    "tim_ns = np.array(timings_ns)\n",
    "# del_ms[:, 0] /= n_fragment_length\n",
    "\n",
    "fig, ax = plot_timing(tim_ns, labels)\n",
    "for a in ax.flat:\n",
    "    a.axvline(192_000 / n_fragment_length / n_batch, c='k', lw=2, zorder=10)\n",
    "    a.axvline(224_000 / n_fragment_length / n_batch, c='k', lw=2, zorder=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eabfdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'features', 'masked-rnn', 'pol-val',\n",
    "\n",
    "# the x-axis in these plots is x `n_fragment_length`\n",
    "T, B, agent_timings_ns = zip(*agent.timings_ns)\n",
    "\n",
    "tim_ns = np.array(agent_timings_ns)\n",
    "\n",
    "fig, ax = plot_timing(tim_ns, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'glyphs', 'blstats', 'cat',\n",
    "\n",
    "# the x-axis in these plots is x `n_fragment_length`\n",
    "tim_ns = np.array(agent.features.obs.timings_ns)\n",
    "\n",
    "fig, ax = plot_timing(tim_ns, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301cde75",
   "metadata": {},
   "source": [
    "Judging from the bin-entropy and the number of unique glyphs per episode, there\n",
    "should be no change in index distribution at around 1.6k mark, that could cause\n",
    "serialization of reduce ops on backward pass. The dynamics burns-in for a little,\n",
    "then levels to some value and continues jittering around it. Futhermore, the\n",
    "slope of `sys/pfauls` and the delta in `sys/rss` do not behave differently to\n",
    "each side of the 192k-224k `n_steps` interval.\n",
    "\n",
    "Thus we decided to dig deeper into `.glyphs` GlyphEmbedding module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'extract', 'rearrange-1', 'encode-1', 'encode-2', 'rearrange-2',\n",
    "\n",
    "# the x-axis in these plots is x `n_fragment_length`\n",
    "tim_ns = np.array(agent.features.obs.glyphs.timings_ns)\n",
    "\n",
    "fig, ax = plot_timing(tim_ns, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02dd122",
   "metadata": {},
   "source": [
    "To our great surprise, we found out that the slowdown comes not from `.extractor`\n",
    "(which does the embedding), but from the `.encoder`  module, which is `nn.Sequential`\n",
    "with an `nn.LayerNorm` and an `einops.torch.Rearrange`, followed by interleaved `nn.Linear`\n",
    "and `nn.ReLU` layers. The output of `nn.Rearrange` is contiguous in memory, so it\n",
    "shouldn't cause a problem for the downstream linear layers.\n",
    "\n",
    "I've isolated the *Layernorm-Rearrange* and the *MLP* blocks, to see which causes\n",
    "delayed performance degradation. I expect it to be the former, since the `nn.Layernorm`\n",
    "is one of the distinct features of this arch, when compared to the Minigrid reference.\n",
    "\n",
    "But, our expectations were subverted as if by a skilled storyteller. It turns\n",
    "out that the slowdown takes splace solely inside the MLP part of the encoder,\n",
    "which has only `nn.Linear` and `nn.ReLU` layers!\n",
    "```text\n",
    "        (encoder2): Sequential(\n",
    "          (0): Linear(in_features=1568, out_features=512, bias=True)\n",
    "          (1): ReLU()\n",
    "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
    "          (3): ReLU()\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631238e6",
   "metadata": {},
   "source": [
    "Since there is no readily available architectural alternative to `nn.Linear`, we\n",
    "decided to change `nn.ReLU` to another activation, especially since `nn.Linear`\n",
    "are the workhorse of deep learning and are implemented using highly efficient\n",
    "numerical code. We expected, however, that replacing the activation should not\n",
    "cause any meaningful change, since `nn.ReLU` is just $x \\mapsto \\max\\{x, 0\\}$ --\n",
    "a very simple and strainghtforward activation. In particular, we considered:\n",
    "  * `nn.GELU` $x \\mapsto x \\Phi(x)$\n",
    "  * `nn.SiLU` $x \\mapsto x \\sigma(x)$\n",
    "  * `nn.LeakyReLU` $x \\mapsto \\max\\{\\alpha x, x\\}$, $\\alpha \\geq 0$.\n",
    "\n",
    "Yet, as [they say](#citation_needed), *\"you should always look in places you\n",
    "would've never looked in the first place\"* or that Murphy's law about \"a constant\n",
    "at the design phase is a variable at application phase\" (is there a better quote?).\n",
    "\n",
    "Changing to `nn.ReLU(inplace=True)` did not improve anything, however switching\n",
    "to `nn.GELU`, which is a more computationally intensive activation, due to\n",
    "the error function inside the Gaussian CDF, or to `nn.LeakyReLU`, elimintated\n",
    "the slowdown.\n",
    "\n",
    "The behaviour of the `sys/*` metrics seems to be independent of either\n",
    "the activation function or whether `optim.step` is run (except for slighly\n",
    "lower mem footprint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6458a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import grad\n",
    "x = torch.linspace(-10, 10, 1001, requires_grad=True)\n",
    "\n",
    "acts = [\n",
    "    F.gelu,\n",
    "    F.softplus,\n",
    "    F.silu,\n",
    "    F.elu,\n",
    "    F.selu,\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(5, 4), dpi=300)\n",
    "for act in acts:\n",
    "    name = fr'\\operatorname{{{act.__name__}}}'\n",
    "    y = act(x)\n",
    "    dy, = grad(y.sum(), x)\n",
    "\n",
    "    ax[0].plot(x.detach(), y.detach(), label=fr'${name}(x)$')\n",
    "    ax[1].plot(x.detach(), dy, label=fr'$\\partial_x \\,{name}(x)$')\n",
    "\n",
    "ax[0].legend(fontsize='xx-small')\n",
    "ax[1].legend(fontsize='xx-small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582eab02",
   "metadata": {},
   "source": [
    "Let's see relu death statistics timings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f70acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_deaths = {\n",
    "    'agent': collect_relu_death(agent),\n",
    "    'rnd': collect_relu_death(rnd),\n",
    "}\n",
    "\n",
    "for module, relu_death in relu_deaths.items():\n",
    "    if not relu_death:\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 2), dpi=300)\n",
    "    for name, dead in relu_death.items():\n",
    "        ax.plot(dead, label=name)\n",
    "    ax.legend(fontsize='xx-small')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5162315",
   "metadata": {},
   "source": [
    "Sequential timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169126c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq_timings = {\n",
    "    'agent': collect_seq_timings(agent),\n",
    "    'rnd': collect_seq_timings(rnd),\n",
    "}\n",
    "\n",
    "for module, seq_timing in seq_timings.items():\n",
    "    if not seq_timing:\n",
    "        continue\n",
    "\n",
    "    for name, (tim_ns, labels) in seq_timing.items():\n",
    "        fig, ax = plot_timing(tim_ns, labels)\n",
    "        fig.suptitle(name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c40f8",
   "metadata": {},
   "source": [
    "To dig deeper we started measuring timings of each layer in `nn.Sequential`\n",
    "containers, and learned that in fact the slowdown occurs in the linear layer.\n",
    "For some reason `nn.ReLU` interferes with `nn.Linear` resulting in its drammatic\n",
    "slowdown if `optim.step` is used. Death diagnostics of the `nn.ReLU` output does\n",
    "not show exceptinally high rates of sparsity (around 80-90\\%) and the rate is\n",
    "stable around the slowdown mark. Investigating layers' output's `.mean` and `.std`\n",
    "in `nn.Sequential` did not yield any meaningful insights. Using manual matmul\n",
    "implementation of `nn.Linear` had no effect either (unlikely, but `F.linear`\n",
    "might use alternative paths in torch's linear algebra routines).\n",
    "\n",
    "So what have we got:\n",
    "> the slowdown takes place in compute-heavy linear layers (`F.linear` or\n",
    "`.matmul.add` has no effect), when the activation is sparse (`nn.ReLU` as\n",
    "opposed to `LeakyReLU`) and when SGD updates the weights (whether `optim.step()`\n",
    "is run).\n",
    "\n",
    "The next step is to check the \"health\" of linear layers. Again, it does not\n",
    "manifest any odd patterns around the 1.6k mark. Their median slowly decays\n",
    "to a near zero value.\n",
    "\n",
    "Let's see if its the weights of the model (which would make little sense), or\n",
    "some runtime effect. To this end we save the checkpoint from a slowed down run\n",
    "and then start a new run having loaded it into the models and optimizers.\n",
    "I turns out that loading **just the agent** from the checkpoint is enough to\n",
    "slow down, which means that the weights are indeed somehow bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231aaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_health = plyr.apply(np.array, *agent_norm_records, _star=False)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 2), dpi=300)\n",
    "for name, (mins, meds, maxs) in lin_health.items():\n",
    "    ax.semilogy(mins, label=name)\n",
    "\n",
    "ax.legend(fontsize='xx-small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed44ea2",
   "metadata": {},
   "source": [
    "Quickly googling `pytorch weights training slow down` revealed that it is possible\n",
    "that the slowdown could be casued by denormalized floats on some fp architectures.\n",
    "* [this post](https://discuss.pytorch.org/t/speed-of-training-slowdown-with-each-epoch/13125/2)\n",
    "show a very similar timing pattern\n",
    "* and [here](https://discuss.pytorch.org/t/conv2d-is-very-slow-on-trained-weights-vs-random-weights/43377/2)\n",
    "it is explained that fp-ops with denormal floats on CPU are usually very inefficient\n",
    "and it is suggested that either the tensors be clamped to zero, or\n",
    "`torch.set_flush_denormal(True)` be added before the loop. However, a better\n",
    "solution might be to\n",
    "> ... to find out why your training ended up with such weird weights, and fix it!\n",
    "* and, finally, this [SO answer](https://stackoverflow.com/questions/36781881/why-denormalized-floats-are-so-much-slower-than-other-floats-from-hardware-arch) explains what goues on in FPU microcode\n",
    "denormals are floats that are **so close** as to have their exponent equal to a special\n",
    "non-inf value, which indicats that there is no implicit one, and the real is given by `0.b...b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9766a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_health = plyr.apply(np.array, *agent_denorms_records, _star=False)\n",
    "\n",
    "n_den, n_tot = map(sum, zip(*par_health.values()))\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 2), dpi=300)\n",
    "ax.plot(n_den / n_tot, label='total')\n",
    "ax.set_title(\"The share of denormals in the models' parameters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baed084",
   "metadata": {},
   "source": [
    "So what can we do:\n",
    "1. use `AdamW` instead of `Adam`, since the former decays weights more softly\n",
    "and appears to have superiror theoretical grounding (essentially, `Adam` should\n",
    "be used as an adaptive grad estimator of the loss term, not the regularizer)\n",
    "2. avoid high weight-decay in `Adam`\n",
    "3. use a non-sparse activation\n",
    "  * what if other activations suffer from the same issue, just at much larger\n",
    "  time scale? the current 500k iterations might not be enough to capture thie\n",
    "  \"eventual slowdown\"...\n",
    "4. use `torch.set_flush_denormal(True)`, which conceals the problem rather\n",
    "than solving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a774a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95345e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce1f33",
   "metadata": {},
   "source": [
    "A ranked buffer for episode rollouts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0fc1de",
   "metadata": {},
   "source": [
    "* what do we do with the missing `hx`? clone episodes in full?\n",
    "  * `you wake up on a cold stone floor in the middle of a vast chamber without a shred of memoery of how you got here. What do you do?` maybe it is OK to take contiguous fragments of a long episode and start with a wiped out memory.\n",
    "* do we clone just the actions, or also the value function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a3392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heapreplace, heappushpop, heappush, heappop\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "\n",
    "class RankedBuffer:\n",
    "    @dataclass(order=True, frozen=True, repr=False)\n",
    "    class RankedItem:\n",
    "        rank: float\n",
    "        item: Any = field(compare=False)\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = []\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def push(self, rk, it):\n",
    "        item = self.RankedItem(rk, it)\n",
    "        # push the current item\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            return heappush(self.buffer, item)\n",
    "        # ... pop the lowest-ranking one, if we exceed capacity\n",
    "        return heappushpop(self.buffer, item)\n",
    "\n",
    "    def extend(self, pairs):\n",
    "        last = None\n",
    "        for rk, it in pairs:\n",
    "            last = self.push(rk, it)\n",
    "        return last\n",
    "\n",
    "    def __bool__(self):\n",
    "        return bool(self.buffer)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.buffer[index]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return type(self).__name__ + f\"({len(self.buffer)}/{self.capacity})\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        return ((el.rank, el.item) for el in self.buffer)\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        n_samples=8,\n",
    "        n_steps=64,\n",
    "        *,\n",
    "        rng=np.random.default_rng(),\n",
    "    ):\n",
    "        # determinie the sufficiently long episodes\n",
    "        eligible = []\n",
    "        for j, ep in enumerate(self.buffer):\n",
    "            input, val, pol = ep.item\n",
    "            dur_ = len(input.fin) - int(input.fin[-1])\n",
    "            if dur_ < n_steps:\n",
    "                continue\n",
    "\n",
    "            eligible.append((j, dur_,))\n",
    "\n",
    "        # sample starting strands from episodes\n",
    "        chunks = []\n",
    "        for i in rng.choice(len(eligible), size=n_samples):\n",
    "            k, dur_ = eligible[i]\n",
    "            j = rng.integers(dur_ - n_steps + 1)\n",
    "\n",
    "            chunk = plyr.apply(lambda t: t[j:j + n_steps],\n",
    "                               self.buffer[k].item)\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        return plyr.apply(torch.stack, *chunks, _star=False, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c474ee9",
   "metadata": {},
   "source": [
    "A procedure to get the likelihood of actions uder a given policy sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ac259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.returns import pyt_vtrace\n",
    "\n",
    "def logpact(logpol, act):\n",
    "    # (sys) get \\log\\mu_t(a_t) from `logpol[t][act[t+1]])`, t=0..T-1\n",
    "    return logpol[:-1].gather(-1, act[1:].unsqueeze(-1)).squeeze_(-1)\n",
    "\n",
    "def td_target(rew, fin, val, *, gam):\n",
    "    # add extra trailing unitary dims for broadcasting\n",
    "    fin_ = fin.reshape(fin.shape + (1,) * max(rew.ndim - fin.ndim, 0))\n",
    "    gam_ = rew.new_full(fin_.shape, gam).masked_fill_(fin_, 0.)\n",
    "    return torch.addcmul(rew, gam_, val[1:])\n",
    "\n",
    "@torch.no_grad()\n",
    "def pyt_impala(rew, fin, act, val, pol, myuval, myupol, *, gam, r_bar, c_bar):\n",
    "    rho = logpact(pol, act) - logpact(myupol, act)\n",
    "    vtr = pyt_vtrace(rew[1:], fin[1:], myuval, rho=rho,\n",
    "                     gam=gam, r_bar=r_bar, c_bar=c_bar)\n",
    "\n",
    "    # [O(T B F)] get the importance-weighted td(0) errors\n",
    "    adv = td_target(rew[1:], fin[1:], vtr, gam=gam)\n",
    "    rho_ = rho.reshape(rho.shape + (1,) * max(rew.ndim - fin.ndim, 0))\n",
    "    rho_.exp_().clamp_(max=r_bar)\n",
    "    adv.sub_(val[:-1]).mul_(rho_)\n",
    "\n",
    "    return vtr[:-1], adv, rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b2124",
   "metadata": {},
   "source": [
    "Compute the exploration metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65435df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle.nethack import NLE_BL_SCORE\n",
    "from nle_toolbox.utils.env.defs import GLYPH_CMAP_OFF, symbol\n",
    "\n",
    "def ep_metrics(ep, *, S_stone=symbol.S_stone + GLYPH_CMAP_OFF):\n",
    "    met = {}\n",
    "\n",
    "    # convert to numpy and determine the offset for unfinished episodes\n",
    "    npy = plyr.apply(np.asarray, ep)\n",
    "    off = int(npy.fin[-1])\n",
    "    if len(npy.fin) <= off:\n",
    "        return met\n",
    "\n",
    "    obs, msk = npy.obs\n",
    "\n",
    "    # score the episode\n",
    "    met['ret'] = float(npy.rew[1:].sum())\n",
    "    met['scr'] = obs['blstats'][-1-off, NLE_BL_SCORE]\n",
    "\n",
    "    # coverage and action effectiveness\n",
    "    gly = obs['glyphs'][:(-1 if off > 0 else None)]\n",
    "    # XXX we exclude the terminal obs, because it is actually the init\n",
    "    #  obs from the next episode\n",
    "    non_stone = (gly != S_stone).mean((-2, -1))\n",
    "    met['cov'] = non_stone.max() / non_stone.min()\n",
    "    met['eff'] = sum((g0 != g1).mean() for g0, g1 in zip(gly, gly[1:]))\n",
    "\n",
    "    met['len'] = len(npy.fin) - off\n",
    "\n",
    "    return met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581980a",
   "metadata": {},
   "source": [
    "Rank the peisode and put it into a buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_episodes(buf, iterable):\n",
    "    for input, val, pol in iterable:\n",
    "        met = ep_metrics(input)\n",
    "        if not met:\n",
    "            continue\n",
    "\n",
    "        rk = met['ret'] + 0.1 * met['cov'] / met['len']\n",
    "        buf.push(rk, (input, val, pol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb692ae",
   "metadata": {},
   "source": [
    "A visualized evaluation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SerialVecEnv(factory, n_envs=4)\n",
    "epx, buf = EpisodeExtractor(), RankedBuffer(128)\n",
    "\n",
    "n_total = 16384\n",
    "n_steps, visualize = 0, None\n",
    "\n",
    "npyt, hx = prepare(env, rew=0., fin=True), None\n",
    "while n_steps < n_total:\n",
    "    with torch.no_grad():\n",
    "        # (sys) collect a fragment of the episode time `t` afterstates, t=0..N-1\n",
    "        fragment, hxx = zip(*collect(env, agent, npyt, hx, n_steps=128, visualize=visualize))\n",
    "        # XXX `fragment` is ((x_t, a_{t-1}, r_t, d_t), v_t, \\mu_t), t=0..N-1\n",
    "\n",
    "        # (sys) retain running state `hx`, but detach its grads (truncated bptt)\n",
    "        # ATTN do not update `npyt` and `hx`!\n",
    "        hx = plyr.apply(torch.Tensor.detach, hxx[-1])\n",
    "\n",
    "    # (sys) repack the fragment data\n",
    "    # XXX note, `.act[t]` is $a_{t-1}$, but the other `*[t]` are $*_t$,\n",
    "    #  e.g. `.rew[t]` is $r_t$, and `pol[t]` is `$\\pi_t$.\n",
    "    input, _, _ = fragment = plyr.apply(torch.cat, *fragment, _star=False)\n",
    "\n",
    "    # (sys) incerment the step count\n",
    "    n_steps += input.fin.numel()\n",
    "\n",
    "    # (sys) extract episode stands with log-probs of the taken actions\n",
    "    add_episodes(buf, epx.extract(input.fin, fragment))\n",
    "\n",
    "# (sys) extract episode stands\n",
    "add_episodes(buf, epx.finish())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83057d58",
   "metadata": {},
   "source": [
    "The stats of the episodes in the buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac750ab7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "out, fps = [], None\n",
    "for rk, (input, val, pol) in buf:\n",
    "    npy = plyr.apply(np.asarray, input)\n",
    "    off = int(npy.fin[-1])  # offset for unfinished strands\n",
    "    for t in range(len(npy.fin) - off):\n",
    "        obs = plyr.apply(plyr.getitem, npy.obs, index=t)\n",
    "        ipynb_render(obs, fps=fps)\n",
    "\n",
    "    met = ep_metrics(input)\n",
    "    if met:\n",
    "        out.append(met)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 3), dpi=300)\n",
    "\n",
    "out_ = plyr.apply(list, *out, _star=False)\n",
    "for ax, (nom, val) in zip(axes.flat, out_.items()):\n",
    "    ax.hist(val, label=nom, log=nom in ('scr', 'ret',), bins=20)\n",
    "    ax.set_title(nom)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac996af",
   "metadata": {},
   "source": [
    "Behaviour cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbffca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_steps = 8, 128\n",
    "r_bar, c_bar = 1.01, 1.1\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "losses = []\n",
    "for k in tqdm.tqdm(range(50), ncols=70):\n",
    "    input, myuval, myupol = buf.sample(n_samples, n_steps, rng=rng)\n",
    "\n",
    "    # recompute the policy and value-to-go estimates for the episode\n",
    "    _, (val, pol), _ = agent(input.obs, input.act, input.rew, hx=None, fin=None)\n",
    "    # XXX this is not EXACTLY identical to `fin=ep_.fin`, which is guaranteed\n",
    "    #  to contain a reset `fin[0]` and possibly a `fin[-1]` (not in case when\n",
    "    #  the episode is unfinished). We ignore pol[-1] $\\pi_{T}$ and val[-1]\n",
    "    #  $v(s_{T})$, both of which pertain to the next episode. `fin` affects\n",
    "    #  only the recurrrent state anyway and 1) we set the initial to `None`,\n",
    "    #  and 2) do not ever use the\n",
    "\n",
    "    # get the v-trace target for the critic and the advantages to pol-grad\n",
    "    # XXX here `.fin[-1]` properly blocks the last state-value backup\n",
    "    ret, _, rho = pyt_impala(\n",
    "        input.rew, input.fin, input.act,\n",
    "        val['ext'], pol, myuval['ext'], myupol,\n",
    "        gam=f_gamma['ext'], r_bar=r_bar, c_bar=c_bar\n",
    "    )\n",
    "\n",
    "    L_loglik = pyt_polgrad(pol, input.act, adv=1.)\n",
    "    L_critic = pyt_critic(val['ext'], ret)\n",
    "\n",
    "    ell = (L_critic * (C_critic['ext'] / 2) - L_loglik)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    ell.backward()\n",
    "    optim.step()\n",
    "\n",
    "    losses.append(float(ell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e323d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ef74e61",
   "metadata": {},
   "source": [
    "import pdb ; pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plyr.ragged(lambda v, C: C * v.sum(), pg, C_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = []\n",
    "plyr.ragged(lambda v, C: flat.append(C * v), pg_gae, C_pg)\n",
    "plyr.ragged(lambda v, C: flat.append(C * v), entropy, C_entropy)\n",
    "plyr.ragged(lambda v, C: flat.append(C * v), critic, C_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4529833",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eeb387",
   "metadata": {},
   "source": [
    "Remove currently unused fileds from the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4addd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.env.defs import MAX_GLYPH\n",
    "\n",
    "def filter(\n",
    "    glyphs,\n",
    "    blstats,\n",
    "    inv_letters,\n",
    "    inv_glyphs,\n",
    "    **ignore,\n",
    "):\n",
    "    return dict(\n",
    "        glyphs=glyphs,\n",
    "        blstats=blstats,\n",
    "        inv_letters=inv_letters,\n",
    "        inv_glyphs=inv_glyphs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f5491bf",
   "metadata": {},
   "source": [
    "import pdb; pdb.pm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a5837b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff75f63a",
   "metadata": {},
   "source": [
    "     y  k  u  \n",
    "      \\ | /   \n",
    "    h - . - l \n",
    "      / | \\   \n",
    "     b  j  n  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92540bc",
   "metadata": {},
   "source": [
    "Spell tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2268d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcaster(obs, mask, *, dir='.', ctoa):\n",
    "    yield from map(ctoa.get, f'Z{letter}{dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa03612",
   "metadata": {},
   "source": [
    "Random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linger(obs, mask, n=16, *, seed=None, ctoa=None):\n",
    "    rng, j = np.random.default_rng(seed), 0\n",
    "    while not mask.all() and j < n:\n",
    "        # if we're in LINGER state, pick a random non-forbidden action\n",
    "        # XXX whelp... tilde on int8 is `two's complement`, not the `logical not`\n",
    "        act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "\n",
    "        obs, mask = (yield act)\n",
    "        j += 1\n",
    "\n",
    "def search(obs, mask, n=6, *, ctoa):\n",
    "    yield from map(ctoa.get, f'{n:d}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63591f12",
   "metadata": {},
   "source": [
    "Level and dungeon mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb66165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle.nethack import (\n",
    "    NLE_BL_X,\n",
    "    NLE_BL_Y,\n",
    "    NLE_BL_DNUM,\n",
    "    NLE_BL_DLEVEL,\n",
    "    # NLE_BL_DEPTH,  # derived from DNUM and DLEVEL\n",
    "    # XXX does not uniquely identify floors,\n",
    "    #  c.f. [`depth`](./nle/src/dungeon.c#L1086-1084)\n",
    "    DUNGEON_SHAPE,\n",
    "    MAX_GLYPH,\n",
    ")\n",
    "\n",
    "from nle_toolbox.utils.env.defs import \\\n",
    "    glyph_is, dt_glyph_ext, ext_glyphlut\n",
    "\n",
    "from nle_toolbox.bot.level import Level, DungeonMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198a3d5",
   "metadata": {},
   "source": [
    "Detemine the walkability of the observed tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.env.defs import symbol, GLYPH_CMAP_OFF, glyph_group, get_group\n",
    "from nle_toolbox.utils.env.defs import glyphlut, ext_glyphlut\n",
    "\n",
    "closed_doors = get_group(symbol, GLYPH_CMAP_OFF, *[\n",
    "    'S_vcdoor', 'S_hcdoor',\n",
    "    'S_vcdbridge', 'S_hcdbridge',\n",
    "])\n",
    "\n",
    "open_doors = get_group(symbol, GLYPH_CMAP_OFF, *[\n",
    "    'S_ndoor',\n",
    "    'S_vodoor', 'S_hodoor',\n",
    "    'S_vodbridge', 'S_hodbridge',\n",
    "])\n",
    "\n",
    "is_closed_door = np.isin(ext_glyphlut.id.value, np.array(list(closed_doors)))\n",
    "is_actor = np.isin(ext_glyphlut.id.group, np.array(list(glyph_group.ACTORS)))\n",
    "is_pet = ext_glyphlut.id.group == glyph_group.PET\n",
    "\n",
    "is_open_door = np.isin(ext_glyphlut.id.value, np.array(list(open_doors)))\n",
    "is_object = np.isin(ext_glyphlut.id.group, np.asarray(list(glyph_group.OBJECTS)))\n",
    "is_walkable = ext_glyphlut.is_accessible | is_open_door | is_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d80dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "traps = get_group(symbol, GLYPH_CMAP_OFF, *[\n",
    "    'S_arrow_trap',\n",
    "    'S_dart_trap',\n",
    "    'S_falling_rock_trap',\n",
    "    'S_squeaky_board',\n",
    "    'S_bear_trap',\n",
    "    'S_land_mine',\n",
    "    'S_rolling_boulder_trap',\n",
    "    'S_sleeping_gas_trap',\n",
    "    'S_rust_trap',\n",
    "    'S_fire_trap',\n",
    "    'S_pit',\n",
    "    'S_spiked_pit',\n",
    "    'S_hole',\n",
    "    'S_trap_door',\n",
    "    'S_teleportation_trap',\n",
    "    'S_level_teleporter',\n",
    "    'S_magic_portal',\n",
    "    'S_web',\n",
    "    'S_statue_trap',\n",
    "    'S_magic_trap',\n",
    "    'S_anti_magic_trap',\n",
    "    'S_polymorph_trap',\n",
    "    'S_vibrating_square',\n",
    "])\n",
    "\n",
    "is_trap = np.isin(ext_glyphlut.id.value, np.array(list(traps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177664e",
   "metadata": {},
   "source": [
    "The core of the \"smart\" dungeon explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b17319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def crawler(obs, mask, *, dir, seed=None):\n",
    "    dng = DungeonMapper()\n",
    "\n",
    "    # own random number generator\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # a simple state machine: linger <<-->> crawler\n",
    "    state, n_linger, stack = 'linger', 16, []\n",
    "    while True:\n",
    "        dng.update(obs)\n",
    "        pos = dng.level.trace[-1]\n",
    "\n",
    "        if state == 'crawl':\n",
    "            if stack:\n",
    "                plan.pop()\n",
    "                act = dir[stack.pop()]\n",
    "\n",
    "            else:\n",
    "                state, n_linger = 'linger', 16\n",
    "                continue\n",
    "\n",
    "        elif state == 'linger':\n",
    "            if n_linger > 0:\n",
    "                n_linger -= 1\n",
    "\n",
    "                # if we're in LINGER state, pick a random non-forbidden action\n",
    "                # XXX whelp... tilde on int8 is `two's complement`, not the `logical not`\n",
    "                act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "\n",
    "            else:\n",
    "                lvl = dng.level\n",
    "\n",
    "                # we've run out linger moves, time to pick a random destination\n",
    "                # and go to it\n",
    "                state = 'crawl'\n",
    "\n",
    "                # get the walkability cost\n",
    "                cost = np.where(\n",
    "                    # is_walkable[lvl.bg_tiles.glyph]\n",
    "                    (is_walkable | is_pet)[lvl.bg_tiles.glyph]\n",
    "                    , .334, np.inf)\n",
    "                # XXX adjust `cost` for hard-to-pass objects?\n",
    "                cost[is_trap[lvl.bg_tiles.glyph]] = 10.\n",
    "\n",
    "                # get the shortest paths from the current position\n",
    "                value, path = dij(cost, pos)\n",
    "\n",
    "                # draw a destination, the further the better\n",
    "                prob = softmax(np.where(\n",
    "                    is_closed_door[lvl.bg_tiles.glyph],\n",
    "                    100.,\n",
    "                    np.where(\n",
    "                        np.logical_and(\n",
    "                            np.isfinite(value),\n",
    "                            np.logical_not(\n",
    "                                is_trap[lvl.bg_tiles.glyph]\n",
    "                            )\n",
    "                        ), value, -np.inf\n",
    "                    ))\n",
    "                )\n",
    "                dest = divmod(rng.choice(prob.size, p=prob.flat), prob.shape[1])\n",
    "\n",
    "                # reconstruct the path to the destination in reverse order\n",
    "                plan = list(backup(path, dest))\n",
    "                for (r1, c1), (r0, c0) in zip(plan, plan[1:]):\n",
    "                    stack.append(dir_to_ascii[r1-r0, c1-c0])\n",
    "\n",
    "                plan.pop()\n",
    "                continue\n",
    "\n",
    "        obs, mask = yield act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ec111",
   "metadata": {},
   "source": [
    "How do we want to explore?\n",
    "* open closed doors\n",
    "* explore tunnels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83512a48",
   "metadata": {},
   "source": [
    "Implementing the random dungeon crwaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c40bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dng = getgeneratorlocals(gen).get('dng')\n",
    "# dng.level.trace[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dng.level.bg_tiles.info.is_accessible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f588a",
   "metadata": {},
   "source": [
    "     y  k  u  \n",
    "      \\ | /   \n",
    "    h - . - l \n",
    "      / | \\   \n",
    "     b  j  n  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the walkability cost\n",
    "cost = np.where((\n",
    "    is_walkable\n",
    "    | is_pet\n",
    ")[obs['glyphs']], 1., np.inf)\n",
    "# XXX adjust `cost` for hard-to-pass objects?\n",
    "cost[is_trap[obs['glyphs']]] = 10.\n",
    "\n",
    "# get shroteste paths from the current position\n",
    "bls = obs['blstats']\n",
    "value, path = dij(cost, (bls[NLE_BL_Y], bls[NLE_BL_X]))\n",
    "\n",
    "prob = softmax(np.where(\n",
    "    np.logical_and(\n",
    "        np.isfinite(value),\n",
    "        np.logical_not(\n",
    "            is_trap[obs['glyphs']]\n",
    "        )\n",
    "    ), value, -np.inf\n",
    "))\n",
    "\n",
    "plt.imshow(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab898e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6bc4b",
   "metadata": {},
   "source": [
    "Test the algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 12, 12\n",
    "\n",
    "rng = np.random.default_rng()  #248675)\n",
    "\n",
    "cost = -np.log(rng.random((21, 79)))\n",
    "# cost = np.ones((21, 79))\n",
    "cost[rng.random(cost.shape) < .5] = np.inf\n",
    "\n",
    "value, path = dij(cost, (r, c))\n",
    "\n",
    "\n",
    "# mask = is_walkable[lvl.bg_tiles.glyph] | is_walkable[lvl.stg_tiles.glyph]\n",
    "mask = np.isfinite(value)\n",
    "mask[r, c] = False  # mask the current position\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "value = np.where(value > 5, 0., -np.inf)\n",
    "prob = softmax(np.where(mask, value, -np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841157d1",
   "metadata": {},
   "source": [
    "Play around with the shortes path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = divmod(rng.choice(prob.size, p=prob.flat, ), prob.shape[1])\n",
    "\n",
    "displ = cost.copy()\n",
    "plan = list(backup(path, (r, c)))\n",
    "for ij in plan:\n",
    "    displ[ij] = 10\n",
    "displ[12, 12] = 11\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=300)\n",
    "ax.imshow(displ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = []\n",
    "for (r1, c1), (r0, c0) in zip(plan, plan[1:]):\n",
    "    commands.append(dir_to_ascii[r1-r0, c1-c0])\n",
    "\n",
    "''.join(reversed(commands))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d5208",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c03a68",
   "metadata": {},
   "source": [
    "A non-illegal random action exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from nle_toolbox.bot.chassis import get_wrapper\n",
    "\n",
    "\n",
    "def random_explore(seed=None, n_steps=1000, *, auto=False, fps=None, copy=False):\n",
    "    \"\"\"A non-illegal random action explorer.\n",
    "    \"\"\"\n",
    "    ss_pol, ss_env = np.random.SeedSequence(seed).spawn(2)\n",
    "\n",
    "    rng, j, n_linger, pf = np.random.default_rng(ss_pol), 0, 0, None\n",
    "    with factory(seed=ss_env) as env:\n",
    "        # we need access to the Chassis for additional meta state variables\n",
    "        cha = get_wrapper(env, Chassis)\n",
    "\n",
    "        # ActionMasker caches the esacpe action id\n",
    "        ESC = get_wrapper(env, ActionMasker).escape\n",
    "\n",
    "        # setup the dungeon mapper\n",
    "        dng = DungeonMapper()\n",
    "\n",
    "        # launch the episode\n",
    "        (obs, mask), fin = env.reset(), False\n",
    "        while (\n",
    "            ipynb_render(obs, clear=True, fps=fps)\n",
    "            and not (fin or j >= n_steps)\n",
    "        ):\n",
    "            # though nle reuses buffers, we do not deep copy them\n",
    "            #  delegating this to the downstream user instead\n",
    "            yield deepcopy(obs) if copy else obs\n",
    "\n",
    "            # default to immediately escaping from any menu or prompt\n",
    "            act = ESC\n",
    "            if not (cha.in_menu or cha.prompt):\n",
    "                dng.update(obs)\n",
    "\n",
    "                # if we're in LINGER state, pick a random non-forbidden action\n",
    "                # XXX whelp... tilde on int8 is `two's complement`, not the `logical not`\n",
    "                act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "\n",
    "            (obs, mask), rew, fin, info = env.step(act)\n",
    "            j += 1\n",
    "\n",
    "            if fin and auto:\n",
    "                ipynb_render(obs, clear=True, fps=fps)\n",
    "                (obs, mask), fin = env.reset(), False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f035ca",
   "metadata": {},
   "source": [
    "Get a random episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inspect import getgeneratorlocals\n",
    "episode = random_explore(\n",
    "    seed=None,\n",
    "    n_steps=256,\n",
    "    auto=False,\n",
    "    copy=True,\n",
    "    fps=0.01,\n",
    ")\n",
    "\n",
    "\n",
    "glyphs = [next(episode)]\n",
    "# dng = getgeneratorlocals(episode).get('dng')\n",
    "\n",
    "glyphs.extend(obs['glyphs'] for obs in episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def dstination_prob(lvl, pos):\n",
    "    r, c = pos\n",
    "    dist = np.maximum(abs(lvl.bg_tiles.rc.r - r), abs(lvl.bg_tiles.rc.c - c))\n",
    "\n",
    "    mask = is_walkable[lvl.bg_tiles.glyph] | is_walkable[lvl.stg_tiles.glyph]\n",
    "    mask[r, c] = False  # mask the current position\n",
    "    return softmax(np.minimum(np.where(mask, dist, -np.inf), 5))\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "prob = dstination_prob(dng.level, dng.level.trace[-1])\n",
    "cost = np.where(prob > 0, 1., float('inf'))\n",
    "\n",
    "plt.imshow(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup(path, dest):\n",
    "    p0 = dest\n",
    "    while True:\n",
    "        p0, p1 = path[p0], p0\n",
    "        yield p1\n",
    "        if p0 is None:\n",
    "            return\n",
    "\n",
    "#         (r0, c0), (r1, c1) = p0, p1\n",
    "#         yield directions[r1-r0, c1-c0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "value, path = dij(cost, dng.level.trace[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa36671",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = value.copy()\n",
    "r, c = rng.choice(dng.level.bg_tiles.rc.flat, p=prob.flat)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=300)\n",
    "for i, j in backup(path, (r, c)):\n",
    "    val[i, j] = 0.\n",
    "\n",
    "val[r, c] = np.inf\n",
    "\n",
    "ax.imshow(val[:, 10:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccdf31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31756f0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3da9480",
   "metadata": {},
   "source": [
    "from nle_toolbox.bot.chassis import get_wrapper\n",
    "\n",
    "def pathfinder(env, obs, seed=None):\n",
    "    # pick a random destination and lay a shortest path to it\n",
    "    path = deque(path_to(uxy, dst))\n",
    "\n",
    "    while path and reachable(uxy, path):\n",
    "        obs = yield path.popleft()\n",
    "\n",
    "    state = 0\n",
    "\n",
    "\n",
    "    # if we're in the LINGER state, pick a random non-forbidden action\n",
    "    if state == 0:\n",
    "        # XXX whelp... tilde uint8 flips the sign bit and is not the logical not\n",
    "        act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "\n",
    "    elif state == 1:\n",
    "        state = 2\n",
    "\n",
    "    elif state == 2:\n",
    "        if path and reachable(uxy, path):\n",
    "            act = None\n",
    "\n",
    "        else:\n",
    "            # moving to the destination is complete, revert to lingering about\n",
    "            state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813f8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9364a29",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1888816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import repeat, rearrange\n",
    "from transformers import ViTModel, ViTConfig\n",
    "\n",
    "from transformers.models.vit.modeling_vit import to_2tuple\n",
    "\n",
    "\n",
    "class NLEViTEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        n_rows, n_cols = to_2tuple(2 * config.window + 1)\n",
    "        super().__init__()\n",
    "\n",
    "        self.cls = nn.Parameter(torch.zeros(\n",
    "            1, config.hidden_size))\n",
    "\n",
    "        self.posemb = nn.Parameter(torch.zeros(\n",
    "            1 + n_rows * n_cols, config.hidden_size))\n",
    "\n",
    "    def forward(self, input, **ignore):\n",
    "        x = rearrange(input, 'B D H W -> B (H W) D')\n",
    "\n",
    "        # cls-token and positional embedding\n",
    "        cls = repeat(self.cls.unsqueeze(0), '() N D -> B N D', B=len(x))\n",
    "        return torch.cat((cls, x), dim=1) + self.posemb\n",
    "\n",
    "\n",
    "model = ViTModel(ViTConfig(\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=1,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=512,\n",
    "    window=2,\n",
    "    # image_size,\n",
    "    # patch_size,  # are ignored\n",
    "))\n",
    "\n",
    "model.embeddings = NLEViTEmbeddings(model.config)\n",
    "\n",
    "\n",
    "# obs, msk = input.obs\n",
    "# gly = agent.features.obs[0](obs)\n",
    "\n",
    "# win = gly['vicinity']\n",
    "\n",
    "# size = dict(zip(\"TBCHW\", win.shape[:3]))\n",
    "# x = rearrange(win, 'T B C H W -> (T B) C H W')\n",
    "\n",
    "# out = rearrange(model(x).pooler_output, '(T B) C -> T B C', **size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c0bf2",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7179fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
