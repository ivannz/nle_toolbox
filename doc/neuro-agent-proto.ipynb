{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865180a7",
   "metadata": {},
   "source": [
    "# Neuro proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import nle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del gym.Wrapper.__getattr__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330fa985",
   "metadata": {},
   "source": [
    "We hide the NLE under several layers of wrappers. From the core to the shell:\n",
    "1. `ReplayToFile` saves the seeds and the takes actions into a file for later inspection and replay.\n",
    "2. `NLEAtoN` maps ascii actions to opaque actions accpeted by the NLE.\n",
    "3. `NLEObservationPatches` patches tty-screens, botched by the cr-lf misconfiguration of the NLE's tty term emulator and NetHacks displays (lf only).\n",
    "4. `NLEFeatureExtractor` adds extra features generated on-the-fly from the current NLE's observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.replay import ReplayToFile\n",
    "from nle_toolbox.utils.env.wrappers import (\n",
    "    NLEObservationPatches,\n",
    "    NLEAtoN,\n",
    "    NLEFeatureExtractor,\n",
    ")\n",
    "\n",
    "\n",
    "def factory():\n",
    "    return NLEObservationPatches(\n",
    "        NLEAtoN(\n",
    "            ReplayToFile(\n",
    "                gym.make(\"NetHackChallenge-v0\"),\n",
    "                save_on=\"done\",\n",
    "                sticky=True,\n",
    "                folder=\"./replays\",\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644a2ab",
   "metadata": {},
   "source": [
    "## Basic GUI Handling\n",
    "\n",
    "NetHack's gui is not as intricate as in some other games. We need to deal\n",
    "with menus, text prompts, messages and y/n questions. In order to analyze\n",
    "the interface details and player's journey through the UI, we first implement\n",
    "a simple command evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71997f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "def gui_run(env, *commands):\n",
    "    pipe0 = deque([])\n",
    "    obs, done = env.reset(), False\n",
    "    for cmd in commands:\n",
    "        pipe0.extend(cmd)\n",
    "        while pipe0 and not done:\n",
    "            obs, rew, done, info = env.step(pipe0.popleft())\n",
    "\n",
    "        yield obs\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a3da8",
   "metadata": {},
   "source": [
    "A renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7124c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "from nle_toolbox.utils.env.render import render as tty_render\n",
    "\n",
    "\n",
    "def ipynb_render(obs, clear=True):\n",
    "    from IPython.display import clear_output\n",
    "\n",
    "    if clear:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(tty_render(**obs))\n",
    "\n",
    "\n",
    "def dump(env, obs):\n",
    "    ipynb_render(obs, clear=False)\n",
    "    pp.pprint(\n",
    "        (\n",
    "            env.messages,\n",
    "            env.menu,\n",
    "            env.prompt,\n",
    "            \"FT\"[env.in_menu]\n",
    "            + \"FT\"[env.xwaitingforspace]\n",
    "            + \"FT\"[env.in_yn_function]\n",
    "            + \"FT\"[env.in_getlin],\n",
    "            obs[\"blstats\"][NLE_BL_TIME],\n",
    "            # {\n",
    "            #     chr(let): itm\n",
    "            #     for let, itm in zip(obs['inv_letters'], obs['inv_strs'].view('S80')[:, 0])\n",
    "            #     if let > 0\n",
    "            # }\n",
    "        ),\n",
    "        width=120,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74c113",
   "metadata": {},
   "source": [
    "### Menus\n",
    "\n",
    "There are two types of menus on NetHack: single paged and multipage. Single\n",
    "page menus popup in the middle of the terminal ontop of the dungeon map (and\n",
    "are sort of `dirty`, meaning that they have arbitrary symbols around them),\n",
    "while multi-page menus take up the entire screen after clearing it. Overlaid\n",
    "menu regions appear to be right justified, while their contents' text is\n",
    "left-justified. All menus are modal, i.e. capture the keyboard input until\n",
    "exited. Some menus are static, i.e. display some information, while other\n",
    "are interactive, i.e. allow item selection with letters or punctuation. However,\n",
    "both kinds share two special control keys. The space `\\0x20` (`\\040`, 32,\n",
    "`<SPACE>`) advances to the next page, or closes the menu, if the page was\n",
    "the last or the only one. The escape `\\0x1b` (`\\033`, 27, `^[`) immediately\n",
    "exits any menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8607058",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72af76",
   "metadata": {},
   "source": [
    "The following detects the type of the menu (overlay/fullscreen), its number\n",
    "of pages, and extracts its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dcd8df",
   "metadata": {},
   "source": [
    "The following function extracts raw data from a menu and enumerates all\n",
    "items, which can be interacted with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c288877",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d66acf",
   "metadata": {},
   "source": [
    "## Top Line Messages\n",
    "\n",
    "The game reports events, displays status or information in the top two lines\n",
    "of the screen. The NLE also provides the raw data in the `message` field of\n",
    "the observation. When NetHack generally announces in the top line, however,\n",
    "if it wants to communicate a single message longer than `80` characters, the\n",
    "game allows it to spill over to the second line, appending a `--More--` suffix\n",
    "to it. The game does the same if it has several short messages to announce.\n",
    "In both cases NetHack's gui expects the user to confirm or dismiss each message\n",
    "by pressing Space, Enter or Escape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c3fbf",
   "metadata": {},
   "source": [
    "Some helper functions to fetch and detect multi-part messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dad768",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356cecf3",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9908ce",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5746554",
   "metadata": {},
   "source": [
    "Below is a wrapper, which handles menus (unless an interaction is required) and\n",
    "fetches all consecutive messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.chassis import Chassis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db5f36",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb6ade",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151e0bc0",
   "metadata": {},
   "source": [
    "Let's test it in bulk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "from nle.nethack import NLE_BL_TIME\n",
    "\n",
    "# seed = None\n",
    "# seed = 12513325507677477210, 18325590921330101247  # multi\n",
    "# seed = 1251332550767747710, 18325590921330101247  # single\n",
    "# seed = 125133255076774710, 18325590921330101247  # single\n",
    "# seed = 13765371332493407478, 12246923801353953927\n",
    "# seed = 12301533412141513004, 11519511065143048485\n",
    "# seed = 1632082041122464284, 11609152793318129379\n",
    "seed = 12604736832047991440, 12469632217503715839  # an aspirant\n",
    "\n",
    "with Chassis(factory(), split=False) as env:\n",
    "    seed = env.seed(seed)\n",
    "    for obs in gui_run(\n",
    "        env,\n",
    "        #         ';j:',   # a paragraph about a cat\n",
    "        #         'acy'      # break wand and blow up\n",
    "        \"Zbyyy,\",  # cast a sleep ray at a newt and pick up its corpse\n",
    "        #         # FIXME the inventory seems interactive, but it is not\n",
    "        #         'i',       # open the inventory\n",
    "        #         # drop a quarterstaff\n",
    "        #         '\\033d*a',\n",
    "        # open inventory\n",
    "        \"i><><\",\n",
    "    ):\n",
    "        dump(env, obs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45069a6e",
   "metadata": {},
   "source": [
    "import pdb;pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9939002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.chassis import InteractiveWrapper, Wrapper, get_wrapper\n",
    "\n",
    "history = []\n",
    "\n",
    "\n",
    "class Snitch(InteractiveWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.ctoa = {chr(a): j for j, a in enumerate(self.unwrapped.actions)}\n",
    "        self.atoc = {j: chr(a) for j, a in enumerate(self.unwrapped.actions)}\n",
    "\n",
    "    def reset(self):\n",
    "        self._action = self.ctoa[\".\"]\n",
    "        return super().reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        self._action = action\n",
    "        return super().step(action)\n",
    "\n",
    "    def update(self, obs, rew=0.0, done=False, info=None):\n",
    "        asc = self.atoc[self._action]\n",
    "        history.append(\n",
    "            (\n",
    "                str(asc.encode(\"unicode-escape\"))[2:-1],\n",
    "                self.env.env.messages,\n",
    "                self.env.env.menu,\n",
    "                self.env.env.prompt,\n",
    "                self.env.env.in_menu,\n",
    "                self.env.env.in_yn_function,\n",
    "                self.env.env.in_getlin,\n",
    "                self.env.env.xwaitingforspace,\n",
    "            )\n",
    "        )\n",
    "        # update level representation\n",
    "        return obs, rew, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aed90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.chassis import ActionMasker\n",
    "from nle_toolbox.utils.seeding import set_seed\n",
    "\n",
    "\n",
    "def factory(seed=None):\n",
    "    # we force seed the main challenge task, since we are training here!\n",
    "    # XXX this has one-off effect until the next reset\n",
    "\n",
    "    env = ReplayToFile(\n",
    "        gym.make(\"NetHackChallenge-v0\"),\n",
    "        save_on=\"done,close\",\n",
    "        sticky=True,\n",
    "        folder=\"./replays\",\n",
    "    )\n",
    "    env.seed(seed=seed)\n",
    "\n",
    "    ctoa = {chr(a): j for j, a in enumerate(env.unwrapped.actions)}\n",
    "\n",
    "    # use chassis atop tty patches\n",
    "    env = ActionMasker(\n",
    "        Chassis(NLEObservationPatches(env), space=ctoa[\" \"], split=False)\n",
    "    )\n",
    "    return Snitch(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from rlplay.utils.common import multinomial\n",
    "from rlplay.engine.core import BaseActorModule\n",
    "\n",
    "\n",
    "class RandomActor(BaseActorModule):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.action_space = env.action_space\n",
    "\n",
    "    def step(\n",
    "        self,\n",
    "        stepno,\n",
    "        obs,\n",
    "        act,\n",
    "        rew,\n",
    "        fin,\n",
    "        *,\n",
    "        hx=None,\n",
    "        virtual=False,\n",
    "    ):\n",
    "        if not virtual:\n",
    "            # act = torch.randint_like(act, self.action_space.n)\n",
    "            raw = torch.randn(*act.shape, self.action_space.n, dtype=float)\n",
    "\n",
    "            # mask illegal actions\n",
    "            _, mask = obs\n",
    "            raw = raw.masked_fill(mask.to(torch.int8), -float(\"inf\"))\n",
    "            prb = raw.softmax(-1)\n",
    "            act = multinomial(prb)\n",
    "\n",
    "        return act, (), {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d08263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlplay.engine.rollout import same, multi, single\n",
    "\n",
    "history.clear()\n",
    "# seed = 12604736832047991440, 12469632217503715839\n",
    "# seed = [*b'i9u48y7548']\n",
    "seed = None\n",
    "with factory(seed) as env:\n",
    "    actor = RandomActor(env)\n",
    "    rndgen = same.rollout(\n",
    "        [\n",
    "            env,\n",
    "            # factory(seed),\n",
    "            # factory(seed),\n",
    "            # factory(seed),\n",
    "        ],\n",
    "        actor,\n",
    "        n_steps=250,\n",
    "    )\n",
    "    fragment = next(rndgen)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "793c70a9",
   "metadata": {},
   "source": [
    "import pdb ; pdb.pm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e81fed",
   "metadata": {},
   "source": [
    "* `&` results in `What command?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a027db2a",
   "metadata": {},
   "source": [
    "Building a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "\n",
    "import plyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "from nle_toolbox.bot.legacy.option import OptionWrapper\n",
    "\n",
    "\n",
    "class CompositeActions(OptionWrapper):\n",
    "    def __init__(self, env, *actions, quit=(65, 7)):\n",
    "        super().__init__(env, reduce=sum, allow_empty=True)\n",
    "\n",
    "        # register the composites and redefine the action space\n",
    "        self.actions = (self.forward,) + actions\n",
    "        self.action_space = spaces.Tuple(\n",
    "            (\n",
    "                # halting flag\n",
    "                spaces.Discrete(2),\n",
    "                spaces.Dict(\n",
    "                    dict(\n",
    "                        # the macro action head\n",
    "                        macro=spaces.Discrete(1 + len(actions)),\n",
    "                        # the original actions\n",
    "                        micro=self.action_space,\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.quit = quit\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.obs = super().reset()\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        hlt, act = action\n",
    "\n",
    "        obs, rew, done, info = super().step(self.dispatch(hlt, **act))\n",
    "        self.obs = obs\n",
    "        return obs, rew, done, info\n",
    "\n",
    "    def dispatch(self, hlt, macro, micro):\n",
    "        # omg lul, win by quitting!\n",
    "        if hlt:\n",
    "            # win by flying, ie. executing '\\xf1y' (shorthand for `#quit\\015y`)\n",
    "            yield self.quit\n",
    "            return\n",
    "\n",
    "        yield from self.actions[macro](self.obs, micro)\n",
    "\n",
    "    def forward(self, obs, micro):\n",
    "        yield micro,  # one-action policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561000ae",
   "metadata": {},
   "source": [
    "A default recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = dict(\n",
    "    features=dict(\n",
    "        glyphs=dict(\n",
    "            embedding_dim=64,\n",
    "            window=2,\n",
    "        ),\n",
    "        bls=dict(\n",
    "            n_vitals=64,\n",
    "            n_build=32,\n",
    "        ),\n",
    "        sizes=[\n",
    "            # flattened vicinity, inventory and bls\n",
    "            64 * ((2 + 1 + 2) * (2 + 1 + 2) + 55) + (64 + 32),\n",
    "            2048,\n",
    "            512,\n",
    "        ],\n",
    "    ),\n",
    "    core=dict(\n",
    "        input_size=512,\n",
    "        hidden_size=256,\n",
    "        num_layers=1,\n",
    "        bias=True,\n",
    "        dropout=0.0,\n",
    "        kind=\"lstm\",\n",
    "    ),\n",
    "    head=dict(\n",
    "        n_features=256,\n",
    "        heads=dict(\n",
    "            macro=2,  # determined by the Composite action wrapper\n",
    "            # the underlying discrete action space\n",
    "            micro=len(ActionMasker._raw_nethack_actions),\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe339455",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137cecf0",
   "metadata": {},
   "source": [
    "Let's test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scripted(ctoa, actions):\n",
    "    def generator(obs=None, act=None):\n",
    "        for act in actions:\n",
    "            yield tuple(map(ctoa.get, act))\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factory(seed=None):\n",
    "    env = NLEObservationPatches(\n",
    "        #         ReplayToFile(\n",
    "        gym.make(\"NetHackChallenge-v0\"),\n",
    "        #             save_on='done,close',\n",
    "        #             sticky=True,\n",
    "        #             folder='./replays',\n",
    "        #         )\n",
    "    )\n",
    "    ctoa = {chr(a): j for j, a in enumerate(env.unwrapped.actions)}\n",
    "\n",
    "    return CompositeActions(\n",
    "        ActionMasker(\n",
    "            Chassis(\n",
    "                env,\n",
    "                space=ctoa[\" \"],\n",
    "                split=False,\n",
    "            )\n",
    "        ),\n",
    "        scripted(ctoa, \"32s\"),  # search!\n",
    "        quit=(\n",
    "            ctoa[\"\\xf1\"],\n",
    "            ctoa[\"n\"],\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.model.network import Network\n",
    "from nle_toolbox.bot.model.utils import NeuralActorModule\n",
    "\n",
    "module = Network(recipe)\n",
    "actor = NeuralActorModule(module)\n",
    "# XXX deal with the pesky warning!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "457a18b4",
   "metadata": {},
   "source": [
    "import pdb ; pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "n_epochs = 100\n",
    "with factory() as env:\n",
    "    rndgen = same.rollout(\n",
    "        [\n",
    "            env,\n",
    "            factory(),\n",
    "            # factory(),\n",
    "            # factory(),\n",
    "            # factory(),\n",
    "            # factory(),\n",
    "        ],\n",
    "        actor,\n",
    "        n_steps=25,\n",
    "    )\n",
    "\n",
    "    for ep, fragment in zip(tqdm.tqdm(range(n_epochs)), rndgen):\n",
    "        fragment = next(rndgen)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0355e58c",
   "metadata": {},
   "source": [
    "fragment.state.fin\n",
    "\n",
    "# import pdb ; pdb.set_trace()\n",
    "\n",
    "out, hx = actor.module(\n",
    "    fragment.state.obs[0], fin=fragment.state.fin,\n",
    ")  #, hx=fragment.hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be14a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, mask = fragment.state.obs\n",
    "gl = module.features.glyphs(obs)\n",
    "\n",
    "{k: v.shape for k, v in gl.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45afd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlplay.utils.plotting.grid import make_grid\n",
    "\n",
    "x = gl[\"vicinity\"][:, -1].detach()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=160)\n",
    "ax.imshow(\n",
    "    make_grid(\n",
    "        x.flatten(0, 1),\n",
    "        aspect=(4, 3),\n",
    "        normalize=False,\n",
    "    ).numpy(),\n",
    "    cmap=plt.cm.bone,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32f453",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "\n",
    "class EMA(Optimizer):\n",
    "    r\"\"\"Exponential average parameter tracker.\n",
    "\n",
    "    Details\n",
    "    -------\n",
    "    Update the tracked parameter value $\\hat{\\theta}$ with the current\n",
    "    values $\\theta$ according to\n",
    "\n",
    "    $$\n",
    "        \\hat{\\theta}\n",
    "            \\longleftarrow (1 - \\eta) \\hat{\\theta} + \\eta \\theta\n",
    "        \\,, $$\n",
    "\n",
    "    with $\\eta \\in [-1, +1]$.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=required):\n",
    "        if lr is not required and abs(lr) > 1:\n",
    "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
    "\n",
    "        super().__init__(params, dict(lr=lr))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        \"\"\"Perform a single moving average step.\"\"\"\n",
    "        for group in self.param_groups:\n",
    "            lr = group[\"lr\"]\n",
    "            for p in group[\"params\"]:\n",
    "                # we update diff-able params only\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                if p not in self.state:\n",
    "                    # lazy init buffers by simply copying current value\n",
    "                    self.state[p] = p.clone()\n",
    "\n",
    "                else:\n",
    "                    # otherwise lerp the buffer with the current param\n",
    "                    self.state[p].lerp_(p, lr)\n",
    "\n",
    "    def zero_grad(self, set_to_none: bool = False):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30290a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def gen(module, **sizes):\n",
    "    out = {}\n",
    "    for k, n in sizes.items():\n",
    "        X = torch.randn(n, 16)\n",
    "        out[k] = TensorDataset(\n",
    "            X,\n",
    "            module(X).argmax(-1),\n",
    "        )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da95b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dope!\n",
    "L, S, A = nn.Linear, nn.Sequential, nn.ReLU\n",
    "R = type(\n",
    "    \"R\",\n",
    "    (S,),\n",
    "    dict(\n",
    "        forward=lambda self, x: self[0](x) + x,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e45b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = nn.Sequential(\n",
    "    nn.Linear(16, 2),\n",
    ")\n",
    "\n",
    "datasets = gen(ref, train=1024, test=256)\n",
    "\n",
    "feeds = dict(\n",
    "    train=torch.utils.data.DataLoader(datasets[\"train\"], batch_size=32, shuffle=True),\n",
    "    test=torch.utils.data.DataLoader(datasets[\"test\"], batch_size=64, shuffle=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = S(\n",
    "    L(16, 32),\n",
    "    A(),\n",
    "    *[\n",
    "        R(\n",
    "            S(\n",
    "                L(32, 32),\n",
    "                A(),\n",
    "            )\n",
    "        )\n",
    "        for _ in range(1)\n",
    "    ],\n",
    "    L(32, 2),\n",
    "    nn.LogSoftmax(dim=-1),\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(module.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "n_epochs = 500\n",
    "losses, ema_tracked, tracked = [], [], []\n",
    "\n",
    "# init ema\n",
    "ema = deepcopy(module)\n",
    "state = ema.state_dict()\n",
    "\n",
    "for ep in tqdm.tqdm(range(n_epochs)):\n",
    "    ep_losses = []\n",
    "    for bx, by in feeds[\"train\"]:\n",
    "        loss = F.nll_loss(module(bx), by, reduction=\"mean\")\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # update ema\n",
    "        with torch.no_grad():\n",
    "            plyr.suply(\n",
    "                torch.Tensor.lerp_,\n",
    "                state,\n",
    "                module.state_dict(),\n",
    "                weight=0.1,  # 1 / float(ep + 1),\n",
    "            )\n",
    "\n",
    "        ep_losses.append(float(loss))\n",
    "\n",
    "    losses.append(np.mean(ep_losses))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        nll = torch.cat(\n",
    "            [F.nll_loss(ema(tx), ty, reduction=\"none\") for tx, ty in feeds[\"test\"]],\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "    ema_tracked.append(float(nll.mean(-1)))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        nll = torch.cat(\n",
    "            [F.nll_loss(module(tx), ty, reduction=\"none\") for tx, ty in feeds[\"test\"]],\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "    tracked.append(float(nll.mean(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff454de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(losses)\n",
    "\n",
    "plt.semilogy(tracked)\n",
    "plt.semilogy(ema_tracked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plyr.suply(plyr.getitem, fragment, index=(slice(None), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle.nethack import NLE_BL_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee728043",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragment.state.obs[0][\"blstats\"][..., NLE_BL_TIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494afe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.env.defs import glyphlut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_from_example(\n",
    "    obs,\n",
    "    act,\n",
    "    rew,\n",
    "    fin,\n",
    "    actor,\n",
    "    env,\n",
    "    hx,\n",
    "    /,\n",
    "    n_steps,\n",
    "    n_envs,\n",
    "    *,\n",
    "    pinned=False,\n",
    "    shared=False,\n",
    "    device=None,\n",
    "):\n",
    "    # we get an example data for one time-step and a single\n",
    "    #  environment and replicate it across time and envs\n",
    "    pass\n",
    "\n",
    "    # ensure float32 and bool data types for `rew_` and `fin_`, respectively,\n",
    "    # while leaving `obs_` and `act_` intact as they are nested containers of\n",
    "    # numpy arrays or scalars with proper dtypes.\n",
    "    rew_, fin_, stepno_ = numpy.float32(rew), bool(fin), numpy.int64(0)\n",
    "\n",
    "    # the buffers for the actor's info and state are `(1 + n_steps) x n_envs x ...`\n",
    "    #  while for the env we allocate an `n_steps x n_envs x ...` buffer\n",
    "    state, actor = torchify(\n",
    "        (State(stepno_, obs, act, rew_, fin_), actor),\n",
    "        1 + n_steps,\n",
    "        n_envs,\n",
    "        shared=shared,\n",
    "        pinned=pinned,\n",
    "    )\n",
    "    env = torchify(env, n_steps, n_envs, shared=shared, pinned=pinned)\n",
    "\n",
    "    # the hidden recurrent state has to be replicated manually\n",
    "    hx = torchify(hx, shared=shared, pinned=pinned)\n",
    "\n",
    "    return Fragment(state=state, actor=actor, env=env, hx=hx)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0468277",
   "metadata": {},
   "source": [
    "import pdb; pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25736d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hx = mod(fragment.state.obs)  # , fin=fragment.state.fin, hx=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64049b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = postproc(fragment.state.obs, hx, **out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bcb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e060b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f471eca",
   "metadata": {},
   "source": [
    "### Basic automatic actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2dad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import render, get_logger\n",
    "\n",
    "logger = get_logger(\"debug.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee14d6",
   "metadata": {},
   "source": [
    "Detect in-game events based on the response to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b724e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(obs):\n",
    "    \"\"\"Detect and dispatch events.\"\"\"\n",
    "    while is_menu(obs):\n",
    "        obx, rew, done, info = yield \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aa9571",
   "metadata": {},
   "source": [
    "Ensure that the game does not prompt for anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1297277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush(obs):\n",
    "    yield \"\\033\\033\\033\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559906d8",
   "metadata": {},
   "source": [
    "search and pass in-game time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8361d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(obs=None, n=10):\n",
    "    \"\"\"Search around the player's current location for several turns.\"\"\"\n",
    "    # issuing a search command is an atomic operation\n",
    "    obx, rew, done, info = yield (f\"{n:d}s\" if n > 1 else \"s\")\n",
    "\n",
    "    # which however may cause the game to bring up some state messages\n",
    "    yield from detect(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63e027a",
   "metadata": {},
   "source": [
    "search and pass in-game time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3818aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "\n",
    "def randomstep(obs=None, rng=default_rng(42)):\n",
    "    dirs = rng.integers(9, size=100)\n",
    "    path = \"\".join(\"ykuh.lbjn\"[j] for j in dirs)\n",
    "\n",
    "    # assume a good path that does not bump into walls\n",
    "    logger.info(f\"randomstep:: `{path}`\")\n",
    "\n",
    "    # yield singleton actions\n",
    "    for s in path:\n",
    "        obs, rew, done, info = yield s\n",
    "\n",
    "    yield from detect(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3040dc",
   "metadata": {},
   "source": [
    "An end-of-everything action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quit(obs):\n",
    "    yield from flush(obs)\n",
    "    yield \"#quit\\015y\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717af0c3",
   "metadata": {},
   "source": [
    "The startup character analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c716e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Startup:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "\n",
    "    def analyze(self, obs):\n",
    "        screen = b\"\\n\".join(obs[\"tty_chars\"].view(\"S80\")[:, 0]).decode(\"ascii\")\n",
    "        message = obs[\"message\"].view(\"S256\")[0].decode(\"ascii\")\n",
    "        self.data.append((screen, message))\n",
    "        logger.info(f\"Startup:: screen\\n{' tty ':=^80}\\n{screen}\\n{'':=<80}\")\n",
    "        logger.info(f\"Startup:: message `{message}`\")\n",
    "\n",
    "    def __call__(self, obs):\n",
    "        # initial screen (hopefully)\n",
    "        self.analyze(obs)\n",
    "        # disable autopickup and request character overview\n",
    "        obs, rew, done, info = yield \"@\\x18\"\n",
    "        while is_menu(obs):\n",
    "            self.analyze(obs)\n",
    "            obs, rew, done, info = yield \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad66116",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionInspector(gym.Wrapper):\n",
    "    def reset(self):\n",
    "        self.history = []\n",
    "        return super().reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.history.append(action)\n",
    "        return super().step(action)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"`\" + \"\".join(env.history) + \"`\"\n",
    "\n",
    "    __str__ = __repr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.legacy.genfun import is_suspended\n",
    "from nle_toolbox.bot.legacy.option import Continue, Preempt\n",
    "\n",
    "options = dict(\n",
    "    startup=Startup(),\n",
    "    #     quit=quit,\n",
    "    search=search,\n",
    "    detect=detect,\n",
    "    randomstep=randomstep,\n",
    ")\n",
    "\n",
    "\n",
    "def preempt(obs, current):\n",
    "    return False\n",
    "\n",
    "\n",
    "def ok(obs, current):\n",
    "    return True\n",
    "\n",
    "\n",
    "def supervisor(obs, *, rng):\n",
    "    current, done = \"startup\", False\n",
    "    while not done:\n",
    "        # schedule an option\n",
    "        option = options[current](obs)\n",
    "        obs, rew, done, info = yield option\n",
    "\n",
    "        # preemption loop\n",
    "        while is_suspended(option):\n",
    "            # if it is a menu and it is ok to interject the current action\n",
    "            if is_menu(obs) and ok(obs, current):\n",
    "                # interject with a menu-gobbling option: unlike sending a new\n",
    "                # interjecting suspends the current option and delegates control\n",
    "                # to the alternative option until it terminates.\n",
    "                obs, rew, done, info = yield Preempt(detect(obs))\n",
    "\n",
    "            elif not preempt(obs, current):\n",
    "                # there are no emergencies to deal with, so we can continue\n",
    "                # with the current option\n",
    "                obs, rew, done, info = yield Continue\n",
    "\n",
    "        # pick the next option, since none is currently running\n",
    "        current = rng.choice(list(options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from nle_toolbox.bot.legacy.option import InterruptibleOptionWrapper as OptionWrapper\n",
    "from nle_toolbox.bot.legacy.option import OptionWrapper\n",
    "\n",
    "seed = (12513325507677477210, 18325590921330101247)\n",
    "with OptionWrapper(Inspector(factory()), reduce=sum, allow_empty=True) as env:\n",
    "    seed = env.seed(seed)\n",
    "    logger.info(\"python -m nle_toolbox.utils.play.one --seed\" f\" {seed[0]} {seed[1]}\")\n",
    "\n",
    "    rewards = []\n",
    "\n",
    "    tick = time.monotonic_ns()\n",
    "\n",
    "    tx = None\n",
    "    obs, rew, done, info = env.reset(), 0.0, False, {}\n",
    "\n",
    "    sup = supervisor(obs, rng=default_rng(14426138988763310091))\n",
    "    while render(env, obs) and not done:\n",
    "        tx = obs, rew, done, info = env.step(sup.send(tx))\n",
    "        rewards.append(rew)\n",
    "\n",
    "    tock = time.monotonic_ns()\n",
    "\n",
    "print((tock - tick) / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58168ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(env.env.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b59808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "render(env, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ae232",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rewards)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b3bfb64",
   "metadata": {},
   "source": [
    "options['startup'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(map(type, map(sum, rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[j for j, l in enumerate(map(len, rewards)) if l == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37681d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "035d4648",
   "metadata": {},
   "source": [
    "import pdb ; pdb.pm()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b384075",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "sizes = torch.randint(1023, 1024, (32,))\n",
    "indices = [\n",
    "    torch.randint(512, size=(sz, 2))\n",
    "    for sz in sizes\n",
    "]\n",
    "\n",
    "%%timeit\n",
    "base = torch.zeros(len(sizes)+1, dtype=int)\n",
    "torch.cumsum(sizes, dim=0, out=base[1:])\n",
    "out = torch.cat(indices, dim=0).add_(\n",
    "    torch.repeat_interleave(base[:-1], sizes).unsqueeze(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf32251c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8794bf6",
   "metadata": {},
   "source": [
    "A proto option policy (neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9943b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def option(core, obs, lookahead=False):\n",
    "    \"\"\"An option `core` starting at `obs`.\n",
    "\n",
    "    Details\n",
    "    -------\n",
    "    Sutton, R.S., Precup, D., Singh, S. (1999) suggest the following:\n",
    "\n",
    "      At s_t the option (\\pi, \\beta), given the opportunity, executes\n",
    "      the transition\n",
    "       s_t, a_t -->> s_{t+1}, x_{t+1}, r_{t+1}\n",
    "      with a_t = \\pi(x_t) and then decides to halt w. prob.\n",
    "      \\beta_{t+1} = \\beta(x_{t+1}).\n",
    "\n",
    "    this corresponds to `lookahead = False`.\n",
    "\n",
    "    The option `core` is a callable returning the action a_t, the halting\n",
    "    probability \\beta_t, and the next context `hx` for the observation x_t\n",
    "    and current context `hx`. The core is designed in such a way as to\n",
    "    keep all the relevant runtime data in an external context `hx`.\n",
    "\n",
    "    They also mention interrupted options, which we are work-in-progress atm.\n",
    "    \"\"\"\n",
    "\n",
    "    # init the flags and the core's context `hx`\n",
    "    done, halt, hx = False, False, None\n",
    "    if lookahead:\n",
    "        # get a_t, \\beta_t = \\pi(x_t) and execute a transition\n",
    "        #  s_t, a_t -->> s_{t+1}, x_{t+1}, r_{t+1} w. prob. \\beta_t\n",
    "        # and halt otherwise.\n",
    "        # XXX potentially empty options\n",
    "        act, halt, hx = core(obs, hx=hx)  # a_0, \\beta_0 = \\pi(x_0)\n",
    "        while not (done or halt):  # for t \\geq 0\n",
    "            obx, rew, done, info = yield act  # send a_t, recv x_{t+1}\n",
    "            act, halt, hx = core(obs, hx=hx)  # a_{t+1}, \\beta_{t+1} = \\pi(x_{t+1})\n",
    "        # XXX a_t is enacted w. prob. \\beta_t\n",
    "\n",
    "    else:\n",
    "        # get a_t, \\beta_t = \\pi(x_t), execute a transition\n",
    "        #    s_t, a_t -->> s_{t+1}, x_{t+1}, r_{t+1},\n",
    "        # then halt w. prob. \\beta_t, regardless of the new x_{t+1}.\n",
    "        while not (done or halt):  # for t \\geq 0\n",
    "            act, halt, hx = core(obs, hx=hx)  # a_t, \\beta_t = \\pi(x_t)\n",
    "            obx, rew, done, info = yield act  # send a_t, recv x_{t+1}\n",
    "        # XXX a_t is enacted w. prob. \\beta_{t-1}\n",
    "\n",
    "    # nothing to comm through StopIteration\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d343d959",
   "metadata": {},
   "source": [
    "a simple neural net for random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f6ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from rlplay.engine.utils.shared import torchify\n",
    "from rlplay.utils.common import multinomial\n",
    "\n",
    "from nle_toolbox.bot.model.blstats import BLStatsVitalsEmbedding\n",
    "\n",
    "\n",
    "class SirvivalWalk(torch.nn.Module):\n",
    "    _actions = \"ykuh.lbjn\"\n",
    "\n",
    "    def __init__(self, vitals):\n",
    "        super().__init__()\n",
    "        self.vitals = vitals\n",
    "\n",
    "        self.core = torch.nn.GRU(128, 64, 2)\n",
    "        self.control = torch.nn.Sequential(\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 9 + 1),\n",
    "        )\n",
    "\n",
    "        # our experience buffer\n",
    "        self.buffer = []\n",
    "\n",
    "    def forward(self, obs, hx=None):\n",
    "        out, hx = self.core(self.vitals(obs[\"blstats\"]), hx=hx)\n",
    "\n",
    "        logits = self.control(out)\n",
    "        l_act, l_halt = torch.split(logits, (9, 1), dim=-1)\n",
    "\n",
    "        # non-diffable stuff\n",
    "        act = multinomial(l_act.softmax(-1))\n",
    "        tau = torch.rand_like(l_halt).logit_()  # logistic r.v.\n",
    "        return (\n",
    "            act,\n",
    "            l_halt.ge(tau),\n",
    "            hx,\n",
    "            dict(\n",
    "                l_act=l_act,\n",
    "                l_halt=l_halt,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def run(self, obs, hx=None):\n",
    "        logger.info(f\"SirvivalWalk:: start\")\n",
    "        done, halt, probs = False, False, []\n",
    "        while not (done or bool(halt)):\n",
    "            act, halt, hx, a_info = self(torchify(obs, 1, 1), hx=hx)\n",
    "\n",
    "            act = int(act)\n",
    "            obs_, rew, done, e_info = yield self._actions[act]\n",
    "\n",
    "            p_halt = a_info[\"l_halt\"].sigmoid()\n",
    "            probs.append(float(p_halt))\n",
    "            self.buffer.append((obs[\"blstats\"], act, obs_[\"blstats\"]))\n",
    "\n",
    "            obs = obs_\n",
    "\n",
    "        # nothing to comm through StopIteration\n",
    "        logger.info(f\"SirvivalWalk:: {probs}\")\n",
    "        return\n",
    "\n",
    "    def train(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91b2c9f5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# somewhere\n",
    "gen = executor(env)\n",
    "\n",
    "obs, rew, done, info = gen.send(None)\n",
    "while not done:\n",
    "    while not (done or preempt(obs, opt)):\n",
    "        # we want to continue: send empty iterable\n",
    "        obs, rew, done, info = gen.throw(ExecContinue)\n",
    "\n",
    "    # Here we end up with an empty pipe0 either way: it itself\n",
    "    #  is empty or we wish to preempt and flush it.\n",
    "    opt = schedule(tx)\n",
    "    tx, finished = gen.send(opt.run)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23fa99",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da913e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [\n",
    "    #     (5009195464289726085, 12625175316870653325),\n",
    "    #     (7002570039340100249, 14426138988763310091),\n",
    "    #     (14278027783296323177, 11038440290352864458),\n",
    "    #     (14046273391210721807, 3865099148830813988),\n",
    "    #     (18386314338156462112, 4255575630009817530)\n",
    "    None\n",
    "]\n",
    "\n",
    "\n",
    "vitals = BLStatsVitalsEmbedding(128)\n",
    "surv = SirvivalWalk(vitals)\n",
    "\n",
    "for seed in seeds:\n",
    "    with Driver(\n",
    "        factory(),\n",
    "        startup=Startup(),\n",
    "        quit=quit,\n",
    "        search=search,\n",
    "        #         randomstep=surv.run\n",
    "    ) as env:\n",
    "        seed = env.seed(seed)\n",
    "        logger.info(\n",
    "            \"python -m nle_toolbox.utils.play.one --seed\" f\" {seed[0]} {seed[1]}\"\n",
    "        )\n",
    "\n",
    "        obs, done, rewards = env.reset(), False, []\n",
    "        while render(env, obs) and not done:\n",
    "            if preempt(obs, current):\n",
    "                action = current = schedule(obs)\n",
    "            else:\n",
    "                action = env.Continue\n",
    "\n",
    "            obs, rew, done, info = env.step(action, n_slice=10)\n",
    "            rewards.append(rew)\n",
    "            time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbeb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "surv.buffer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fed0b024",
   "metadata": {},
   "source": [
    "g = surv.run(obs)\n",
    "\n",
    "g.send(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf47b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64971351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, recipe):\n",
    "        recipe = deepcopy(recipe)\n",
    "        super().__init__()\n",
    "\n",
    "        # the embedders\n",
    "        self.glyphs = GlyphFeatures(**recipe[\"glyphs\"])\n",
    "        self.bls = BLStatsEmbedding(**recipe[\"bls\"])\n",
    "\n",
    "        # build the feature network\n",
    "        n_features = recipe[\"features\"][-1]\n",
    "        layers = [\n",
    "            ModuleDict(\n",
    "                dict(\n",
    "                    vicinity=nn.Flatten(-3, -1),\n",
    "                    inventory=nn.Flatten(-2, -1),\n",
    "                    bls=nn.Identity(),\n",
    "                ),\n",
    "                dim=-1,\n",
    "            )\n",
    "        ]\n",
    "        for n, m in zip(recipe[\"features\"], recipe[\"features\"][1:]):\n",
    "            layers.append(nn.Linear(n, m, bias=True))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "        # the core is either absent or a GRU\n",
    "        core = nn.GRU if \"core\" in recipe else nn.Identity\n",
    "        self.core = core(n_features, n_features, 1, bias=True, batch_first=False)\n",
    "\n",
    "        # construct h0 for the core\n",
    "        shape, h0 = hx_shape(self.core), None\n",
    "        if isinstance(shape, torch.Size):\n",
    "            h0 = torch.nn.Parameter(torch.zeros(*shape))\n",
    "\n",
    "        elif isinstance(shape, tuple):\n",
    "            h0 = torch.nn.ParameterList(\n",
    "                [torch.nn.Parameter(torch.zeros(*s)) for s in shape]\n",
    "            )\n",
    "        self.register_parameter(\"h0\", h0)\n",
    "\n",
    "        # halting probability logit, action prelogits, and the critic's value\n",
    "        self.head = LinearSplitter(n_features, dict(val=1, hlt=1, **recipe[\"heads\"]))\n",
    "\n",
    "    def forward(self, obs, fin=None, hx=None):\n",
    "        # embed and compute features\n",
    "        features = self.features(\n",
    "            {\n",
    "                **self.glyphs(obs),\n",
    "                \"bls\": self.bls(obs),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # prepare the hiddens: we keep an explicit `h0`, in the case\n",
    "        # it is diff-able and learnable\n",
    "        n_seq, n_batch = features.shape[:2]\n",
    "        h0 = hx_broadcast(self.h0, n_batch)\n",
    "        hx = h0 if hx is None else hx\n",
    "\n",
    "        # run the core\n",
    "        out = features\n",
    "        if not isinstance(self.core, nn.Identity):\n",
    "            outputs = []\n",
    "            # in case fin is missing, create a never-resetting mask\n",
    "            if fin is None:\n",
    "                fin = torch.zeros(n_seq, n_batch, dtype=bool, device=features.device)\n",
    "\n",
    "            # make sure the termination mask is on-device and numeric\n",
    "            fin = fin.unsqueeze(-1).to(features)\n",
    "            for x, f in zip(features.unsqueeze(1), fin.unsqueeze(1)):\n",
    "                # reset the hiddens by lerping with `fin`: hx = hx * (1 - f) + h0 * f\n",
    "                out, hx = self.core(x, hx=plyr.suply(torch.lerp, hx, h0, weight=f))\n",
    "                outputs.append(out)\n",
    "\n",
    "            out = torch.cat(outputs, dim=0)\n",
    "\n",
    "        return self.head(out), hx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9364a29",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
