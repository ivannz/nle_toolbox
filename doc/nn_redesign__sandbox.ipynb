{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a978e8",
   "metadata": {},
   "source": [
    "# Let's try an non-hierarchical RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import nle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del gym.Wrapper.__getattr__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e1ac6e",
   "metadata": {},
   "source": [
    "Import other useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baefd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plyr\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91212f6",
   "metadata": {},
   "source": [
    "We hide the NLE under several layers of wrappers. From the core to the shell:\n",
    "1. `ReplayToFile` handles seeding and logs the taken actions and seed into a file for later inspection and replay.\n",
    "\n",
    "2. `NLEPatches` patches tty-screens, botched by the cr-lf misconfiguration of the NLE's tty term emulator and NetHacks displays (lf only).\n",
    "\n",
    "3. `Chassis` handles skippable gui events that do not require a decision, such as collecting menu pages unless an interaction is required, fetching consecutive topline or log messages.\n",
    "\n",
    "4. `ActionMasker` computes the mask of action that are **forbidden** in the current game state (_gui_ or _play_)\n",
    "\n",
    "5. `RecentHistory` keeps a brief log of actions taken in the environment (partially duplicates the functionality of the `Replay` wrapper).\n",
    "\n",
    "6. `NLEAtoN` maps ascii actions to opaque actions accpeted by the NLE.\n",
    "\n",
    "7. (**unused**) `NLEFeatures` adds extra features generated on-the-fly from the current NLE's observation.\n",
    "  * see `NLEFeaturesVicinity` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.wrappers.replay import ReplayToFile, Replay\n",
    "\n",
    "from nle_toolbox.wrappers.features import NLEPatches, NLEAtoN\n",
    "from nle_toolbox.bot.chassis import Chassis, ActionMasker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5975e4e3",
   "metadata": {},
   "source": [
    "A temporary wrapper that bails out on any menu or prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.chassis import InteractiveWrapper\n",
    "from nle_toolbox.bot.chassis import get_wrapper\n",
    "\n",
    "class AutoEscape(InteractiveWrapper):\n",
    "    def __init__(self, env, escape='\\033'):\n",
    "        super().__init__(env)\n",
    "        self.chassis = get_wrapper(env, Chassis)\n",
    "        self.escape = escape\n",
    "\n",
    "    def update(self, obs, rew=0., done=False, info=None):\n",
    "        # default to immediately escaping from any menu or prompt\n",
    "        while self.chassis.in_menu or self.chassis.prompt:\n",
    "            obs, rew, done, info = self.env.step(self.escape)\n",
    "\n",
    "        # update must always return the most recent relevant transition data\n",
    "        return obs, rew, done, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9906d62",
   "metadata": {},
   "source": [
    "A wrpper that keeps track of the action history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class RecentHistory(gym.Wrapper):\n",
    "    \"\"\"The base interaction architecture is essentially a middleman, who passes\n",
    "    the action to the underlying env and intercepts the resulting transition\n",
    "    data. It also is allowed, but not obliged to interact with the env, while\n",
    "    intercepting the observations.\n",
    "    \"\"\"\n",
    "    def __new__(cls, env, *, n_recent=0, map=None):\n",
    "        if n_recent < 1:\n",
    "            return env\n",
    "        return object.__new__(cls)\n",
    "\n",
    "    def __init__(self, env, *, n_recent=0, map=None):\n",
    "        super().__init__(env)\n",
    "        self.recent = deque([], n_recent)\n",
    "        self.map = map if callable(map) else lambda x: x\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        self.recent.append(self.map(action))\n",
    "        return self.env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386b5c9",
   "metadata": {},
   "source": [
    "A wrapper that keeps the specified observation keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3890c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.wrappers.features import ObservationWrapper\n",
    "\n",
    "class ObservationKeyFilter(ObservationWrapper):\n",
    "    \"\"\"Filter out the fields of the observation dict specified fields and optionally make a copy.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, *keys):\n",
    "        super().__init__(env)\n",
    "        self.keys = frozenset(keys)\n",
    "\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            self.observation(self.observation_space)\n",
    "        )\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return {k: v for k, v in observation.items() if k in self.keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01294c",
   "metadata": {},
   "source": [
    "A wrapper, which pre-extracts the field-of-view around the agent\n",
    "* `NLEFeatures` is a little bit outdated, but hopefully, if the wrapper below helps,\n",
    "then it will be updated and merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf165df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.wrappers.features import ObservationWrapper\n",
    "\n",
    "from nle_toolbox.utils.fold import npy_fold2d\n",
    "from nle.nethack import (\n",
    "    MAX_GLYPH,\n",
    "    NLE_BL_X,\n",
    "    NLE_BL_Y,\n",
    "    DUNGEON_SHAPE,\n",
    ")\n",
    "\n",
    "class NLEFeaturesVicinity(ObservationWrapper):\n",
    "    def __init__(self, env, *, k=3):\n",
    "        super().__init__(env)\n",
    "\n",
    "        decl = self.observation_space['glyphs']\n",
    "\n",
    "        # create bordered glyph array\n",
    "        rows, cols = DUNGEON_SHAPE\n",
    "        glyphs = self.glyphs = np.full((\n",
    "            k + rows + k, k + cols + k,\n",
    "        ), MAX_GLYPH, dtype=decl.dtype)\n",
    "\n",
    "        # create view for fast access\n",
    "        self.vw_glyphs = glyphs[k:-k, k:-k]\n",
    "        self.vw_vicinity = npy_fold2d(\n",
    "            glyphs, k=k, n_leading=0, writeable=True,\n",
    "            # XXX pytorch does not like read-only views\n",
    "        )\n",
    "\n",
    "        # declare the observation space\n",
    "        self.observation_space['vicinity'] = gym.spaces.Box(\n",
    "            0, MAX_GLYPH,\n",
    "            dtype=self.vw_vicinity.dtype,\n",
    "            shape=self.vw_vicinity.shape[2:],\n",
    "        )\n",
    "\n",
    "    def observation(self, observation):\n",
    "        np.copyto(self.vw_glyphs, observation['glyphs'], 'same_kind')\n",
    "\n",
    "        bls = observation['blstats']\n",
    "        vic = self.vw_vicinity[bls[NLE_BL_Y], bls[NLE_BL_X]]\n",
    "\n",
    "        # make sure to produce a coipy of the array\n",
    "        observation.update(dict(vicinity=vic.copy()))\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d23967",
   "metadata": {},
   "source": [
    "The strength stats in AD&D 2ed, upon which the mechanics of NetHack is based,\n",
    "comes in two ints: strength and percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle.nethack import (\n",
    "    NLE_BL_STR25,\n",
    "    NLE_BL_STR125,\n",
    ")\n",
    "\n",
    "class NLEFeaturesStrengthPatch(ObservationWrapper):\n",
    "    def observation(self, observation):\n",
    "        bls = observation['blstats'].copy()\n",
    "\n",
    "        # strength percentage is more detailed than `str` stat\n",
    "        # XXX compare src/winrl.cc#L538 with src/attrib.c#L1072-1085\n",
    "        #     e.g. src/dokick.c#L38 sums the transformed str with dex and con\n",
    "        str, prc = bls[NLE_BL_STR125], 0.\n",
    "        if str >= 122:\n",
    "            str = min(str - 100, 25)\n",
    "\n",
    "        elif str >= 19:\n",
    "            str, prc = divmod(19 + str / 50, 1)  # divmod-by-one :)\n",
    "        bls[NLE_BL_STR25] = int(str)\n",
    "        bls[NLE_BL_STR125] = int(prc * 100)  # original step .02, so ok\n",
    "\n",
    "        # replace the original blstats array\n",
    "        observation.update(dict(blstats=bls))\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7194a",
   "metadata": {},
   "source": [
    "The factory for collecting random exploration rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fe6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nle_toolbox.utils import seeding\n",
    "import minihack\n",
    "# env = gym.make(\"MiniHack-River-v0\")\n",
    "\n",
    "def factory(seed=None, folder=None, sticky=False):\n",
    "#     env = gym.make('NetHackChallenge-v0')\n",
    "    env = gym.make(\n",
    "        'MiniHack-Room-Ultimate-15x15-v0',\n",
    "        observation_keys=(\n",
    "            'glyphs',\n",
    "            'chars',\n",
    "            'colors',\n",
    "            'specials',\n",
    "            'blstats',\n",
    "            'message',\n",
    "            'inv_glyphs',\n",
    "            'inv_strs',\n",
    "            'inv_letters',\n",
    "            'inv_oclasses',\n",
    "            'tty_chars',\n",
    "            'tty_colors',\n",
    "            'tty_cursor',\n",
    "            'misc',\n",
    "            'screen_descriptions',\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    from nle.nethack import ACTIONS\n",
    "    ctoa = {chr(a): j for j, a in enumerate(env.unwrapped._actions)}\n",
    "    atoc = tuple(map(chr, env.unwrapped._actions))\n",
    "\n",
    "    # provide seeding capabilities and full action tracking\n",
    "    if folder is None:\n",
    "        env = Replay(env, sticky=sticky)\n",
    "\n",
    "    else:\n",
    "        env = ReplayToFile(env, sticky=sticky, folder=folder, save_on='done')\n",
    "    env.seed(seed)\n",
    "\n",
    "    # patch bugged tty output\n",
    "    env = NLEPatches(env)\n",
    "\n",
    "    # log recent actions\n",
    "    env = RecentHistory(\n",
    "        env,\n",
    "        n_recent=128,\n",
    "        map=lambda a: atoc[a],  # XXX atoc IS NOT a dict!\n",
    "    )\n",
    "\n",
    "    # skippable gui abstraction layer. Excluded if the action space does not\n",
    "    #  hace the SPACE action.\n",
    "    env = Chassis(env, space=ctoa.get(' '), split=False)\n",
    "\n",
    "    # # auto-skip any menu or prompt\n",
    "    # env = AutoEscape(env, escape=ctoa['\\033'])\n",
    "\n",
    "    # a feature extractor to potentially reduce\n",
    "    #  the runtime complexity of the agent.\n",
    "    env = NLEFeaturesVicinity(env, k=3)\n",
    "\n",
    "    # properly handle str and str125 stats\n",
    "    env = NLEFeaturesStrengthPatch(env)\n",
    "\n",
    "    # filter unused observation keys\n",
    "    # XXX this wrapper should be applied before any container-type\n",
    "    #  modifications of the NLE's observation space.\n",
    "    env = ObservationKeyFilter(\n",
    "        env,\n",
    "        # the map, bottom line stats and inventory\n",
    "        'glyphs',\n",
    "        # 'chars',\n",
    "        # 'colors',\n",
    "        # 'specials',\n",
    "        'blstats',\n",
    "        'inv_glyphs',\n",
    "        # 'inv_strs',\n",
    "        # 'inv_letters',\n",
    "        # 'inv_oclasses',\n",
    "\n",
    "        # used for in-notebook rendering\n",
    "        'tty_chars',\n",
    "        'tty_colors',\n",
    "        'tty_cursor',\n",
    "\n",
    "        # used by the GUI abstraction layer (Chassis)\n",
    "        # 'message',\n",
    "        # 'misc',\n",
    "\n",
    "        # extra features produced by the upstream wrappers\n",
    "        'vicinity',\n",
    "        # 'is_objpile',\n",
    "    )\n",
    "\n",
    "    # compute and action mask based on the current NLE mode: gui or play\n",
    "    env = ActionMasker(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a3da8",
   "metadata": {},
   "source": [
    "A renderer for this **factory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7124c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "from time import sleep\n",
    "\n",
    "from nle_toolbox.utils.env.render import render as tty_render\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def ipynb_render(obs, clear=True, fps=None):\n",
    "    if fps is not None:\n",
    "        if clear:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        obs, mask = obs\n",
    "        print(tty_render(**obs))\n",
    "        if fps > 0:\n",
    "            sleep(fps)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644a2ab",
   "metadata": {},
   "source": [
    "We start with implementing a simple command evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71997f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def gui_run(env, *commands):\n",
    "    pipe0 = deque([])\n",
    "    obs, fin = env.reset(), False\n",
    "    for cmd in commands:\n",
    "        if fin:\n",
    "            break\n",
    "\n",
    "        pipe0.extend(cmd)\n",
    "        while pipe0 and not fin:\n",
    "            obs, rew, fin, nfo = env.step(pipe0.popleft())\n",
    "\n",
    "        yield obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e46693",
   "metadata": {},
   "source": [
    "Interesting historical seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaaa8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = None\n",
    "# seed = 13765371332493407478, 12246923801353953927\n",
    "# seed = 12301533412141513004, 11519511065143048485\n",
    "# seed = 1632082041122464284, 11609152793318129379\n",
    "# seed = 5009195464289726085, 12625175316870653325\n",
    "# seed = 8962210393456991721, 8431607288866012881\n",
    "# seed = 14729177660914946268, 9187177962698747861\n",
    "# seed = 16892554419799916328, 6562518563582851317\n",
    "\n",
    "# seed = 12513325507677477210, 18325590921330101247  # Ranger, arrows, dualwields\n",
    "# seed = 1251332550767747710, 18325590921330101247  # Monk, martial arts, single\n",
    "# seed = 125133255076774710, 18325590921330101247  # single\n",
    "# seed = 12604736832047991440, 12469632217503715839  # Wizard, three spells, exploding wand\n",
    "# seed = 14278027783296323177, 11038440290352864458  # valkyrie, dual-wield\n",
    "# seed = 5009195464289726085, 12625175316870653325  # priestess, can loot lots of spells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570ba4d",
   "metadata": {},
   "source": [
    "The code below is used to debug certain events and gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d9c10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with NLEAtoN(factory(seed, sticky=True)) as env:\n",
    "    from nle_toolbox.bot.chassis import get_wrapper\n",
    "    cha = get_wrapper(env, Chassis)\n",
    "\n",
    "    for obs in gui_run(\n",
    "        env,\n",
    "#         ';j:',         # a paragraph about a cat\n",
    "#         'acy',         # break a wand \"of slow\" and blow up\n",
    "        ''\n",
    "    ):\n",
    "        pp.pprint(\n",
    "            (\n",
    "                cha.messages, cha.prompt,  # obs['tty_chars'][0].view('S80')[0].strip(),\n",
    "                cha.in_getlin, cha.in_menu, cha.in_yn_function, cha.xwaitingforspace,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ipynb_render(obs, clear=False, fps=0.01)  # dump(env.env, obs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573960f0",
   "metadata": {},
   "source": [
    "Random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2373af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(obs, n=float('inf'), *, seed=None):\n",
    "    obs, mask = obs\n",
    "    rng, j = np.random.default_rng(seed), 0\n",
    "    while not mask.all() and j < n:\n",
    "        # if we're in LINGER state, pick a random non-forbidden action\n",
    "        # XXX whelp... tilde on int8 is `two's complement`, not the `logical not`\n",
    "        act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "\n",
    "        obs, mask = (yield act)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a67fc9e",
   "metadata": {},
   "source": [
    "Do a limited step run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df767340",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with factory(seed=seed, sticky=True) as env:\n",
    "        cha = get_wrapper(env, Chassis)\n",
    "        msk = get_wrapper(env, ActionMasker)\n",
    "\n",
    "        # init the agent and get its first reaction\n",
    "        gen = random(obs)\n",
    "        act = gen.send(None)\n",
    "\n",
    "        # reset the env and get the initial obs\n",
    "        obs, fin = env.reset(), False\n",
    "        while ipynb_render(obs, clear=True, fps=0.01) and not fin:\n",
    "            obs, rew, fin, info = env.step(act)\n",
    "            act = gen.send(obs)\n",
    "\n",
    "# Although the crawler is an infinite loop\n",
    "#  we still trivially protect against `StopIteration`\n",
    "except StopIteration:\n",
    "    pass\n",
    "\n",
    "finally:\n",
    "    gen.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb157caf",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5264f",
   "metadata": {},
   "source": [
    "### Let's train an A2C agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c6fbc",
   "metadata": {},
   "source": [
    "An object to extract full episodes from their trajectory fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c77184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.tools import EpisodeExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28465837",
   "metadata": {},
   "source": [
    "One step in the joint differentiable rollout collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.engine import step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88b7014",
   "metadata": {},
   "source": [
    "Prepare the runtume context for the advantage-actor-critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.engine import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4069b68",
   "metadata": {},
   "source": [
    "A procedure to collect a differentiable rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(env, agent, npyt, hx, *, n_steps, visualize=None):\n",
    "    \"\"\"Collect a fragment of the trajectory.\"\"\"\n",
    "    # (sys) get a view into numpy's observation arrays\n",
    "    vw_vis = None\n",
    "    if visualize is not None:\n",
    "        vw_vis = plyr.apply(plyr.getitem, npyt.npy.obs, index=visualize)\n",
    "\n",
    "    for j in range(n_steps):\n",
    "        if vw_vis is not None:\n",
    "            ipynb_render(vw_vis, clear=True, fps=0.01)\n",
    "\n",
    "        # (sys) get $(x_t, a_{t-1}, r_t, d_t), v_t, \\pi_t$\n",
    "        ignore, hx = out = step(env, agent, npyt, hx)\n",
    "        yield out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75236c1",
   "metadata": {},
   "source": [
    "Compute the policy gradient surrogate, the entropy and other loss components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea31c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.engine import pyt_polgrad\n",
    "\n",
    "from nle_toolbox.utils.rl.engine import pyt_entropy\n",
    "\n",
    "from nle_toolbox.utils.rl.engine import pyt_critic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2ea52",
   "metadata": {},
   "source": [
    "We shall use GAE in policy gradients and returns for the critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.returns import pyt_ret_gae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1397a",
   "metadata": {},
   "source": [
    "A function to compute the targets (GAE, returns) for policy grads and critic loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c04614",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def pg_targets(rew, val, /, gam, lam, *, fin):\n",
    "    r\"\"\"Compute the targets (GAE, returns) for policy grads and critic loss.\n",
    "\n",
    "    Details\n",
    "    -------\n",
    "    The arguments `rew`, `fin`, and `val` are $r_t$, $d_t$ and $v(s_t)$,\n",
    "    respectively! The td-error terms in GAE depend on $r_{t+1}$, $d_{t+1}$\n",
    "    and on both $v(s_{t+1})$ and $v(s_t)$, hence on `rew[1:]`, `fin[1:]`,\n",
    "    `val[1:]` and `val[:-1]`. `val[-1]` is the value-to-go estimate for\n",
    "    the last state in the related trajectory fragment.\n",
    "    \"\"\"\n",
    "    gae, ret = {}, {}\n",
    "    for k in rew:\n",
    "        ret[k], gae[k] = pyt_ret_gae(\n",
    "            rew[k][1:], fin[1:], val[k],\n",
    "            gam=gam[k], lam=lam[k],\n",
    "        )\n",
    "\n",
    "    return gae, ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbced801",
   "metadata": {},
   "source": [
    "A nested parameter container, which keeps references to the leaf parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97bb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterContainerModule(nn.Module):\n",
    "    \"\"\"Collect base parameters into parameter containers, and containers\n",
    "    into module containers, since `nn.ParameterList` or `nn.ParameterDict`\n",
    "    are actually subclasses of `nn.Module`.\n",
    "    \"\"\"\n",
    "    def __init__(self, parameters):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(parameters, tuple) and hasattr(parameters, '_fields'):\n",
    "            parameters = parameters._asdict()\n",
    "\n",
    "        if isinstance(parameters, (tuple, list)):\n",
    "            for j, it in enumerate(parameters):\n",
    "                setattr(self, str(j), it)\n",
    "\n",
    "        elif isinstance(parameters, dict):\n",
    "            for k, it in parameters.items():\n",
    "                setattr(self, k, it)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, str(key))\n",
    "\n",
    "    def extra_repr(self):\n",
    "        # use ParameterList's extra repr implementation\n",
    "        tmpstr = nn.ParameterList.extra_repr(self)\n",
    "        return '\\n'.join(map(str.strip, tmpstr.splitlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5383f",
   "metadata": {},
   "source": [
    "The following network feeds the **obs**ervation $x_t$, **act**ion $a_{t-1}$, and **rew**ard $r_t$\n",
    "through the provided `features` network to their joint representations. They are then passed into\n",
    "the LSTM core along with the recurrent state `hx` $h_t$, and finally through value and policy heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15241a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.nn import multinomial\n",
    "from nle_toolbox.utils.nn import masked_rnn, rnn_hx_shape\n",
    "from nle_toolbox.utils.nn import LinearSplitter, ModuleDict\n",
    "\n",
    "def masked_multinomial(raw, mask, dim=-1):\n",
    "    \"\"\"Draw a variate from the categorical rv, specified by\n",
    "    the unnormalized logits `raw` at the indicated `dim`, optionally\n",
    "    masked by `mask` boolean array of the same shape as `raw`.\n",
    "    \"\"\"\n",
    "    raw = raw.detach().masked_fill(mask, -float('inf'))\n",
    "    return multinomial(raw.softmax(dim=dim), 1, dim).squeeze(dim)\n",
    "\n",
    "\n",
    "class NLENeuralAgent(nn.Module):\n",
    "    \"\"\"A generic recurrent agent.\"\"\"\n",
    "    def __init__(self, env, features, *, pol, val, core=None, h0=True):\n",
    "        if not isinstance(features, ModuleDict):\n",
    "            raise TypeError('Expected `features` to be a `ModuleDict`,'\n",
    "                            f'got `{type(features)}` instead.')\n",
    "\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "\n",
    "        self.core = nn.Identity()\n",
    "        if isinstance(core, dict):\n",
    "            self.core = nn.LSTM(**core)\n",
    "        \n",
    "        if h0:\n",
    "            # XXX why shoul the agent OWN the initial hx? Make it an external\n",
    "            #  parameter maybe?\n",
    "            h0 = plyr.apply(torch.zeros, rnn_hx_shape(self.core))\n",
    "\n",
    "            # assigning a single element tuple intentionally bypasses nn.Module's\n",
    "            #  parameter registration logic. Furhter more any device moves and\n",
    "            #  dtype changes to the module are reflected in the parameters in-place\n",
    "            #  and thus are still reflected by this nested container, since the\n",
    "            #  Parameter objects themselves are not changed and still referenced.\n",
    "            self._hidden = (plyr.apply(nn.Parameter, h0),)\n",
    "\n",
    "            # let the `nn.Module` machinery handle unstructured `h0`\n",
    "            self.h0 = plyr.apply(\n",
    "                lambda x: x, *self._hidden, _finalizer=ParameterContainerModule)\n",
    "\n",
    "        else:\n",
    "            self._hidden = (None,)\n",
    "            self.register_parameter('h0', None)\n",
    "\n",
    "        self.pol = LinearSplitter(**pol)\n",
    "        self.val = LinearSplitter(**val)\n",
    "\n",
    "    @property\n",
    "    def initial_hx(self):\n",
    "        return self._hidden[0]\n",
    "\n",
    "    def forward(self, obs, act=None, rew=None, hx=None, *, fin=None):\n",
    "        # make sure to extract the mask from the obs\n",
    "        obs, mask = obs\n",
    "\n",
    "        # `.features` is a ModuleDict, which ignores kwargs NOT declared\n",
    "        #  at its `__init__`, which makes `locals()` work really neatly here.\n",
    "        x = self.features(locals())\n",
    "        out, hx = masked_rnn(self.core, x, hx, reset=fin, h0=self.initial_hx)\n",
    "\n",
    "        # sampling before logsoftmax, because masking is\n",
    "        #  applied to unnormalized logits.\n",
    "        pol = self.pol(out)\n",
    "        act = plyr.apply(masked_multinomial, pol, mask)\n",
    "\n",
    "        return act, (\n",
    "            plyr.apply(torch.squeeze, self.val(out), dim=-1),\n",
    "            plyr.apply(F.log_softmax, pol, dim=-1),\n",
    "        ), hx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2709ece",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b592f56",
   "metadata": {},
   "source": [
    "### Redesigning the building blocks of the NLE featrue extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e7595",
   "metadata": {},
   "source": [
    "We simplify the shared glyph embedding layer to rely on glyph entities only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.model.glyph import GlyphEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c74ea",
   "metadata": {},
   "source": [
    "We re-use the original glyph feature extractor layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.bot.model.glyph import GlyphFeatures\n",
    "from einops import rearrange\n",
    "\n",
    "class RestrictedGlyphFeatures(GlyphFeatures):\n",
    "    def __init__(self, glyphs):\n",
    "        super().__init__(glyphs, window=None)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # get the pre-extracted vicinities\n",
    "        gl_vicinity = rearrange(self.glyphs(obs['vicinity']),\n",
    "                                'T B H W C -> T B C H W')\n",
    "        # embed inventory glyphs\n",
    "        # XXX need to replace NO_GLYPH with MAX_GLYPH, unless they coincide.\n",
    "        gl_inventory = rearrange(self.glyphs(obs['inv_glyphs']),\n",
    "                                 'T B N ... -> T B ... N')\n",
    "\n",
    "        return dict(\n",
    "            vicinity=gl_vicinity,\n",
    "            inventory=gl_inventory.contiguous(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de80c5c7",
   "metadata": {},
   "source": [
    "A design of the new embedding:\n",
    "* the vicinity is an ego-centric view into the map\n",
    "* embed entities and their groupd additively\n",
    "* also ad the `ego` embedding offset to the centre of the vicinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from einops import rearrange\n",
    "\n",
    "from typing import Optional\n",
    "from nle_toolbox.utils.env.defs import glyphlut, glyph_group, MAX_ENTITY\n",
    "\n",
    "class GlyphVicinityEmbedding(nn.Module):\n",
    "    \"\"\"The combined ego-centric vicinity - inventory embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # glyph-to-entity embedding\n",
    "        self.entity = nn.Embedding(\n",
    "            MAX_ENTITY + 1, embedding_dim, padding_idx=MAX_ENTITY,\n",
    "        )\n",
    "        self.entity.register_buffer(\n",
    "            'lut', torch.tensor(glyphlut.entity).clone(),\n",
    "        )\n",
    "\n",
    "        # glyph-to-group embedding\n",
    "        self.group = nn.Embedding(\n",
    "            glyph_group.MAX + 1, embedding_dim, padding_idx=glyph_group.MAX,\n",
    "        )\n",
    "        self.group.register_buffer(\n",
    "            'lut', torch.tensor(glyphlut.group).clone(),\n",
    "        )\n",
    "\n",
    "        # ego embedding offset\n",
    "        self.ego = nn.Parameter(torch.randn(1, 1, embedding_dim))\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # get the pre-extracted ego-centric vicinities\n",
    "        vicinity = obs['vicinity']  # XXX or use `GlyphFeatures.forward`\n",
    "        k = vicinity.shape[-1] // 2\n",
    "\n",
    "        # glyph -->> W_e[glyph.entity] + W_g[glyph.group] + ego\n",
    "        ent = self.entity(self.entity.lut[vicinity.long()])\n",
    "        grp = self.group(self.group.lut[vicinity.long()])\n",
    "        ego = F.pad(self.ego, (0, 0,) + (k, k) * 2)  # XXX pad spatial dims\n",
    "\n",
    "        gl_vicinity = rearrange(ent + grp + ego, 'T B H W C -> T B C H W')\n",
    "\n",
    "        # embed inventory glyphs\n",
    "        # XXX need to replace NO_GLYPH with MAX_GLYPH, unless they coincide.\n",
    "        inv = self.entity(self.entity.lut[obs['inv_glyphs'].long()])\n",
    "        gl_inventory = rearrange(inv, 'T B N ... -> T B ... N')\n",
    "\n",
    "        return dict(\n",
    "            vicinity=gl_vicinity,\n",
    "            inventory=gl_inventory.contiguous(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4092a",
   "metadata": {},
   "source": [
    "Now let's redo the bottom line stats: vitals first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class BLSHungerEmbedding(nn.Embedding):\n",
    "    from nle_toolbox.utils.env.defs import hunger\n",
    "    from nle.nethack import NLE_BL_HUNGER\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int = 8,\n",
    "        max_norm: Optional[float] = None,\n",
    "        norm_type: float = 2.0,\n",
    "        scale_grad_by_freq: bool = False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            self.hunger.MAX + 1,\n",
    "            embedding_dim,\n",
    "            padding_idx=self.hunger.MAX,\n",
    "            max_norm=max_norm,\n",
    "            norm_type=norm_type,\n",
    "            scale_grad_by_freq=scale_grad_by_freq,\n",
    "            sparse=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        return super().forward(blstats[..., self.NLE_BL_HUNGER])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42127666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.nn import OneHotBits\n",
    "\n",
    "class BLSConditionEmbedding(nn.Module):\n",
    "    from nle_toolbox.utils.env.defs import condition\n",
    "    from nle.nethack import NLE_BL_CONDITION\n",
    "\n",
    "    def __init__(self, embedding_dim: int = 8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.onehot = OneHotBits(self.condition.N_BITS)\n",
    "        self.linear = nn.Linear(self.condition.N_BITS, embedding_dim)\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        return self.linear(self.onehot(blstats[..., self.NLE_BL_CONDITION]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da939d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.nn import EquispacedEmbedding\n",
    "\n",
    "class BLSVitalsEmbedding(EquispacedEmbedding):\n",
    "    from nle.nethack import (\n",
    "        NLE_BL_HP,\n",
    "        NLE_BL_HPMAX,\n",
    "        NLE_BL_ENE,\n",
    "        NLE_BL_ENEMAX,\n",
    "    )\n",
    "\n",
    "    def __init__(self, num_bins: int):\n",
    "        super().__init__(0, 1, num_bins - 1, scale='lin')\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        hp = blstats[..., self.NLE_BL_HP] / blstats[..., self.NLE_BL_HPMAX]\n",
    "        mp = blstats[..., self.NLE_BL_ENE] / blstats[..., self.NLE_BL_ENEMAX]\n",
    "        return torch.cat([\n",
    "            super().forward(torch.nan_to_num_(hp)),\n",
    "            super().forward(torch.nan_to_num_(mp)),\n",
    "        ], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d628d4",
   "metadata": {},
   "source": [
    "Now we redo the stats and build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597127e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSStatsEmbedding(nn.ModuleDict):\n",
    "    from nle.nethack import (\n",
    "        NLE_BL_STR25,\n",
    "        NLE_BL_STR125,\n",
    "        NLE_BL_DEX,\n",
    "        NLE_BL_CON,\n",
    "        NLE_BL_INT,\n",
    "        NLE_BL_WIS,\n",
    "        NLE_BL_CHA,\n",
    "    )\n",
    "\n",
    "    # 6 base stats (luck is hidden) range 0..25\n",
    "    index = {\n",
    "        'str': NLE_BL_STR25,\n",
    "        # 'strprc': NLE_BL_STR125,  # handled manually\n",
    "        'dex': NLE_BL_DEX,\n",
    "        'con': NLE_BL_CON,\n",
    "        'int': NLE_BL_INT,\n",
    "        'wis': NLE_BL_WIS,\n",
    "        'cha': NLE_BL_CHA,\n",
    "    }\n",
    "\n",
    "    def __init__(self, embedding_dim: int = 16):\n",
    "        stats = {k: nn.Embedding(25 + 1, embedding_dim) for k in self.index}\n",
    "\n",
    "        # embedding (adjusted) percentage strength for warrior classes\n",
    "        stats['strprc'] = EquispacedEmbedding(0, 1, embedding_dim-1, scale='lin')\n",
    "        super().__init__(stats)\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        # deal with\n",
    "        #  'strength_percentage',\n",
    "        #  'str', 'dex', 'con', 'int', 'wis', 'cha',\n",
    "        out = []\n",
    "        for k, j in self.index.items():\n",
    "            out.append(self[k](blstats[..., j]))\n",
    "\n",
    "        out.append(self['strprc'](blstats[..., self.NLE_BL_STR125].div(99)))\n",
    "        return torch.cat(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSArmorClassEmbedding(nn.Embedding):\n",
    "    from nle.nethack import NLE_BL_AC\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int,\n",
    "        max_norm: Optional[float] = None,\n",
    "        norm_type: float = 2.0,\n",
    "        scale_grad_by_freq: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            24,  # the AC is mapped to 24 bins by the lookup table below\n",
    "            embedding_dim,\n",
    "            padding_idx=None,  # no padding index,\n",
    "            max_norm=max_norm,\n",
    "            norm_type=norm_type,\n",
    "            scale_grad_by_freq=scale_grad_by_freq,\n",
    "            sparse=False,\n",
    "        )\n",
    "\n",
    "        # a bin lookup table for armor_class, a categorical variable.\n",
    "        self.register_buffer(\n",
    "            'lookup', torch.tensor(\n",
    "                # 0..10 mapped to 11..1, 11..127 to 0\n",
    "                [*reversed(range(1, 12))] + [0] * 117\n",
    "\n",
    "                # 128..244 mapped to 23, 245..256 to 22..12\n",
    "                + [23] * 117 + [*range(22, 11, -1)]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, blstats: torch.Tensor) -> torch.Tensor:\n",
    "        # 'armor_class' in NetHack is descending just like in adnd. In the\n",
    "        # [code](src/do_wear.c#L2107-2153) it appears that AC is confined\n",
    "        # to the range of a `signed char`, however to adnd 2e mechanics it\n",
    "        # is sufficient to consider the range [-10, 10] for the player's AC,\n",
    "        # since we make d20 rolls anyway.\n",
    "        # https://merricb.com/2014/06/08/a-look-at-armour-class-in-original-dd-and-first-edition-add/\n",
    "        # XXX Also, NetHack, just why?! include/hack.h#L499-500\n",
    "        return super().forward(self.lookup[blstats[..., self.NLE_BL_AC]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b02c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSEncumberanceEmbedding(nn.Embedding):\n",
    "    from nle_toolbox.utils.env.defs import encumberance\n",
    "    from nle.nethack import NLE_BL_CAP\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int = 8,\n",
    "        max_norm: Optional[float] = None,\n",
    "        norm_type: float = 2.0,\n",
    "        scale_grad_by_freq: bool = False,\n",
    "    ):\n",
    "        #  'carrying_capacity'\n",
    "        super().__init__(\n",
    "            self.encumberance.MAX + 1,\n",
    "            embedding_dim,\n",
    "            padding_idx=self.encumberance.MAX,\n",
    "            max_norm=max_norm,\n",
    "            norm_type=norm_type,\n",
    "            scale_grad_by_freq=scale_grad_by_freq,\n",
    "            sparse=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        return super().forward(blstats[..., self.NLE_BL_CAP])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b856aef",
   "metadata": {},
   "source": [
    "The following layer puts all the preceding layers together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91894d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# botl stats that were not accounted for.\n",
    "from nle.nethack import (\n",
    "    NLE_BL_X,\n",
    "    NLE_BL_Y,\n",
    "    NLE_BL_SCORE,\n",
    "    NLE_BL_DEPTH,\n",
    "    NLE_BL_GOLD,\n",
    "    NLE_BL_HD,\n",
    "    NLE_BL_XP,\n",
    "    NLE_BL_EXP,\n",
    "    NLE_BL_TIME,\n",
    "    NLE_BL_DNUM,\n",
    "    NLE_BL_DLEVEL,\n",
    ")\n",
    "\n",
    "class BLSEmbedding(nn.ModuleDict):\n",
    "    bls_map = {\n",
    "        'hunger': BLSHungerEmbedding,\n",
    "        'condition': BLSConditionEmbedding,\n",
    "        'vitals': BLSVitalsEmbedding,\n",
    "        'stats': BLSStatsEmbedding,\n",
    "        'armorclass': BLSArmorClassEmbedding,\n",
    "        'encumberance': BLSEncumberanceEmbedding,\n",
    "    }\n",
    "\n",
    "    def __init__(self, **recipe):\n",
    "        #  ignore `None`\n",
    "        recipe = {k: v for k, v in recipe.items() if v is not None}\n",
    "        if not recipe:\n",
    "            raise RuntimeError(f\"`{type(self).__name__}` got an empty recipe.\")\n",
    "\n",
    "        # check if the ingredietns are dicts\n",
    "        not_dicts = [k for k, v in recipe.items() if not isinstance(v, dict)]\n",
    "        if not_dicts:\n",
    "            raise RuntimeError(f\"These are not dicts: `{not_dicts}`.\")\n",
    "\n",
    "        super().__init__({\n",
    "            k: self.bls_map[k](**v) for k, v in recipe.items()\n",
    "        })\n",
    "\n",
    "    def forward(self, blstats):\n",
    "        return torch.cat([m(blstats) for m in self.values()], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004b57e",
   "metadata": {},
   "source": [
    "Now we put the glyph- and botl- related features in one module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "from nle_toolbox.utils.nn import ModuleDict\n",
    "\n",
    "from nle_toolbox.bot.model.vit import ViTEncoder\n",
    "\n",
    "class GlyphViTEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        radius: int,\n",
    "        embedding_dim: int,\n",
    "        num_attention_heads: int,\n",
    "        intermediate_size: int,\n",
    "        head_size:int = None,\n",
    "        dropout: float = 0.0,\n",
    "        *,\n",
    "        n_layers: int = 1,\n",
    "        b_mean: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.extractor = RestrictedGlyphFeatures(\n",
    "            GlyphEmbedding(embedding_dim),\n",
    "            # window=radius,\n",
    "        )\n",
    "\n",
    "        self.vit = ViTEncoder(\n",
    "            radius + 1 + radius,\n",
    "            embedding_dim,\n",
    "            num_attention_heads,\n",
    "            intermediate_size,\n",
    "            head_size=head_size,\n",
    "            dropout=dropout,\n",
    "            n_layers=n_layers,\n",
    "            b_mean=b_mean,\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        patch = self.extractor(obs)['vicinity']\n",
    "\n",
    "        size = dict(zip(\"TBCHW\", patch.shape[:2]))\n",
    "        out, attn = self.vit(rearrange(patch, 'T B ... -> (T B) ...'))\n",
    "        return rearrange(out, '(T B) ... -> T B ...', **size), \\\n",
    "            rearrange(attn, '(T B) ... -> T B ...', **size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec93ba2",
   "metadata": {},
   "source": [
    "An encoder of glyphs, simpler than ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26525ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "class GlyphSimpleEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        radius: int,\n",
    "        embedding_dim: int,\n",
    "        intermediate_size: int,\n",
    "        dropout: float = 0.0,\n",
    "        kind='old',\n",
    "        **ignore,\n",
    "    ):\n",
    "        n_rows = n_cols = radius + 1 + radius\n",
    "        assert kind in ('old', 'new',)\n",
    "\n",
    "        super().__init__()\n",
    "        if kind == 'new':\n",
    "            self.extractor = GlyphVicinityEmbedding(embedding_dim)\n",
    "\n",
    "        else:\n",
    "            self.extractor = RestrictedGlyphFeatures(\n",
    "                GlyphEmbedding(embedding_dim),\n",
    "                # window=radius,\n",
    "            )\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            Rearrange('B N C -> B (N C)'),\n",
    "            nn.Linear(\n",
    "                (n_rows * n_cols) * embedding_dim,\n",
    "                intermediate_size,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(intermediate_size, intermediate_size, bias=True),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        patch = self.extractor(obs)['vicinity']\n",
    "\n",
    "        size = dict(zip(\"TBCHW\", patch.shape[:2]))\n",
    "        x = rearrange(patch, 'T B C H W -> (T B) (H W) C')\n",
    "\n",
    "        out = self.encoder(x)\n",
    "        out = rearrange(out, '(T B) ... -> T B ...', **size)\n",
    "\n",
    "        return out, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae782e12",
   "metadata": {},
   "source": [
    "A mutating encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlyphEncoder(nn.Module):\n",
    "    def __new__(cls, kind, **passthrough):\n",
    "        if kind == 'vit':\n",
    "            return GlyphViTEncoder(**passthrough)\n",
    "\n",
    "        if kind == 'simple':\n",
    "            return GlyphSimpleEncoder(**passthrough, kind='new')\n",
    "\n",
    "        if kind == 'ego':\n",
    "            return GlyphSimpleEncoder(**passthrough, kind='new')\n",
    "\n",
    "        raise RuntimeError(f'Unknown encoder `{kind}`.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12353904",
   "metadata": {},
   "source": [
    "The combined feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLEFeatures(nn.Module):\n",
    "    def __init__(self, glyphs, blstats, **ignore):\n",
    "        super().__init__()\n",
    "\n",
    "        self.glyphs = GlyphEncoder(**glyphs)\n",
    "        self.blstats = BLSEmbedding(**blstats)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        gl, *ignore = self.glyphs(obs)\n",
    "        bls = self.blstats(obs['blstats'])\n",
    "        return torch.cat((gl, bls,), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f8dd2",
   "metadata": {},
   "source": [
    "Intrinsic motivation via Random Network distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc808030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNDModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        radius: int,\n",
    "        embedding_dim: int,\n",
    "        sizes: list[int],\n",
    "    ):\n",
    "        n_rows = n_cols = radius + 1 + radius\n",
    "\n",
    "        super().__init__()\n",
    "        self.extractor = RestrictedGlyphFeatures(\n",
    "            GlyphEmbedding(embedding_dim),\n",
    "            # window=radius,\n",
    "        )\n",
    "\n",
    "        layers = [\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            Rearrange('B N C -> B (N C)'),\n",
    "            nn.Linear(\n",
    "                (n_rows * n_cols) * embedding_dim,\n",
    "                sizes[0],\n",
    "                bias=True,\n",
    "            ),\n",
    "        ]\n",
    "        for n, m in zip(sizes, sizes[1:]):\n",
    "            layers.append(nn.GELU())\n",
    "            layers.append(nn.Linear(n, m, bias=True))\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        patch = self.extractor(obs)['vicinity']\n",
    "        size = dict(zip(\"TBCHW\", patch.shape[:2]))\n",
    "        x = rearrange(patch, 'T B C H W -> (T B) (H W) C')\n",
    "        return rearrange(self.encoder(x), '(T B) ... -> T B ...', **size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b98cdb",
   "metadata": {},
   "source": [
    "Create the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16 # 256\n",
    "intermediate_size = 128 # 1024\n",
    "\n",
    "recipe = {\n",
    "    'features': {\n",
    "        'glyphs': {\n",
    "            'kind': 'ego',\n",
    "            # radius is currently hardcoded to be `k=3` in `factory()`\n",
    "            'radius': 3,  # (2 + 1 + 2) * (2 + 1 + 2) * embedding_dim\n",
    "            'embedding_dim': embedding_dim,\n",
    "            'num_attention_heads': 4,\n",
    "            'intermediate_size': intermediate_size,\n",
    "            'head_size': None,\n",
    "            'dropout': 0.0,\n",
    "            'n_layers': 1,\n",
    "            'b_mean': False,\n",
    "        },\n",
    "        'blstats': {\n",
    "            'hunger': {'embedding_dim': 5},\n",
    "            'condition': {'embedding_dim': 5},\n",
    "            'vitals': {'num_bins': 5},  # * 2\n",
    "            'stats': None,  # {'embedding_dim': 5},  # * (6 + 1)\n",
    "            'armorclass': None,  # {'embedding_dim': 5},\n",
    "            'encumberance': None,  # {'embedding_dim': 5},\n",
    "        },  # (4 + 7 + 2) * 5\n",
    "    },\n",
    "    'core': {\n",
    "        'input_size':  4 * 5 + intermediate_size, # (4 + 7 + 2) * 5 + intermediate_size,\n",
    "        'hidden_size': 128,\n",
    "        'num_layers': 2,  # it appears that more layers makes the agent learn more than nothing!\n",
    "    },\n",
    "    'pol': {\n",
    "        'in_features': 128,\n",
    "        'out_features': 8,  # len(ActionMasker._raw_nethack_actions)\n",
    "    },\n",
    "    'val': {\n",
    "        'in_features': 128,\n",
    "        'out_features': {\n",
    "            'ext': 1,\n",
    "            'int': 1,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "rnd_recipe = {\n",
    "    'radius': 3,  # hardcoded! see `factory()`\n",
    "    'embedding_dim': embedding_dim,  # 32,\n",
    "    'sizes': [\n",
    "        intermediate_size,  # 256,\n",
    "        16,  # 32,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8f3c1",
   "metadata": {},
   "source": [
    "The fragmented a2c parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffdb847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project='nle-toolbox',\n",
    "    job_type='nethack',\n",
    "    tags=[\n",
    "        'VicinityWrapper',\n",
    "        'ego',\n",
    "#         'ViT',\n",
    "    ],\n",
    "    # mode='disabled',\n",
    "    config=dict(\n",
    "        # int weight in the gae mix for the polgrads\n",
    "        f_alpha=0.5,\n",
    "\n",
    "        # extrinsic/intrinsic reward PV discount\n",
    "        f_gamma={'ext': 0.999, 'int': 0.99},\n",
    "\n",
    "        # the GAE discount\n",
    "        f_lambda={'ext': 0.96, 'int': 0.96},\n",
    "\n",
    "        # the share of the runtime state's hx's gard to be passed to h0\n",
    "        f_h0_lerp=0.05,\n",
    "\n",
    "        # critic (both ext and int) and entropy weights in the loss\n",
    "        C_pg=1.,\n",
    "        C_critic={'ext': 0.5, 'int': 0.5},\n",
    "        C_entropy=0.01,\n",
    "\n",
    "        # the truncated-bptt length rollout\n",
    "        n_fragment_length=20,\n",
    "\n",
    "        # the number of envs run simultaneously\n",
    "        n_batch=16,\n",
    "\n",
    "        # the total number of steps allotted to training (summed across all envs)\n",
    "        n_total=2_592_000 * 6,\n",
    "\n",
    "        # also track the recipes\n",
    "        recipe=recipe,\n",
    "        rnd_recipe=rnd_recipe,\n",
    "    ),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d43ff",
   "metadata": {},
   "source": [
    "Create the vectorized env and the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0623ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.engine import SerialVecEnv\n",
    "\n",
    "env = SerialVecEnv(factory, n_envs=wandb.config.n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd63e21",
   "metadata": {},
   "source": [
    "Build an agent and the RND motivator from the recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nle_toolbox.bot.model.network import NetworkFeatures\n",
    "from collections import OrderedDict\n",
    "\n",
    "agent = NLENeuralAgent(env, **{\n",
    "    **recipe,\n",
    "    'features': ModuleDict({\n",
    "        # XXX ignores kwargs not declared at `__init__`\n",
    "        'obs': NLEFeatures(**recipe['features']),\n",
    "    }, dim=-1)\n",
    "})\n",
    "\n",
    "rnd = ModuleDict(dict(\n",
    "    target=RNDModule(**rnd_recipe).requires_grad_(False),\n",
    "    online=RNDModule(**rnd_recipe),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4e33d",
   "metadata": {},
   "source": [
    "Reset the bias terms in the recurrent core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init\n",
    "from nle_toolbox.utils.nn import rnn_reset_bias\n",
    "\n",
    "agent.apply(rnn_reset_bias);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33113c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc8da7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1eb51",
   "metadata": {},
   "source": [
    "A clunky tool to split the parameters into biases and weights.\n",
    "\n",
    "Unlike `.bias` parameters, which **should not** be decayed, not every `.weight` parameter\n",
    "**should be** decayed. For example, learnt positional encodings can be seen as bias terms\n",
    "to the \"linear\" operation effected by an `nn.Embedding`, at the same time ordinary token\n",
    "embeddings should also not be decayed either, since they effectively serve as the input\n",
    "data representation.\n",
    "\n",
    "`nn.LayerNorm` layers perform within-layer normalization and then re-scale and translate\n",
    "it, meaning that their weight should be regularized to unit scales ant not zeros.\n",
    "\n",
    "Hence:\n",
    "* all biases, and weights of `nn.LayerNorm` and `nn.Embedding` should not be regularized\n",
    "by weight decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_parameters(module):\n",
    "    decay, no_decay, seen = [], [], set()\n",
    "    for prefix, mod in module.named_modules():\n",
    "        for name, par in mod.named_parameters(prefix='', recurse=False):\n",
    "            assert par not in seen\n",
    "            seen.add(par)\n",
    "\n",
    "            # always exclude bias terms\n",
    "            if name.startswith('bias'):\n",
    "                no_decay.append(par)\n",
    "\n",
    "            # but always decay dense linear weights\n",
    "            elif name.startswith('weight') and isinstance(\n",
    "                mod, (nn.Linear, nn.LSTM)\n",
    "            ):\n",
    "                decay.append(par)\n",
    "\n",
    "            # yet never decay normalization translations and embedding representations\n",
    "            elif name.startswith('weight') and isinstance(\n",
    "                mod, (nn.LayerNorm, nn.Embedding)\n",
    "            ):\n",
    "                no_decay.append(par)\n",
    "\n",
    "            elif name in ('posemb', 'cls') and isinstance(\n",
    "                mod, (ViTEncoder,)\n",
    "            ):\n",
    "                no_decay.append(par)\n",
    "\n",
    "            else:\n",
    "                no_decay.append(par)\n",
    "                # raise TypeError(f'Unrecognized parameter `{name}` in `{prefix}` {mod}.')\n",
    "\n",
    "    return decay, no_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b500ed",
   "metadata": {},
   "source": [
    "Adam with high `weight_decay` may push many parameters' values\n",
    "into denormalized fp mode, which is ultra slow on CPU (but not\n",
    "as bad on GPU), see the answer and a reply form *njuffa* in to\n",
    "this [stackoverflow](https://stackoverflow.com/questions/36781881)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbe708",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_flush_denormal(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4f5545",
   "metadata": {},
   "source": [
    "Init agent's optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ca95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decay, no_decay = split_parameters(agent)\n",
    "\n",
    "# AdamW doesnt do what you expect it to do, Ivan! (although it\n",
    "#  correctly decouples the objective's grad and the ell-2 weight reg).\n",
    "#  See https://arxiv.org/abs/1711.05101.pdf\n",
    "agent.optim = torch.optim.AdamW([\n",
    "    dict(params=decay),\n",
    "    dict(params=no_decay, weight_decay=0.),\n",
    "], lr=1e-3, eps=1e-5, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a27a7",
   "metadata": {},
   "source": [
    "An optimizer for the RND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fa267",
   "metadata": {},
   "outputs": [],
   "source": [
    "decay, no_decay = split_parameters(rnd.online)\n",
    "rnd.optim = torch.optim.AdamW([\n",
    "    dict(params=decay),\n",
    "    dict(params=no_decay, weight_decay=0.),\n",
    "], lr=1e-3, eps=1e-5, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5529759",
   "metadata": {},
   "source": [
    "Cache the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b764657",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = wandb.config.n_total\n",
    "n_fragment_length = wandb.config.n_fragment_length\n",
    "n_batch = wandb.config.n_batch\n",
    "\n",
    "f_lambda = wandb.config.f_lambda\n",
    "f_gamma = wandb.config.f_gamma\n",
    "f_alpha = wandb.config.f_alpha\n",
    "f_h0_lerp = wandb.config.f_h0_lerp\n",
    "\n",
    "C_pg = wandb.config.C_pg\n",
    "C_entropy = wandb.config.C_entropy\n",
    "C_critic = wandb.config.C_critic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e0e50",
   "metadata": {},
   "source": [
    "Progress bar update and termination condition checker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587f6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def progress(bar, n):\n",
    "    bar.update(n - bar.n)\n",
    "    return n < bar.total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc338825",
   "metadata": {},
   "source": [
    "a service function to get diagnostic stats from an episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c335d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nle_toolbox.utils.env.defs import MAX_ENTITY\n",
    "\n",
    "def ep_stats(ep):\n",
    "    # episode duration and total score\n",
    "    n_length = len(ep.fin) - int(ep.fin[-1])\n",
    "    f_score = float(ep.rew[1:].sum())\n",
    "\n",
    "    # count the number of unique glyphs seen during the episode\n",
    "    off = -1 if ep.fin[-1] else None  # end-of-episode/reset corrrection\n",
    "    vic = ep.obs[0]['vicinity'][:off]\n",
    "    cnt = torch.bincount(vic.flatten(), minlength=MAX_ENTITY + 1)\n",
    "    n_unique = int(cnt.gt(0).sum())\n",
    "\n",
    "    # compute the entropy of the discrete distribution. This is\n",
    "    #  a good proxy for the diversity, since it measures the amoun\n",
    "    #  of information content the encountered glyphs signal.\n",
    "    proba = cnt.div(cnt.sum())\n",
    "    f_ent = F.kl_div(proba.new_zeros(()), proba, reduction='sum').neg()\n",
    "\n",
    "    return n_length, f_score, n_unique, float(f_ent) / math.log(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfceb44",
   "metadata": {},
   "source": [
    "learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1f7db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "n_steps, epx = 0, EpisodeExtractor()\n",
    "npyt, hx = prepare(env, rew=0., fin=True), None\n",
    "with tqdm.tqdm(\n",
    "    initial=n_steps, total=n_total, ncols=80, disable=False,\n",
    ") as bar:\n",
    "    while progress(bar, n_steps):\n",
    "        # (sys) collect a fragment of the episode time `t` afterstates, t=0..N-1\n",
    "        fragment, hxx = zip(*collect(\n",
    "            env, agent, npyt, hx, n_steps=n_fragment_length, visualize=None,\n",
    "        ))\n",
    "\n",
    "        # (sys) bootstrap the one-step value-to-go approximation\n",
    "        # XXX do not update `npyt` and `hx`! Also be careful not to\n",
    "        # add this last record to the trajectory!\n",
    "        input = plyr.apply(torch.clone, npyt.pyt)\n",
    "        act_, (val_, pol_), _ = agent(**input._asdict(), hx=hxx[-1])\n",
    "        fragment += ((input, val_, pol_),)\n",
    "\n",
    "        # (sys) repack data ((x_t, a_{t-1}, r^E_t, d_t), v_t, \\pi_t)\n",
    "        input, val, pol = plyr.apply(torch.cat, *fragment, _star=False)\n",
    "        # XXX note, `.act[t]` is $a_{t-1}$, but the other `*[t]` are $*_t$,\n",
    "        #  e.g. `.rew[t]` is $r_t$, and `pol[t]` is `$\\pi_t$.\n",
    "\n",
    "        # (sys) retain running state `hx`, but detach its grads (truncated bptt)\n",
    "        # XXX although val[-1] is used as a non-diffable bootstrap for value-to-go\n",
    "        #  estimate, and pol[-1] does not participates in either policy-grad nor\n",
    "        #  the entropy computation, it is imperative that we DO NOT `.detach` prior\n",
    "        #  to computing these values. Although torch does not backprop through unused\n",
    "        #  tensors, for some reason, it destabilizes a reference implementation.\n",
    "        hx = plyr.apply(torch.Tensor.detach, hxx[-1])\n",
    "\n",
    "        # (sys) pass some feedback from the next fragment into `h0` by lerp-ing\n",
    "        #  from `hx` to `h0`. `.lerp` does all the necessary broadcasting itself.\n",
    "        #    `hx <<-- (1 - w) * hx + w * h0`\n",
    "        if f_h0_lerp > 0:\n",
    "            hx = plyr.apply(torch.lerp, hx, agent.initial_hx, weight=f_h0_lerp)\n",
    "\n",
    "        # (sys) extract episode strands\n",
    "        # XXX the current `input` overlaps the next one! due to the one-step-ahead bootstrap\n",
    "        episodes = epx.extract(\n",
    "            input.fin[:-1], plyr.apply(lambda t: t[:-1], input)\n",
    "        )\n",
    "\n",
    "        # (rnd) compute the diff-able intrinsic reward\n",
    "        #     r^I_t = \\frac12 \\| f(x_t) - \\bar{f}(x_t) \\|, t=0..N\n",
    "        # XXX we use huber loss and clamp the intinsic rewards to [0, 1]\n",
    "        with torch.no_grad():\n",
    "            rnd_target = rnd.target(input.obs[0])\n",
    "        rnd_mse = F.mse_loss(\n",
    "            rnd.online(input.obs[0]), rnd_target, reduction='none',\n",
    "        ).sum(-1)\n",
    "\n",
    "        rew_int = rnd_mse.detach()  # .clamp(max=1)  # torch.zeros_like(input.rew)\n",
    "\n",
    "        # (gae) compute the extrinsic GAE and returns\n",
    "        # XXX `rew`, `fin`, `val` are $r_t$, $d_t$ and $v(s_t)$!\n",
    "        rew = {'ext': input.rew, 'int': rew_int}\n",
    "        gae, ret = pg_targets(rew, val, f_gamma, f_lambda, fin=input.fin)\n",
    "        # XXX had we used `plyr.apply()` we would need to invert the structure\n",
    "\n",
    "        # (sys) policy grad surrogate (uses common gae!)\n",
    "        # XXX r_{t+1}, v_t, v{t+1} -->> A_t \\log \\pi_t(a_t)\n",
    "        adv = gae['ext'].add(gae['int'], alpha=f_alpha).detach()\n",
    "        pg_gae = plyr.apply(pyt_polgrad, pol, input.act, adv=adv)\n",
    "\n",
    "        # (sys) entropy of the policy\n",
    "        # XXX kl-div computes \\sum_n e^{\\log p_n} \\log p_n, so we flip the sign\n",
    "        entropy = plyr.apply(pyt_entropy, pol)\n",
    "\n",
    "        # (sys) extrinsic critic loss\n",
    "        critic = plyr.apply(pyt_critic, val, ret)\n",
    "\n",
    "        # (sys) compute the loss\n",
    "        loss = \\\n",
    "            - pg_gae * C_pg \\\n",
    "            - entropy * C_entropy \\\n",
    "            + critic['ext'] * (C_critic['ext'] / 2) \\\n",
    "            + critic['int'] * (C_critic['int'] / 2)\n",
    "\n",
    "        loss_rnd = rnd_mse.sum() / 2\n",
    "\n",
    "        # (sys) backprop through the agent and the online network of RND\n",
    "        # XXX this would fail if there is gradient leakage between RND\n",
    "        #  and the agent.\n",
    "        agent.optim.zero_grad()\n",
    "        rnd.optim.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        loss_rnd.backward()\n",
    "        grad = clip_grad_norm_(agent.parameters(), 5.)\n",
    "\n",
    "        agent.optim.step()\n",
    "        rnd.optim.step()\n",
    "\n",
    "        # (sys) incerment the step count\n",
    "        n_steps += n_fragment_length * n_batch\n",
    "\n",
    "        # (log) the training progress\n",
    "        with torch.no_grad():\n",
    "            if episodes:\n",
    "                dur_, ret_, unq_, div_ = \\\n",
    "                    map(np.median, zip(*map(ep_stats, episodes)))\n",
    "                wandb.log({\n",
    "                    'metrics/return': float(ret_),\n",
    "                    'metrics/duration': float(dur_),\n",
    "                    'metrics/n_unique': float(unq_),\n",
    "                    'metrics/diversity': float(div_),\n",
    "                }, commit=False)\n",
    "\n",
    "            wandb.log({\n",
    "                'n_steps': n_steps,\n",
    "                'loss/loss': float(loss),\n",
    "                'loss/ext': float(critic['ext']),\n",
    "                'loss/int': float(critic['int']),\n",
    "                'loss/entropy': float(entropy) / (n_fragment_length * n_batch),\n",
    "                'loss/pg': float(pg_gae),\n",
    "                'loss/rnd': float(loss_rnd),\n",
    "            })\n",
    "            bar.set_postfix_str(f\"{float(loss):10.1e} {float(grad):10.1e}\")\n",
    "\n",
    "    # (sys) extract the residual episode strands\n",
    "    unfninished = epx.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nle_toolbox.utils.io import mkstemp\n",
    "\n",
    "\n",
    "target = os.path.abspath('./checkpoints')\n",
    "os.makedirs(target, exist_ok=True)\n",
    "\n",
    "checkpoint = mkstemp('.pt', f'ckpt__vit__{n_steps}__', dir=target)\n",
    "torch.save({\n",
    "    'agent': agent.state_dict(),\n",
    "    'agent.optim': agent.optim.state_dict(),\n",
    "    'rnd': rnd.state_dict(),\n",
    "    'rnd.optim': rnd.optim.state_dict(),\n",
    "    'config': dict(wandb.config),\n",
    "}, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b44bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.finish(quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e8094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc; gc.collect(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a774a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02820413",
   "metadata": {},
   "source": [
    "We finally got something:\n",
    "* reducing the dim of the RND output vector from 64 to 16 was, perhaps,\n",
    "the most significant step in the direction of the agent learning at least\n",
    "something.\n",
    "* the next thing was removing the build embedding and using `condition`,\n",
    "`hunger`, and `vitals\n",
    "* the effect of positive `f_h0_lerp` has not been investigated\n",
    "  * reducing it from `.05` to `0.0` seems to **adversely** impact learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100e217",
   "metadata": {},
   "source": [
    "Next idea to try: like token + position in in GERT and GPT, let's exploit additive embeddings.\n",
    "* in glyphs: entity + group embedding -- entities semantics is modulated by its group (relevant to MON, PET, RIDE, STATUE), also add special `ego`-embedding at the centre of vicinity.\n",
    "Let $g_{uv} \\in \\mathbb{G}$ be glyph at position $u, v$ relative to the `hero` (bls-x, -y coords).\n",
    "$$\n",
    "f_{uv}\n",
    "    = w_E\\bigl[\\operatorname{entity}(g_{uv})\\bigr]\n",
    "    + w_G\\bigl[\\operatorname{group}(g_{uv})\\bigr]\n",
    "    + 1_{(0,0)}{(u, v)} w_{\\mathrm{ego}}\n",
    "  \\,, $$\n",
    "where $w_\\cdot$ are game map-related embeddings\n",
    "* in blstats: modulate an `ego`-embedding by the `vitals`, `condition` and other stats' embeddings.\n",
    "  * should the the `ego`-embedding be shared between map and state?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95345e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce1f33",
   "metadata": {},
   "source": [
    "A ranked buffer for episode rollouts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0fc1de",
   "metadata": {},
   "source": [
    "* what do we do with the missing `hx`? clone episodes in full?\n",
    "  * `you wake up on a cold stone floor in the middle of a vast chamber without a shred of memoery of how you got here. What do you do?` maybe it is OK to take contiguous fragments of a long episode and start with a wiped out memory.\n",
    "* do we clone just the actions, or also the value function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a3392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heapreplace, heappushpop, heappush, heappop\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any\n",
    "\n",
    "class RankedBuffer:\n",
    "    @dataclass(order=True, frozen=True, repr=False)\n",
    "    class RankedItem:\n",
    "        rank: float\n",
    "        item: Any = field(compare=False)\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = []\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def push(self, rk, it):\n",
    "        item = self.RankedItem(rk, it)\n",
    "        # push the current item\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            return heappush(self.buffer, item)\n",
    "        # ... pop the lowest-ranking one, if we exceed capacity\n",
    "        return heappushpop(self.buffer, item)\n",
    "\n",
    "    def extend(self, pairs):\n",
    "        last = None\n",
    "        for rk, it in pairs:\n",
    "            last = self.push(rk, it)\n",
    "        return last\n",
    "\n",
    "    def __bool__(self):\n",
    "        return bool(self.buffer)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.buffer[index]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return type(self).__name__ + f\"({len(self.buffer)}/{self.capacity})\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        return ((el.rank, el.item) for el in self.buffer)\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        n_samples=8,\n",
    "        n_steps=64,\n",
    "        *,\n",
    "        rng=np.random.default_rng(),\n",
    "    ):\n",
    "        # determinie the sufficiently long episodes\n",
    "        eligible = []\n",
    "        for j, ep in enumerate(self.buffer):\n",
    "            input, val, pol = ep.item\n",
    "            dur_ = len(input.fin) - int(input.fin[-1])\n",
    "            if dur_ < n_steps:\n",
    "                continue\n",
    "\n",
    "            eligible.append((j, dur_,))\n",
    "\n",
    "        # sample starting strands from episodes\n",
    "        chunks = []\n",
    "        for i in rng.choice(len(eligible), size=n_samples):\n",
    "            k, dur_ = eligible[i]\n",
    "            j = rng.integers(dur_ - n_steps + 1)\n",
    "\n",
    "            chunk = plyr.apply(lambda t: t[j:j + n_steps],\n",
    "                               self.buffer[k].item)\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        return plyr.apply(torch.stack, *chunks, _star=False, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c474ee9",
   "metadata": {},
   "source": [
    "A procedure to get the likelihood of actions uder a given policy sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ac259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.rl.returns import pyt_vtrace\n",
    "\n",
    "def logpact(logpol, act):\n",
    "    # (sys) get \\log\\mu_t(a_t) from `logpol[t][act[t+1]])`, t=0..T-1\n",
    "    return logpol[:-1].gather(-1, act[1:].unsqueeze(-1)).squeeze_(-1)\n",
    "\n",
    "def td_target(rew, fin, val, *, gam):\n",
    "    # add extra trailing unitary dims for broadcasting\n",
    "    fin_ = fin.reshape(fin.shape + (1,) * max(rew.ndim - fin.ndim, 0))\n",
    "    gam_ = rew.new_full(fin_.shape, gam).masked_fill_(fin_, 0.)\n",
    "    return torch.addcmul(rew, gam_, val[1:])\n",
    "\n",
    "@torch.no_grad()\n",
    "def pyt_impala(rew, fin, act, val, pol, myuval, myupol, *, gam, r_bar, c_bar):\n",
    "    rho = logpact(pol, act) - logpact(myupol, act)\n",
    "    vtr = pyt_vtrace(rew[1:], fin[1:], myuval, rho=rho,\n",
    "                     gam=gam, r_bar=r_bar, c_bar=c_bar)\n",
    "\n",
    "    # [O(T B F)] get the importance-weighted td(0) errors\n",
    "    adv = td_target(rew[1:], fin[1:], vtr, gam=gam)\n",
    "    rho_ = rho.reshape(rho.shape + (1,) * max(rew.ndim - fin.ndim, 0))\n",
    "    rho_.exp_().clamp_(max=r_bar)\n",
    "    adv.sub_(val[:-1]).mul_(rho_)\n",
    "\n",
    "    return vtr[:-1], adv, rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b2124",
   "metadata": {},
   "source": [
    "Compute the exploration metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65435df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle.nethack import NLE_BL_SCORE\n",
    "from nle_toolbox.utils.env.defs import GLYPH_CMAP_OFF, symbol\n",
    "\n",
    "def ep_metrics(ep, *, S_stone=symbol.S_stone + GLYPH_CMAP_OFF):\n",
    "    met = {}\n",
    "\n",
    "    # convert to numpy and determine the offset for unfinished episodes\n",
    "    npy = plyr.apply(np.asarray, ep)\n",
    "    off = int(npy.fin[-1])\n",
    "    if len(npy.fin) <= off:\n",
    "        return met\n",
    "\n",
    "    obs, msk = npy.obs\n",
    "\n",
    "    # score the episode\n",
    "    met['ret'] = float(npy.rew[1:].sum())\n",
    "    met['scr'] = obs['blstats'][-1-off, NLE_BL_SCORE]\n",
    "\n",
    "    # coverage and action effectiveness\n",
    "    gly = obs['glyphs'][:(-1 if off > 0 else None)]\n",
    "    # XXX we exclude the terminal obs, because it is actually the init\n",
    "    #  obs from the next episode\n",
    "    non_stone = (gly != S_stone).mean((-2, -1))\n",
    "    met['cov'] = non_stone.max() / non_stone.min()\n",
    "    met['eff'] = sum((g0 != g1).mean() for g0, g1 in zip(gly, gly[1:]))\n",
    "\n",
    "    met['len'] = len(npy.fin) - off\n",
    "\n",
    "    return met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ad74d",
   "metadata": {},
   "source": [
    "A common routine to plot the computed rollout metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912caf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ep_metrics(metrics):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(7, 3), dpi=300)\n",
    "\n",
    "    out_ = plyr.apply(list, *metrics, _star=False)\n",
    "    for ax, (nom, val) in zip(axes.flat, out_.items()):\n",
    "        ax.hist(val, label=nom, log=nom in ('scr', 'ret',), bins=20)\n",
    "        ax.set_title(nom)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581980a",
   "metadata": {},
   "source": [
    "Rank the peisode and put it into a buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_episodes(buf, iterable, *, C_cov=0.1):\n",
    "    for input, val, pol in iterable:\n",
    "        met = ep_metrics(input)\n",
    "        if not met:\n",
    "            continue\n",
    "\n",
    "        rk = met['ret'] + C_cov * met['cov'] / met['len']\n",
    "        buf.push(rk, (input, val, pol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d968e61",
   "metadata": {},
   "source": [
    "Prepare a strand extractor and a buffer for ranking episodes, and ready the vectorized env and the runtime context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9beda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epx, buf = EpisodeExtractor(), RankedBuffer(128)\n",
    "metrics = []\n",
    "\n",
    "env = SerialVecEnv(factory, n_envs=4)\n",
    "npyt, hx = prepare(env, rew=0., fin=True), None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb692ae",
   "metadata": {},
   "source": [
    "A visualized evaluation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = 16384\n",
    "n_steps, visualize = 0, 0\n",
    "with torch.no_grad(), tqdm.tqdm(\n",
    "    initial=n_steps, total=n_total, ncols=80,\n",
    "    disable=visualize is not None,\n",
    ") as bar:\n",
    "    while progress(bar, n_steps):\n",
    "        # (sys) collect a fragment of the episode time `t` afterstates, t=0..N-1\n",
    "        fragment, hxx = zip(*collect(env, agent, npyt, hx, n_steps=128, visualize=visualize))\n",
    "        # XXX `fragment` is ((x_t, a_{t-1}, r_t, d_t), v_t, \\mu_t), t=0..N-1\n",
    "\n",
    "        # (sys) retain running state `hx`, but detach its grads (truncated bptt)\n",
    "        # ATTN do not update `npyt` and `hx`!\n",
    "        hx = plyr.apply(torch.Tensor.detach, hxx[-1])\n",
    "\n",
    "        # (sys) repack the fragment data\n",
    "        # XXX note, `.act[t]` is $a_{t-1}$, but the other `*[t]` are $*_t$,\n",
    "        #  e.g. `.rew[t]` is $r_t$, and `pol[t]` is `$\\pi_t$.\n",
    "        input, _, _ = fragment = plyr.apply(torch.cat, *fragment, _star=False)\n",
    "\n",
    "        # (sys) incerment the step count\n",
    "        n_steps += input.fin.numel()\n",
    "\n",
    "        # (sys) extract episode strands with log-probs of the taken actions\n",
    "        episodes = epx.extract(input.fin, fragment)\n",
    "        add_episodes(buf, episodes, C_cov=0.5)\n",
    "\n",
    "        # (evl) compute the metrics of the completed episodes\n",
    "        for input_, val_, pol_ in episodes:\n",
    "            met = ep_metrics(input_)\n",
    "            if met:\n",
    "                metrics.append(met)\n",
    "\n",
    "    # (sys) extract the residual episode strands\n",
    "    unfinished = epx.finish()\n",
    "    add_episodes(buf, unfinished, C_cov=0.5)\n",
    "\n",
    "plot_ep_metrics(metrics);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83057d58",
   "metadata": {},
   "source": [
    "The stats of the episodes in the buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac750ab7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "out, fps = [], None\n",
    "for rk, (input, val, pol) in buf:\n",
    "    npy = plyr.apply(np.asarray, input)\n",
    "    off = int(npy.fin[-1])  # offset for unfinished strands\n",
    "    for t in range(len(npy.fin) - off):\n",
    "        obs = plyr.apply(plyr.getitem, npy.obs, index=t)\n",
    "        ipynb_render(obs, fps=fps)\n",
    "\n",
    "    met = ep_metrics(input)\n",
    "    if met:\n",
    "        out.append(met)\n",
    "\n",
    "plot_ep_metrics(out);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c99984",
   "metadata": {},
   "source": [
    "Get ready to clone the successful episodes in the ranked buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58af4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_steps = 8, 64\n",
    "r_bar, c_bar = 1.01, 1.1\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac996af",
   "metadata": {},
   "source": [
    "Behaviour cloning\n",
    "* let's have a look at [Self-Imitation Learning](https://proceedings.mlr.press/v80/oh18b.html)\n",
    "> ... off-policy actor-critic algorithm that learns to reproduce the agents past good decisions.\n",
    "... that exploiting past good experiences can indirectly drive deep exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbffca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in tqdm.tqdm(range(50), ncols=70):\n",
    "    # sample a bath of trajectory fragments\n",
    "    input, myuval, myupol = buf.sample(n_samples, n_steps, rng=rng)\n",
    "\n",
    "    # recompute the policy and value-to-go estimates for the episode\n",
    "    # XXX amnesia training: forget the hx\n",
    "    _, (val, pol), _ = agent(input.obs, input.act, input.rew, hx=None, fin=None)\n",
    "    # XXX this is not EXACTLY identical to `fin=ep_.fin`, which is guaranteed\n",
    "    #  to contain a reset `fin[0]` and possibly a `fin[-1]` (not in case when\n",
    "    #  the episode is unfinished). We ignore pol[-1] $\\pi_{T}$ and val[-1]\n",
    "    #  $v(s_{T})$, both of which pertain to the next episode. `fin` affects\n",
    "    #  only the recurrrent state anyway and 1) we set the initial to `None`,\n",
    "    #  and 2) do not ever use the\n",
    "\n",
    "    L_loglik = pyt_polgrad(pol, input.act, adv=1.)\n",
    "    ell = - L_loglik\n",
    "\n",
    "    # get the v-trace target for the critic and the advantages to pol-grad\n",
    "    # XXX here `.fin[-1]` properly blocks the last state-value backup\n",
    "#     ret, _, rho = pyt_impala(\n",
    "#         input.rew, input.fin, input.act,\n",
    "#         val['ext'], pol, myuval['ext'], myupol,\n",
    "#         gam=f_gamma['ext'], r_bar=r_bar, c_bar=c_bar\n",
    "#     )\n",
    "#     L_critic = pyt_critic(val['ext'], ret)\n",
    "\n",
    "#     ell = (L_critic * (C_critic['ext'] / 2) - L_loglik)\n",
    "\n",
    "    agent.optim.zero_grad()\n",
    "    ell.backward()\n",
    "    agent.optim.step()\n",
    "\n",
    "#     losses.append((float(L_loglik), float(L_critic)))\n",
    "    losses.append((float(L_loglik),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_loglik, = map(np.array, zip(*losses))\n",
    "\n",
    "plt.semilogy(-L_loglik, c='C1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae1f46",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e352394",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # `(W_ii|W_if|W_ig|W_io)`\n",
    "    blsw = agent.core.weight_ih_l0[:, 128:]\n",
    "    blsw = blsw.reshape(len(blsw), -1, 5)\n",
    "    norms = blsw.norm(p=2, dim=-1)\n",
    "\n",
    "norms = dict(zip([\n",
    "    'hunger', 'status', 'hp', 'mp',\n",
    "    'str', 'dex', 'con', 'int', 'wis', 'cha',\n",
    "    'strprc', 'AC', 'encumberance',\n",
    "], norms.T))\n",
    "\n",
    "breaks = 0, 128, 256, 384, 512\n",
    "c_pair = \"C0\", \"C1\"\n",
    "fig, axes = plt.subplots(2,2, figsize=(7, 7,), dpi=300, sharey=True, sharex=True)\n",
    "for nom, ax in zip(norms, axes.flat):\n",
    "    ax.semilogy(norms[nom], label=nom)\n",
    "    for j, (a, b) in enumerate(zip(breaks[1:], breaks)):\n",
    "        ax.axvspan(a, b, color=c_pair[j&1], alpha=0.05, zorder=-10)\n",
    "\n",
    "    ax.legend(fontsize='xx-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e323d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ef74e61",
   "metadata": {},
   "source": [
    "import pdb ; pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plyr.ragged(lambda v, C: C * v.sum(), pg, C_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = []\n",
    "plyr.ragged(lambda v, C: flat.append(C * v), pg_gae, C_pg)\n",
    "plyr.ragged(lambda v, C: flat.append(C * v), entropy, C_entropy)\n",
    "plyr.ragged(lambda v, C: flat.append(C * v), critic, C_critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4529833",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eeb387",
   "metadata": {},
   "source": [
    "Remove currently unused fileds from the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4addd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.env.defs import MAX_GLYPH\n",
    "\n",
    "def filter(\n",
    "    glyphs,\n",
    "    blstats,\n",
    "    inv_letters,\n",
    "    inv_glyphs,\n",
    "    **ignore,\n",
    "):\n",
    "    return dict(\n",
    "        glyphs=glyphs,\n",
    "        blstats=blstats,\n",
    "        inv_letters=inv_letters,\n",
    "        inv_glyphs=inv_glyphs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f5491bf",
   "metadata": {},
   "source": [
    "import pdb; pdb.pm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a5837b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff75f63a",
   "metadata": {},
   "source": [
    "     y  k  u  \n",
    "      \\ | /   \n",
    "    h - . - l \n",
    "      / | \\   \n",
    "     b  j  n  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92540bc",
   "metadata": {},
   "source": [
    "Spell tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2268d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellcaster(obs, mask, *, dir='.', ctoa):\n",
    "    yield from map(ctoa.get, f'Z{letter}{dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa03612",
   "metadata": {},
   "source": [
    "Random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linger(obs, mask, n=16, *, seed=None, ctoa=None):\n",
    "    rng, j = np.random.default_rng(seed), 0\n",
    "    while not mask.all() and j < n:\n",
    "        # if we're in LINGER state, pick a random non-forbidden action\n",
    "        # XXX whelp... tilde on int8 is `two's complement`, not the `logical not`\n",
    "        act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "\n",
    "        obs, mask = (yield act)\n",
    "        j += 1\n",
    "\n",
    "def search(obs, mask, n=6, *, ctoa):\n",
    "    yield from map(ctoa.get, f'{n:d}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63591f12",
   "metadata": {},
   "source": [
    "Level and dungeon mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb66165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle.nethack import (\n",
    "    NLE_BL_X,\n",
    "    NLE_BL_Y,\n",
    "    NLE_BL_DNUM,\n",
    "    NLE_BL_DLEVEL,\n",
    "    # NLE_BL_DEPTH,  # derived from DNUM and DLEVEL\n",
    "    # XXX does not uniquely identify floors,\n",
    "    #  c.f. [`depth`](./nle/src/dungeon.c#L1086-1084)\n",
    "    DUNGEON_SHAPE,\n",
    "    MAX_GLYPH,\n",
    ")\n",
    "\n",
    "from nle_toolbox.utils.env.defs import \\\n",
    "    glyph_is, dt_glyph_ext, ext_glyphlut\n",
    "\n",
    "from nle_toolbox.bot.level import Level, DungeonMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198a3d5",
   "metadata": {},
   "source": [
    "Detemine the walkability of the observed tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a3d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nle_toolbox.utils.env.defs import symbol, GLYPH_CMAP_OFF, glyph_group, get_group\n",
    "from nle_toolbox.utils.env.defs import glyphlut, ext_glyphlut\n",
    "\n",
    "closed_doors = get_group(symbol, GLYPH_CMAP_OFF, *[\n",
    "    'S_vcdoor', 'S_hcdoor',\n",
    "    'S_vcdbridge', 'S_hcdbridge',\n",
    "])\n",
    "\n",
    "open_doors = get_group(symbol, GLYPH_CMAP_OFF, *[\n",
    "    'S_ndoor',\n",
    "    'S_vodoor', 'S_hodoor',\n",
    "    'S_vodbridge', 'S_hodbridge',\n",
    "])\n",
    "\n",
    "is_closed_door = np.isin(ext_glyphlut.id.value, np.array(list(closed_doors)))\n",
    "is_actor = np.isin(ext_glyphlut.id.group, np.array(list(glyph_group.ACTORS)))\n",
    "is_pet = ext_glyphlut.id.group == glyph_group.PET\n",
    "\n",
    "is_open_door = np.isin(ext_glyphlut.id.value, np.array(list(open_doors)))\n",
    "is_object = np.isin(ext_glyphlut.id.group, np.asarray(list(glyph_group.OBJECTS)))\n",
    "is_walkable = ext_glyphlut.is_accessible | is_open_door | is_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d80dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "traps = get_group(symbol, GLYPH_CMAP_OFF, *[\n",
    "    'S_arrow_trap',\n",
    "    'S_dart_trap',\n",
    "    'S_falling_rock_trap',\n",
    "    'S_squeaky_board',\n",
    "    'S_bear_trap',\n",
    "    'S_land_mine',\n",
    "    'S_rolling_boulder_trap',\n",
    "    'S_sleeping_gas_trap',\n",
    "    'S_rust_trap',\n",
    "    'S_fire_trap',\n",
    "    'S_pit',\n",
    "    'S_spiked_pit',\n",
    "    'S_hole',\n",
    "    'S_trap_door',\n",
    "    'S_teleportation_trap',\n",
    "    'S_level_teleporter',\n",
    "    'S_magic_portal',\n",
    "    'S_web',\n",
    "    'S_statue_trap',\n",
    "    'S_magic_trap',\n",
    "    'S_anti_magic_trap',\n",
    "    'S_polymorph_trap',\n",
    "    'S_vibrating_square',\n",
    "])\n",
    "\n",
    "is_trap = np.isin(ext_glyphlut.id.value, np.array(list(traps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177664e",
   "metadata": {},
   "source": [
    "The core of the \"smart\" dungeon explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b17319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def crawler(obs, mask, *, dir, seed=None):\n",
    "    dng = DungeonMapper()\n",
    "\n",
    "    # own random number generator\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # a simple state machine: linger <<-->> crawler\n",
    "    state, n_linger, stack = 'linger', 16, []\n",
    "    while True:\n",
    "        dng.update(obs)\n",
    "        pos = dng.level.trace[-1]\n",
    "\n",
    "        if state == 'crawl':\n",
    "            if stack:\n",
    "                plan.pop()\n",
    "                act = dir[stack.pop()]\n",
    "\n",
    "            else:\n",
    "                state, n_linger = 'linger', 16\n",
    "                continue\n",
    "\n",
    "        elif state == 'linger':\n",
    "            if n_linger > 0:\n",
    "                n_linger -= 1\n",
    "\n",
    "                # if we're in LINGER state, pick a random non-forbidden action\n",
    "                # XXX whelp... tilde on int8 is `two's complement`, not the `logical not`\n",
    "                act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "\n",
    "            else:\n",
    "                lvl = dng.level\n",
    "\n",
    "                # we've run out linger moves, time to pick a random destination\n",
    "                # and go to it\n",
    "                state = 'crawl'\n",
    "\n",
    "                # get the walkability cost\n",
    "                cost = np.where(\n",
    "                    # is_walkable[lvl.bg_tiles.glyph]\n",
    "                    (is_walkable | is_pet)[lvl.bg_tiles.glyph]\n",
    "                    , .334, np.inf)\n",
    "                # XXX adjust `cost` for hard-to-pass objects?\n",
    "                cost[is_trap[lvl.bg_tiles.glyph]] = 10.\n",
    "\n",
    "                # get the shortest paths from the current position\n",
    "                value, path = dij(cost, pos)\n",
    "\n",
    "                # draw a destination, the further the better\n",
    "                prob = softmax(np.where(\n",
    "                    is_closed_door[lvl.bg_tiles.glyph],\n",
    "                    100.,\n",
    "                    np.where(\n",
    "                        np.logical_and(\n",
    "                            np.isfinite(value),\n",
    "                            np.logical_not(\n",
    "                                is_trap[lvl.bg_tiles.glyph]\n",
    "                            )\n",
    "                        ), value, -np.inf\n",
    "                    ))\n",
    "                )\n",
    "                dest = divmod(rng.choice(prob.size, p=prob.flat), prob.shape[1])\n",
    "\n",
    "                # reconstruct the path to the destination in reverse order\n",
    "                plan = list(backup(path, dest))\n",
    "                for (r1, c1), (r0, c0) in zip(plan, plan[1:]):\n",
    "                    stack.append(dir_to_ascii[r1-r0, c1-c0])\n",
    "\n",
    "                plan.pop()\n",
    "                continue\n",
    "\n",
    "        obs, mask = yield act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ec111",
   "metadata": {},
   "source": [
    "How do we want to explore?\n",
    "* open closed doors\n",
    "* explore tunnels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83512a48",
   "metadata": {},
   "source": [
    "Implementing the random dungeon crwaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c40bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dng = getgeneratorlocals(gen).get('dng')\n",
    "# dng.level.trace[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f76c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dng.level.bg_tiles.info.is_accessible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f588a",
   "metadata": {},
   "source": [
    "     y  k  u  \n",
    "      \\ | /   \n",
    "    h - . - l \n",
    "      / | \\   \n",
    "     b  j  n  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the walkability cost\n",
    "cost = np.where((\n",
    "    is_walkable\n",
    "    | is_pet\n",
    ")[obs['glyphs']], 1., np.inf)\n",
    "# XXX adjust `cost` for hard-to-pass objects?\n",
    "cost[is_trap[obs['glyphs']]] = 10.\n",
    "\n",
    "# get shroteste paths from the current position\n",
    "bls = obs['blstats']\n",
    "value, path = dij(cost, (bls[NLE_BL_Y], bls[NLE_BL_X]))\n",
    "\n",
    "prob = softmax(np.where(\n",
    "    np.logical_and(\n",
    "        np.isfinite(value),\n",
    "        np.logical_not(\n",
    "            is_trap[obs['glyphs']]\n",
    "        )\n",
    "    ), value, -np.inf\n",
    "))\n",
    "\n",
    "plt.imshow(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab898e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6bc4b",
   "metadata": {},
   "source": [
    "Test the algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 12, 12\n",
    "\n",
    "rng = np.random.default_rng()  #248675)\n",
    "\n",
    "cost = -np.log(rng.random((21, 79)))\n",
    "# cost = np.ones((21, 79))\n",
    "cost[rng.random(cost.shape) < .5] = np.inf\n",
    "\n",
    "value, path = dij(cost, (r, c))\n",
    "\n",
    "\n",
    "# mask = is_walkable[lvl.bg_tiles.glyph] | is_walkable[lvl.stg_tiles.glyph]\n",
    "mask = np.isfinite(value)\n",
    "mask[r, c] = False  # mask the current position\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "value = np.where(value > 5, 0., -np.inf)\n",
    "prob = softmax(np.where(mask, value, -np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841157d1",
   "metadata": {},
   "source": [
    "Play around with the shortes path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = divmod(rng.choice(prob.size, p=prob.flat, ), prob.shape[1])\n",
    "\n",
    "displ = cost.copy()\n",
    "plan = list(backup(path, (r, c)))\n",
    "for ij in plan:\n",
    "    displ[ij] = 10\n",
    "displ[12, 12] = 11\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=300)\n",
    "ax.imshow(displ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = []\n",
    "for (r1, c1), (r0, c0) in zip(plan, plan[1:]):\n",
    "    commands.append(dir_to_ascii[r1-r0, c1-c0])\n",
    "\n",
    "''.join(reversed(commands))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d5208",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c03a68",
   "metadata": {},
   "source": [
    "A non-illegal random action exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from nle_toolbox.bot.chassis import get_wrapper\n",
    "\n",
    "\n",
    "def random_explore(seed=None, n_steps=1000, *, auto=False, fps=None, copy=False):\n",
    "    \"\"\"A non-illegal random action explorer.\n",
    "    \"\"\"\n",
    "    ss_pol, ss_env = np.random.SeedSequence(seed).spawn(2)\n",
    "\n",
    "    rng, j, n_linger, pf = np.random.default_rng(ss_pol), 0, 0, None\n",
    "    with factory(seed=ss_env) as env:\n",
    "        # we need access to the Chassis for additional meta state variables\n",
    "        cha = get_wrapper(env, Chassis)\n",
    "\n",
    "        # ActionMasker caches the esacpe action id\n",
    "        ESC = get_wrapper(env, ActionMasker).escape\n",
    "\n",
    "        # setup the dungeon mapper\n",
    "        dng = DungeonMapper()\n",
    "\n",
    "        # launch the episode\n",
    "        (obs, mask), fin = env.reset(), False\n",
    "        while (\n",
    "            ipynb_render(obs, clear=True, fps=fps)\n",
    "            and not (fin or j >= n_steps)\n",
    "        ):\n",
    "            # though nle reuses buffers, we do not deep copy them\n",
    "            #  delegating this to the downstream user instead\n",
    "            yield deepcopy(obs) if copy else obs\n",
    "\n",
    "            # default to immediately escaping from any menu or prompt\n",
    "            act = ESC\n",
    "            if not (cha.in_menu or cha.prompt):\n",
    "                dng.update(obs)\n",
    "\n",
    "                # if we're in LINGER state, pick a random non-forbidden action\n",
    "                # XXX whelp... tilde on int8 is `two's complement`, not the `logical not`\n",
    "                act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "\n",
    "            (obs, mask), rew, fin, info = env.step(act)\n",
    "            j += 1\n",
    "\n",
    "            if fin and auto:\n",
    "                ipynb_render(obs, clear=True, fps=fps)\n",
    "                (obs, mask), fin = env.reset(), False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f035ca",
   "metadata": {},
   "source": [
    "Get a random episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inspect import getgeneratorlocals\n",
    "episode = random_explore(\n",
    "    seed=None,\n",
    "    n_steps=256,\n",
    "    auto=False,\n",
    "    copy=True,\n",
    "    fps=0.01,\n",
    ")\n",
    "\n",
    "\n",
    "glyphs = [next(episode)]\n",
    "# dng = getgeneratorlocals(episode).get('dng')\n",
    "\n",
    "glyphs.extend(obs['glyphs'] for obs in episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def dstination_prob(lvl, pos):\n",
    "    r, c = pos\n",
    "    dist = np.maximum(abs(lvl.bg_tiles.rc.r - r), abs(lvl.bg_tiles.rc.c - c))\n",
    "\n",
    "    mask = is_walkable[lvl.bg_tiles.glyph] | is_walkable[lvl.stg_tiles.glyph]\n",
    "    mask[r, c] = False  # mask the current position\n",
    "    return softmax(np.minimum(np.where(mask, dist, -np.inf), 5))\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "prob = dstination_prob(dng.level, dng.level.trace[-1])\n",
    "cost = np.where(prob > 0, 1., float('inf'))\n",
    "\n",
    "plt.imshow(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup(path, dest):\n",
    "    p0 = dest\n",
    "    while True:\n",
    "        p0, p1 = path[p0], p0\n",
    "        yield p1\n",
    "        if p0 is None:\n",
    "            return\n",
    "\n",
    "#         (r0, c0), (r1, c1) = p0, p1\n",
    "#         yield directions[r1-r0, c1-c0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "value, path = dij(cost, dng.level.trace[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa36671",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = value.copy()\n",
    "r, c = rng.choice(dng.level.bg_tiles.rc.flat, p=prob.flat)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=300)\n",
    "for i, j in backup(path, (r, c)):\n",
    "    val[i, j] = 0.\n",
    "\n",
    "val[r, c] = np.inf\n",
    "\n",
    "ax.imshow(val[:, 10:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccdf31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31756f0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3da9480",
   "metadata": {},
   "source": [
    "from nle_toolbox.bot.chassis import get_wrapper\n",
    "\n",
    "def pathfinder(env, obs, seed=None):\n",
    "    # pick a random destination and lay a shortest path to it\n",
    "    path = deque(path_to(uxy, dst))\n",
    "\n",
    "    while path and reachable(uxy, path):\n",
    "        obs = yield path.popleft()\n",
    "\n",
    "    state = 0\n",
    "\n",
    "\n",
    "    # if we're in the LINGER state, pick a random non-forbidden action\n",
    "    if state == 0:\n",
    "        # XXX whelp... tilde uint8 flips the sign bit and is not the logical not\n",
    "        act = rng.choice(*np.logical_not(mask).nonzero())\n",
    "\n",
    "    elif state == 1:\n",
    "        state = 2\n",
    "\n",
    "    elif state == 2:\n",
    "        if path and reachable(uxy, path):\n",
    "            act = None\n",
    "\n",
    "        else:\n",
    "            # moving to the destination is complete, revert to lingering about\n",
    "            state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813f8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9364a29",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1888816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import repeat, rearrange\n",
    "from transformers import ViTModel, ViTConfig\n",
    "\n",
    "from transformers.models.vit.modeling_vit import to_2tuple\n",
    "\n",
    "\n",
    "class NLEViTEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        n_rows, n_cols = to_2tuple(2 * config.window + 1)\n",
    "        super().__init__()\n",
    "\n",
    "        self.cls = nn.Parameter(torch.zeros(\n",
    "            1, config.hidden_size))\n",
    "\n",
    "        self.posemb = nn.Parameter(torch.zeros(\n",
    "            1 + n_rows * n_cols, config.hidden_size))\n",
    "\n",
    "    def forward(self, input, **ignore):\n",
    "        x = rearrange(input, 'B D H W -> B (H W) D')\n",
    "\n",
    "        # cls-token and positional embedding\n",
    "        cls = repeat(self.cls.unsqueeze(0), '() N D -> B N D', B=len(x))\n",
    "        return torch.cat((cls, x), dim=1) + self.posemb\n",
    "\n",
    "\n",
    "model = ViTModel(ViTConfig(\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=1,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=512,\n",
    "    window=2,\n",
    "    # image_size,\n",
    "    # patch_size,  # are ignored\n",
    "))\n",
    "\n",
    "model.embeddings = NLEViTEmbeddings(model.config)\n",
    "\n",
    "\n",
    "# obs, msk = input.obs\n",
    "# gly = agent.features.obs[0](obs)\n",
    "\n",
    "# win = gly['vicinity']\n",
    "\n",
    "# size = dict(zip(\"TBCHW\", win.shape[:3]))\n",
    "# x = rearrange(win, 'T B C H W -> (T B) C H W')\n",
    "\n",
    "# out = rearrange(model(x).pooler_output, '(T B) C -> T B C', **size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c0bf2",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7179fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
